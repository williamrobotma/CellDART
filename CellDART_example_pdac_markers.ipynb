{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellDART Example Code: mouse brain \n",
    "## (10x Visium of anterior mouse brain + scRNA-seq data of mouse brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31598/3903643673.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf  # TensorFlow registers PluggableDevices here.\n",
    "from tqdm.autonotebook import tqdm\n",
    "import yaml\n",
    "\n",
    "from CellDART import da_cellfraction\n",
    "from src.da_utils import data_loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_SEEDS = (3679, 343, 25, 234, 98098)\n",
    "MODEL_SEEDS = (2353, 24385, 284, 86322, 98237)\n",
    "MODEL_DIR = \"model_FINAL\"\n",
    "SEED_OVERRIDE = None\n",
    "\n",
    "CONFIGS_DIR = \"configs\"\n",
    "CONFIG_FNAME = \"celldart-final-pdac-ht.yml\"\n",
    "\n",
    "# BOOTSTRAP = False\n",
    "# BOOTSTRAP_ROUNDS = 10\n",
    "# BOOTSTRAP_ALPHAS = [0.6, 1 / 0.6]\n",
    "\n",
    "MODEL_NAME = \"CellDART_original\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lib_params = config[\"lib_params\"]\n",
    "data_params = config[\"data_params\"]\n",
    "model_params = config[\"model_params\"]\n",
    "train_params = config[\"train_params\"]\n",
    "\n",
    "rewrite_config = False\n",
    "if not \"pretraining\" in train_params:\n",
    "    train_params[\"pretraining\"] = True\n",
    "    rewrite_config = True\n",
    "if not \"lr\" in train_params:\n",
    "    train_params[\"lr\"] = 0.001\n",
    "    rewrite_config = True\n",
    "\n",
    "if rewrite_config:\n",
    "    with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "tqdm.write(yaml.safe_dump(config))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load\n",
    "### load scanpy data - 10x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS seed: 3679, model seed: 2353\n",
      "Adversarial training for slides train: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 8s 79us/sample - loss: 0.1178 - mae: 0.0284\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0329 - mae: 0.0151\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0277 - mae: 0.0140\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0260 - mae: 0.0136\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0250 - mae: 0.0132\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0245 - mae: 0.0131\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0240 - mae: 0.0129\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0237 - mae: 0.0128\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0234 - mae: 0.0127\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0231 - mae: 0.0126\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0303476790869236\n",
      "0.0303476790869236\n",
      "Iteration 99, source loss =  1.851, discriminator acc = 0.998\n",
      "Iteration 199, source loss =  0.543, discriminator acc = 0.986\n",
      "Iteration 299, source loss =  0.276, discriminator acc = 1.000\n",
      "Iteration 399, source loss =  0.293, discriminator acc = 0.999\n",
      "Iteration 499, source loss =  0.443, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.215, discriminator acc = 0.965\n",
      "Iteration 699, source loss =  0.287, discriminator acc = 1.000\n",
      "Iteration 799, source loss =  0.322, discriminator acc = 0.411\n",
      "Iteration 899, source loss =  0.389, discriminator acc = 0.667\n",
      "Iteration 999, source loss =  0.122, discriminator acc = 0.957\n",
      "Iteration 1099, source loss =  0.199, discriminator acc = 1.000\n",
      "Iteration 1199, source loss =  0.157, discriminator acc = 0.924\n",
      "Iteration 1299, source loss =  0.217, discriminator acc = 0.394\n",
      "Iteration 1399, source loss =  0.246, discriminator acc = 0.006\n",
      "Iteration 1499, source loss =  0.213, discriminator acc = 1.000\n",
      "Iteration 1599, source loss =  0.377, discriminator acc = 0.084\n",
      "Iteration 1699, source loss =  0.160, discriminator acc = 0.628\n",
      "Iteration 1799, source loss =  0.129, discriminator acc = 0.990\n",
      "Iteration 1899, source loss =  0.117, discriminator acc = 0.533\n",
      "Iteration 1999, source loss =  0.178, discriminator acc = 0.006\n",
      "Iteration 2099, source loss =  0.188, discriminator acc = 0.006\n",
      "Iteration 2199, source loss =  0.132, discriminator acc = 0.272\n",
      "Iteration 2299, source loss =  0.145, discriminator acc = 0.320\n",
      "Iteration 2399, source loss =  0.213, discriminator acc = 0.006\n",
      "Iteration 2499, source loss =  0.167, discriminator acc = 0.008\n",
      "Iteration 2599, source loss =  0.181, discriminator acc = 0.006\n",
      "Iteration 2699, source loss =  0.145, discriminator acc = 0.009\n",
      "Iteration 2799, source loss =  0.184, discriminator acc = 0.006\n",
      "Iteration 2899, source loss =  0.159, discriminator acc = 0.006\n",
      "Iteration 2999, source loss =  0.260, discriminator acc = 0.006\n",
      "Iteration 3099, source loss =  0.192, discriminator acc = 0.006\n",
      "Iteration 3199, source loss =  0.120, discriminator acc = 0.843\n",
      "Iteration 3299, source loss =  0.148, discriminator acc = 0.006\n",
      "Iteration 3399, source loss =  0.194, discriminator acc = 0.007\n",
      "Iteration 3499, source loss =  0.125, discriminator acc = 1.000\n",
      "Iteration 3599, source loss =  0.114, discriminator acc = 1.000\n",
      "Iteration 3699, source loss =  0.117, discriminator acc = 0.006\n",
      "Iteration 3799, source loss =  0.134, discriminator acc = 0.011\n",
      "Iteration 3899, source loss =  0.132, discriminator acc = 1.000\n",
      "Iteration 3999, source loss =  0.140, discriminator acc = 0.087\n",
      "Iteration 4099, source loss =  0.104, discriminator acc = 0.918\n",
      "Iteration 4199, source loss =  0.112, discriminator acc = 0.201\n",
      "Iteration 4299, source loss =  0.131, discriminator acc = 0.726\n",
      "Iteration 4399, source loss =  0.145, discriminator acc = 0.301\n",
      "Iteration 4499, source loss =  0.122, discriminator acc = 0.299\n",
      "Iteration 4599, source loss =  0.185, discriminator acc = 0.006\n",
      "Iteration 4699, source loss =  0.114, discriminator acc = 0.900\n",
      "Iteration 4799, source loss =  0.156, discriminator acc = 0.038\n",
      "Iteration 4899, source loss =  0.116, discriminator acc = 0.967\n",
      "Iteration 4999, source loss =  0.154, discriminator acc = 0.745\n",
      "Iteration 5099, source loss =  0.156, discriminator acc = 1.000\n",
      "Iteration 5199, source loss =  0.157, discriminator acc = 0.133\n",
      "Iteration 5299, source loss =  0.145, discriminator acc = 1.000\n",
      "Iteration 5399, source loss =  0.172, discriminator acc = 0.486\n",
      "Iteration 5499, source loss =  0.197, discriminator acc = 0.095\n",
      "Iteration 5599, source loss =  0.288, discriminator acc = 0.494\n",
      "Iteration 5699, source loss =  0.127, discriminator acc = 0.603\n",
      "Iteration 5799, source loss =  0.328, discriminator acc = 0.209\n",
      "Iteration 5899, source loss =  0.156, discriminator acc = 1.000\n",
      "Iteration 5999, source loss =  0.135, discriminator acc = 0.507\n",
      "Iteration 6099, source loss =  0.175, discriminator acc = 0.005\n",
      "Iteration 6199, source loss =  0.268, discriminator acc = 0.225\n",
      "Iteration 6299, source loss =  0.100, discriminator acc = 0.998\n",
      "Iteration 6399, source loss =  0.154, discriminator acc = 0.006\n",
      "Iteration 6499, source loss =  0.138, discriminator acc = 0.567\n",
      "Iteration 6599, source loss =  0.122, discriminator acc = 0.777\n",
      "Iteration 6699, source loss =  0.209, discriminator acc = 0.931\n",
      "Iteration 6799, source loss =  0.105, discriminator acc = 0.933\n",
      "Iteration 6899, source loss =  0.105, discriminator acc = 0.908\n",
      "Iteration 6999, source loss =  0.135, discriminator acc = 0.006\n",
      "Iteration 7099, source loss =  0.141, discriminator acc = 0.999\n",
      "Iteration 7199, source loss =  0.244, discriminator acc = 0.010\n",
      "Iteration 7299, source loss =  0.193, discriminator acc = 0.123\n",
      "Iteration 7399, source loss =  0.152, discriminator acc = 0.970\n",
      "Iteration 7499, source loss =  0.099, discriminator acc = 0.729\n",
      "Iteration 7599, source loss =  0.097, discriminator acc = 0.996\n",
      "Iteration 7699, source loss =  0.090, discriminator acc = 0.099\n",
      "Iteration 7799, source loss =  0.131, discriminator acc = 0.007\n",
      "Iteration 7899, source loss =  0.102, discriminator acc = 0.006\n",
      "Iteration 7999, source loss =  0.118, discriminator acc = 0.015\n",
      "Iteration 8099, source loss =  0.095, discriminator acc = 0.506\n",
      "Iteration 8199, source loss =  0.110, discriminator acc = 0.983\n",
      "Iteration 8299, source loss =  0.168, discriminator acc = 0.707\n",
      "Iteration 8399, source loss =  0.148, discriminator acc = 0.983\n",
      "Iteration 8499, source loss =  0.118, discriminator acc = 0.787\n",
      "Iteration 8599, source loss =  0.101, discriminator acc = 0.136\n",
      "Iteration 8699, source loss =  0.120, discriminator acc = 0.006\n",
      "Iteration 8799, source loss =  0.173, discriminator acc = 0.040\n",
      "Iteration 8899, source loss =  0.127, discriminator acc = 0.999\n",
      "Iteration 8999, source loss =  0.111, discriminator acc = 0.014\n",
      "Iteration 9099, source loss =  0.203, discriminator acc = 0.032\n",
      "Iteration 9199, source loss =  0.202, discriminator acc = 0.007\n",
      "Iteration 9299, source loss =  0.154, discriminator acc = 0.082\n",
      "Iteration 9399, source loss =  0.234, discriminator acc = 0.319\n",
      "Iteration 9499, source loss =  0.122, discriminator acc = 0.666\n",
      "Iteration 9599, source loss =  0.132, discriminator acc = 0.999\n",
      "Iteration 9699, source loss =  0.109, discriminator acc = 0.969\n",
      "Iteration 9799, source loss =  0.097, discriminator acc = 0.386\n",
      "Iteration 9899, source loss =  0.148, discriminator acc = 0.488\n",
      "Iteration 9999, source loss =  0.119, discriminator acc = 0.013\n",
      "Iteration 10099, source loss =  0.104, discriminator acc = 0.962\n",
      "Iteration 10199, source loss =  0.146, discriminator acc = 0.983\n",
      "Iteration 10299, source loss =  0.110, discriminator acc = 0.017\n",
      "Iteration 10399, source loss =  0.106, discriminator acc = 0.679\n",
      "Iteration 10499, source loss =  0.122, discriminator acc = 0.886\n",
      "Iteration 10599, source loss =  0.113, discriminator acc = 0.932\n",
      "Iteration 10699, source loss =  0.096, discriminator acc = 0.679\n",
      "Iteration 10799, source loss =  0.091, discriminator acc = 0.012\n",
      "Iteration 10899, source loss =  0.090, discriminator acc = 0.319\n",
      "Iteration 10999, source loss =  0.092, discriminator acc = 0.932\n",
      "Iteration 11099, source loss =  0.100, discriminator acc = 0.272\n",
      "Iteration 11199, source loss =  0.091, discriminator acc = 0.990\n",
      "Iteration 11299, source loss =  0.117, discriminator acc = 0.278\n",
      "Iteration 11399, source loss =  0.091, discriminator acc = 0.998\n",
      "Iteration 11499, source loss =  0.145, discriminator acc = 0.683\n",
      "Iteration 11599, source loss =  0.092, discriminator acc = 0.887\n",
      "Iteration 11699, source loss =  0.086, discriminator acc = 0.778\n",
      "Iteration 11799, source loss =  0.092, discriminator acc = 0.438\n",
      "Iteration 11899, source loss =  0.091, discriminator acc = 0.871\n",
      "Iteration 11999, source loss =  0.089, discriminator acc = 0.422\n",
      "Iteration 12099, source loss =  0.088, discriminator acc = 0.717\n",
      "Iteration 12199, source loss =  0.092, discriminator acc = 0.363\n",
      "Iteration 12299, source loss =  0.087, discriminator acc = 0.870\n",
      "Iteration 12399, source loss =  0.099, discriminator acc = 0.939\n",
      "Iteration 12499, source loss =  0.118, discriminator acc = 0.083\n",
      "Iteration 12599, source loss =  0.096, discriminator acc = 0.940\n",
      "Iteration 12699, source loss =  0.093, discriminator acc = 0.577\n",
      "Iteration 12799, source loss =  0.091, discriminator acc = 0.904\n",
      "Iteration 12899, source loss =  0.107, discriminator acc = 0.875\n",
      "Iteration 12999, source loss =  0.088, discriminator acc = 0.836\n",
      "Iteration 13099, source loss =  0.107, discriminator acc = 0.081\n",
      "Iteration 13199, source loss =  0.084, discriminator acc = 0.677\n",
      "Iteration 13299, source loss =  0.088, discriminator acc = 0.663\n",
      "Iteration 13399, source loss =  0.084, discriminator acc = 0.690\n",
      "Iteration 13499, source loss =  0.089, discriminator acc = 0.935\n",
      "Iteration 13599, source loss =  0.091, discriminator acc = 0.824\n",
      "Iteration 13699, source loss =  0.127, discriminator acc = 0.110\n",
      "Iteration 13799, source loss =  0.102, discriminator acc = 0.888\n",
      "Iteration 13899, source loss =  0.095, discriminator acc = 0.994\n",
      "Iteration 13999, source loss =  0.090, discriminator acc = 0.875\n",
      "Iteration 14099, source loss =  0.133, discriminator acc = 0.984\n",
      "Iteration 14199, source loss =  0.106, discriminator acc = 0.931\n",
      "Iteration 14299, source loss =  0.118, discriminator acc = 0.967\n",
      "Iteration 14399, source loss =  0.124, discriminator acc = 0.957\n",
      "Iteration 14499, source loss =  0.127, discriminator acc = 0.996\n",
      "Iteration 14599, source loss =  0.121, discriminator acc = 0.285\n",
      "Iteration 14699, source loss =  0.149, discriminator acc = 0.251\n",
      "Iteration 14799, source loss =  0.095, discriminator acc = 0.656\n",
      "Iteration 14899, source loss =  0.109, discriminator acc = 0.021\n",
      "Iteration 14999, source loss =  0.134, discriminator acc = 0.031\n",
      "PS seed: 343, model seed: 24385\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/24385\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 15us/sample - loss: 0.1156 - mae: 0.0282\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0324 - mae: 0.0150\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0277 - mae: 0.0139\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0261 - mae: 0.0135\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0253 - mae: 0.0132\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0246 - mae: 0.0130\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0242 - mae: 0.0129\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0238 - mae: 0.0128\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0235 - mae: 0.0127\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0232 - mae: 0.0126\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027807374956011773\n",
      "0.027807374956011773\n",
      "Iteration 99, source loss =  1.982, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.787, discriminator acc = 0.006\n",
      "Iteration 299, source loss =  0.422, discriminator acc = 0.006\n",
      "Iteration 399, source loss =  0.221, discriminator acc = 0.010\n",
      "Iteration 499, source loss =  0.220, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.248, discriminator acc = 0.905\n",
      "Iteration 699, source loss =  0.222, discriminator acc = 0.221\n",
      "Iteration 799, source loss =  0.464, discriminator acc = 0.009\n",
      "Iteration 899, source loss =  0.166, discriminator acc = 0.497\n",
      "Iteration 999, source loss =  0.288, discriminator acc = 0.346\n",
      "Iteration 1099, source loss =  0.148, discriminator acc = 0.006\n",
      "Iteration 1199, source loss =  0.142, discriminator acc = 0.996\n",
      "Iteration 1299, source loss =  0.233, discriminator acc = 0.022\n",
      "Iteration 1399, source loss =  0.137, discriminator acc = 0.984\n",
      "Iteration 1499, source loss =  0.182, discriminator acc = 0.463\n",
      "Iteration 1599, source loss =  0.190, discriminator acc = 0.265\n",
      "Iteration 1699, source loss =  0.130, discriminator acc = 0.998\n",
      "Iteration 1799, source loss =  0.124, discriminator acc = 0.998\n",
      "Iteration 1899, source loss =  0.123, discriminator acc = 0.979\n",
      "Iteration 1999, source loss =  0.116, discriminator acc = 0.999\n",
      "Iteration 2099, source loss =  0.131, discriminator acc = 0.500\n",
      "Iteration 2199, source loss =  0.156, discriminator acc = 0.858\n",
      "Iteration 2299, source loss =  0.166, discriminator acc = 0.006\n",
      "Iteration 2399, source loss =  0.200, discriminator acc = 0.981\n",
      "Iteration 2499, source loss =  0.130, discriminator acc = 0.065\n",
      "Iteration 2599, source loss =  0.179, discriminator acc = 0.813\n",
      "Iteration 2699, source loss =  0.145, discriminator acc = 1.000\n",
      "Iteration 2799, source loss =  0.146, discriminator acc = 0.006\n",
      "Iteration 2899, source loss =  0.161, discriminator acc = 0.999\n",
      "Iteration 2999, source loss =  0.154, discriminator acc = 0.077\n",
      "Iteration 3099, source loss =  0.113, discriminator acc = 1.000\n",
      "Iteration 3199, source loss =  0.131, discriminator acc = 1.000\n",
      "Iteration 3299, source loss =  0.148, discriminator acc = 0.006\n",
      "Iteration 3399, source loss =  0.134, discriminator acc = 0.778\n",
      "Iteration 3499, source loss =  0.194, discriminator acc = 0.006\n",
      "Iteration 3599, source loss =  0.232, discriminator acc = 0.050\n",
      "Iteration 3699, source loss =  0.111, discriminator acc = 0.999\n",
      "Iteration 3799, source loss =  0.118, discriminator acc = 0.006\n",
      "Iteration 3899, source loss =  0.105, discriminator acc = 0.996\n",
      "Iteration 3999, source loss =  0.123, discriminator acc = 0.652\n",
      "Iteration 4099, source loss =  0.143, discriminator acc = 0.007\n",
      "Iteration 4199, source loss =  0.113, discriminator acc = 0.998\n",
      "Iteration 4299, source loss =  0.153, discriminator acc = 0.006\n",
      "Iteration 4399, source loss =  0.158, discriminator acc = 0.190\n",
      "Iteration 4499, source loss =  0.125, discriminator acc = 0.743\n",
      "Iteration 4599, source loss =  0.182, discriminator acc = 0.006\n",
      "Iteration 4699, source loss =  0.116, discriminator acc = 0.010\n",
      "Iteration 4799, source loss =  0.196, discriminator acc = 0.979\n",
      "Iteration 4899, source loss =  0.247, discriminator acc = 0.006\n",
      "Iteration 4999, source loss =  0.127, discriminator acc = 0.997\n",
      "Iteration 5099, source loss =  0.194, discriminator acc = 0.947\n",
      "Iteration 5199, source loss =  0.118, discriminator acc = 0.999\n",
      "Iteration 5299, source loss =  0.106, discriminator acc = 1.000\n",
      "Iteration 5399, source loss =  0.129, discriminator acc = 0.221\n",
      "Iteration 5499, source loss =  0.107, discriminator acc = 0.830\n",
      "Iteration 5599, source loss =  0.098, discriminator acc = 0.998\n",
      "Iteration 5699, source loss =  0.141, discriminator acc = 0.215\n",
      "Iteration 5799, source loss =  0.105, discriminator acc = 0.970\n",
      "Iteration 5899, source loss =  0.103, discriminator acc = 1.000\n",
      "Iteration 5999, source loss =  0.118, discriminator acc = 0.616\n",
      "Iteration 6099, source loss =  0.104, discriminator acc = 0.640\n",
      "Iteration 6199, source loss =  0.098, discriminator acc = 0.860\n",
      "Iteration 6299, source loss =  0.102, discriminator acc = 0.874\n",
      "Iteration 6399, source loss =  0.098, discriminator acc = 0.967\n",
      "Iteration 6499, source loss =  0.099, discriminator acc = 0.750\n",
      "Iteration 6599, source loss =  0.091, discriminator acc = 0.764\n",
      "Iteration 6699, source loss =  0.092, discriminator acc = 0.480\n",
      "Iteration 6799, source loss =  0.094, discriminator acc = 0.834\n",
      "Iteration 6899, source loss =  0.093, discriminator acc = 0.815\n",
      "Iteration 6999, source loss =  0.098, discriminator acc = 0.752\n",
      "Iteration 7099, source loss =  0.113, discriminator acc = 0.369\n",
      "Iteration 7199, source loss =  0.099, discriminator acc = 0.996\n",
      "Iteration 7299, source loss =  0.114, discriminator acc = 0.169\n",
      "Iteration 7399, source loss =  0.128, discriminator acc = 0.977\n",
      "Iteration 7499, source loss =  0.134, discriminator acc = 0.985\n",
      "Iteration 7599, source loss =  0.122, discriminator acc = 0.637\n",
      "Iteration 7699, source loss =  0.149, discriminator acc = 0.727\n",
      "Iteration 7799, source loss =  0.102, discriminator acc = 0.877\n",
      "Iteration 7899, source loss =  0.140, discriminator acc = 0.601\n",
      "Iteration 7999, source loss =  0.154, discriminator acc = 0.492\n",
      "Iteration 8099, source loss =  0.128, discriminator acc = 0.822\n",
      "Iteration 8199, source loss =  0.139, discriminator acc = 0.734\n",
      "Iteration 8299, source loss =  0.113, discriminator acc = 0.913\n",
      "Iteration 8399, source loss =  0.195, discriminator acc = 0.076\n",
      "Iteration 8499, source loss =  0.136, discriminator acc = 0.998\n",
      "Iteration 8599, source loss =  0.102, discriminator acc = 0.978\n",
      "Iteration 8699, source loss =  0.162, discriminator acc = 0.927\n",
      "Iteration 8799, source loss =  0.201, discriminator acc = 0.114\n",
      "Iteration 8899, source loss =  0.167, discriminator acc = 0.006\n",
      "Iteration 8999, source loss =  0.187, discriminator acc = 0.996\n",
      "Iteration 9099, source loss =  0.244, discriminator acc = 0.986\n",
      "Iteration 9199, source loss =  0.201, discriminator acc = 0.999\n",
      "Iteration 9299, source loss =  0.397, discriminator acc = 0.007\n",
      "Iteration 9399, source loss =  0.426, discriminator acc = 0.006\n",
      "Iteration 9499, source loss =  0.188, discriminator acc = 0.007\n",
      "Iteration 9599, source loss =  0.194, discriminator acc = 0.923\n",
      "Iteration 9699, source loss =  0.176, discriminator acc = 0.988\n",
      "Iteration 9799, source loss =  0.156, discriminator acc = 0.973\n",
      "Iteration 9899, source loss =  0.143, discriminator acc = 0.978\n",
      "Iteration 9999, source loss =  0.144, discriminator acc = 0.134\n",
      "Iteration 10099, source loss =  0.106, discriminator acc = 0.839\n",
      "Iteration 10199, source loss =  0.124, discriminator acc = 1.000\n",
      "Iteration 10299, source loss =  0.147, discriminator acc = 0.007\n",
      "Iteration 10399, source loss =  0.117, discriminator acc = 0.023\n",
      "Iteration 10499, source loss =  0.102, discriminator acc = 0.892\n",
      "Iteration 10599, source loss =  0.161, discriminator acc = 0.010\n",
      "Iteration 10699, source loss =  0.120, discriminator acc = 0.751\n",
      "Iteration 10799, source loss =  0.107, discriminator acc = 0.830\n",
      "Iteration 10899, source loss =  0.109, discriminator acc = 0.420\n",
      "Iteration 10999, source loss =  0.108, discriminator acc = 0.979\n",
      "Iteration 11099, source loss =  0.108, discriminator acc = 0.168\n",
      "Iteration 11199, source loss =  0.155, discriminator acc = 0.485\n",
      "Iteration 11299, source loss =  0.120, discriminator acc = 0.985\n",
      "Iteration 11399, source loss =  0.127, discriminator acc = 0.979\n",
      "Iteration 11499, source loss =  0.103, discriminator acc = 0.037\n",
      "Iteration 11599, source loss =  0.126, discriminator acc = 0.999\n",
      "Iteration 11699, source loss =  0.108, discriminator acc = 0.008\n",
      "Iteration 11799, source loss =  0.110, discriminator acc = 0.974\n",
      "Iteration 11899, source loss =  0.104, discriminator acc = 0.006\n",
      "Iteration 11999, source loss =  0.087, discriminator acc = 1.000\n",
      "Iteration 12099, source loss =  0.106, discriminator acc = 0.985\n",
      "Iteration 12199, source loss =  0.089, discriminator acc = 0.154\n",
      "Iteration 12299, source loss =  0.085, discriminator acc = 0.987\n",
      "Iteration 12399, source loss =  0.096, discriminator acc = 0.248\n",
      "Iteration 12499, source loss =  0.098, discriminator acc = 0.995\n",
      "Iteration 12599, source loss =  0.102, discriminator acc = 0.869\n",
      "Iteration 12699, source loss =  0.155, discriminator acc = 0.119\n",
      "Iteration 12799, source loss =  0.214, discriminator acc = 0.006\n",
      "Iteration 12899, source loss =  0.094, discriminator acc = 0.980\n",
      "Iteration 12999, source loss =  0.140, discriminator acc = 0.006\n",
      "Iteration 13099, source loss =  0.102, discriminator acc = 0.580\n",
      "Iteration 13199, source loss =  0.221, discriminator acc = 0.065\n",
      "Iteration 13299, source loss =  0.091, discriminator acc = 0.821\n",
      "Iteration 13399, source loss =  0.129, discriminator acc = 0.175\n",
      "Iteration 13499, source loss =  0.110, discriminator acc = 0.451\n",
      "Iteration 13599, source loss =  0.108, discriminator acc = 0.918\n",
      "Iteration 13699, source loss =  0.114, discriminator acc = 0.166\n",
      "Iteration 13799, source loss =  0.127, discriminator acc = 0.262\n",
      "Iteration 13899, source loss =  0.187, discriminator acc = 0.989\n",
      "Iteration 13999, source loss =  0.084, discriminator acc = 0.196\n",
      "Iteration 14099, source loss =  0.132, discriminator acc = 0.362\n",
      "Iteration 14199, source loss =  0.097, discriminator acc = 0.154\n",
      "Iteration 14299, source loss =  0.114, discriminator acc = 0.981\n",
      "Iteration 14399, source loss =  0.093, discriminator acc = 0.010\n",
      "Iteration 14499, source loss =  0.098, discriminator acc = 0.938\n",
      "Iteration 14599, source loss =  0.188, discriminator acc = 0.612\n",
      "Iteration 14699, source loss =  0.211, discriminator acc = 0.805\n",
      "Iteration 14799, source loss =  0.315, discriminator acc = 0.200\n",
      "Iteration 14899, source loss =  0.091, discriminator acc = 0.973\n",
      "Iteration 14999, source loss =  0.132, discriminator acc = 0.268\n",
      "PS seed: 25, model seed: 284\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/284\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 14us/sample - loss: 0.1250 - mae: 0.0307\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0326 - mae: 0.0150\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0280 - mae: 0.0140\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0264 - mae: 0.0136\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0253 - mae: 0.0133\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0246 - mae: 0.0130\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0241 - mae: 0.0129\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0237 - mae: 0.0128\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0235 - mae: 0.0127\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0231 - mae: 0.0126\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02885524251639843\n",
      "0.02885524251639843\n",
      "Iteration 99, source loss =  2.198, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.865, discriminator acc = 0.678\n",
      "Iteration 299, source loss =  0.456, discriminator acc = 1.000\n",
      "Iteration 399, source loss =  0.528, discriminator acc = 0.006\n",
      "Iteration 499, source loss =  0.214, discriminator acc = 0.006\n",
      "Iteration 599, source loss =  0.136, discriminator acc = 0.006\n",
      "Iteration 699, source loss =  0.216, discriminator acc = 0.006\n",
      "Iteration 799, source loss =  0.154, discriminator acc = 0.006\n",
      "Iteration 899, source loss =  0.227, discriminator acc = 0.006\n",
      "Iteration 999, source loss =  0.190, discriminator acc = 0.006\n",
      "Iteration 1099, source loss =  0.189, discriminator acc = 0.006\n",
      "Iteration 1199, source loss =  0.133, discriminator acc = 0.006\n",
      "Iteration 1299, source loss =  0.202, discriminator acc = 0.006\n",
      "Iteration 1399, source loss =  0.124, discriminator acc = 0.007\n",
      "Iteration 1499, source loss =  0.235, discriminator acc = 0.966\n",
      "Iteration 1599, source loss =  0.171, discriminator acc = 0.071\n",
      "Iteration 1699, source loss =  0.161, discriminator acc = 0.986\n",
      "Iteration 1799, source loss =  0.216, discriminator acc = 0.010\n",
      "Iteration 1899, source loss =  0.173, discriminator acc = 0.986\n",
      "Iteration 1999, source loss =  0.229, discriminator acc = 0.365\n",
      "Iteration 2099, source loss =  0.157, discriminator acc = 0.346\n",
      "Iteration 2199, source loss =  0.140, discriminator acc = 1.000\n",
      "Iteration 2299, source loss =  0.170, discriminator acc = 0.205\n",
      "Iteration 2399, source loss =  0.147, discriminator acc = 0.167\n",
      "Iteration 2499, source loss =  0.138, discriminator acc = 0.998\n",
      "Iteration 2599, source loss =  0.172, discriminator acc = 0.094\n",
      "Iteration 2699, source loss =  0.180, discriminator acc = 0.732\n",
      "Iteration 2799, source loss =  0.115, discriminator acc = 0.997\n",
      "Iteration 2899, source loss =  0.121, discriminator acc = 0.006\n",
      "Iteration 2999, source loss =  0.104, discriminator acc = 0.995\n",
      "Iteration 3099, source loss =  0.109, discriminator acc = 0.110\n",
      "Iteration 3199, source loss =  0.120, discriminator acc = 0.120\n",
      "Iteration 3299, source loss =  0.099, discriminator acc = 0.996\n",
      "Iteration 3399, source loss =  0.103, discriminator acc = 0.870\n",
      "Iteration 3499, source loss =  0.322, discriminator acc = 0.065\n",
      "Iteration 3599, source loss =  0.105, discriminator acc = 0.987\n",
      "Iteration 3699, source loss =  0.110, discriminator acc = 0.133\n",
      "Iteration 3799, source loss =  0.097, discriminator acc = 0.700\n",
      "Iteration 3899, source loss =  0.103, discriminator acc = 0.654\n",
      "Iteration 3999, source loss =  0.096, discriminator acc = 0.005\n",
      "Iteration 4099, source loss =  0.095, discriminator acc = 0.530\n",
      "Iteration 4199, source loss =  0.099, discriminator acc = 0.663\n",
      "Iteration 4299, source loss =  0.110, discriminator acc = 0.876\n",
      "Iteration 4399, source loss =  0.095, discriminator acc = 0.890\n",
      "Iteration 4499, source loss =  0.093, discriminator acc = 0.860\n",
      "Iteration 4599, source loss =  0.098, discriminator acc = 0.723\n",
      "Iteration 4699, source loss =  0.095, discriminator acc = 0.444\n",
      "Iteration 4799, source loss =  0.089, discriminator acc = 0.147\n",
      "Iteration 4899, source loss =  0.099, discriminator acc = 0.006\n",
      "Iteration 4999, source loss =  0.119, discriminator acc = 0.136\n",
      "Iteration 5099, source loss =  0.222, discriminator acc = 0.011\n",
      "Iteration 5199, source loss =  0.169, discriminator acc = 1.000\n",
      "Iteration 5299, source loss =  0.116, discriminator acc = 1.000\n",
      "Iteration 5399, source loss =  0.147, discriminator acc = 0.028\n",
      "Iteration 5499, source loss =  0.385, discriminator acc = 0.091\n",
      "Iteration 5599, source loss =  0.179, discriminator acc = 0.989\n",
      "Iteration 5699, source loss =  0.176, discriminator acc = 0.997\n",
      "Iteration 5799, source loss =  0.161, discriminator acc = 0.970\n",
      "Iteration 5899, source loss =  0.490, discriminator acc = 0.997\n",
      "Iteration 5999, source loss =  0.163, discriminator acc = 0.997\n",
      "Iteration 6099, source loss =  0.194, discriminator acc = 0.999\n",
      "Iteration 6199, source loss =  0.126, discriminator acc = 0.999\n",
      "Iteration 6299, source loss =  0.157, discriminator acc = 0.034\n",
      "Iteration 6399, source loss =  0.099, discriminator acc = 0.995\n",
      "Iteration 6499, source loss =  0.106, discriminator acc = 0.925\n",
      "Iteration 6599, source loss =  0.103, discriminator acc = 0.014\n",
      "Iteration 6699, source loss =  0.108, discriminator acc = 0.251\n",
      "Iteration 6799, source loss =  0.107, discriminator acc = 0.987\n",
      "Iteration 6899, source loss =  0.103, discriminator acc = 0.007\n",
      "Iteration 6999, source loss =  0.127, discriminator acc = 0.809\n",
      "Iteration 7099, source loss =  0.093, discriminator acc = 0.999\n",
      "Iteration 7199, source loss =  0.129, discriminator acc = 0.007\n",
      "Iteration 7299, source loss =  0.241, discriminator acc = 0.413\n",
      "Iteration 7399, source loss =  0.134, discriminator acc = 0.847\n",
      "Iteration 7499, source loss =  0.218, discriminator acc = 0.006\n",
      "Iteration 7599, source loss =  0.130, discriminator acc = 0.060\n",
      "Iteration 7699, source loss =  0.145, discriminator acc = 0.866\n",
      "Iteration 7799, source loss =  0.134, discriminator acc = 0.055\n",
      "Iteration 7899, source loss =  0.116, discriminator acc = 0.533\n",
      "Iteration 7999, source loss =  0.136, discriminator acc = 0.613\n",
      "Iteration 8099, source loss =  0.148, discriminator acc = 0.998\n",
      "Iteration 8199, source loss =  0.193, discriminator acc = 0.999\n",
      "Iteration 8299, source loss =  0.178, discriminator acc = 0.032\n",
      "Iteration 8399, source loss =  0.095, discriminator acc = 0.999\n",
      "Iteration 8499, source loss =  0.169, discriminator acc = 0.006\n",
      "Iteration 8599, source loss =  0.142, discriminator acc = 0.132\n",
      "Iteration 8699, source loss =  0.144, discriminator acc = 0.117\n",
      "Iteration 8799, source loss =  0.299, discriminator acc = 0.006\n",
      "Iteration 8899, source loss =  0.134, discriminator acc = 0.999\n",
      "Iteration 8999, source loss =  0.278, discriminator acc = 0.366\n",
      "Iteration 9099, source loss =  0.115, discriminator acc = 1.000\n",
      "Iteration 9199, source loss =  0.166, discriminator acc = 0.008\n",
      "Iteration 9299, source loss =  0.177, discriminator acc = 0.717\n",
      "Iteration 9399, source loss =  0.133, discriminator acc = 0.012\n",
      "Iteration 9499, source loss =  0.134, discriminator acc = 0.991\n",
      "Iteration 9599, source loss =  0.157, discriminator acc = 0.968\n",
      "Iteration 9699, source loss =  0.171, discriminator acc = 0.360\n",
      "Iteration 9799, source loss =  0.139, discriminator acc = 0.999\n",
      "Iteration 9899, source loss =  0.204, discriminator acc = 0.009\n",
      "Iteration 9999, source loss =  0.127, discriminator acc = 0.999\n",
      "Iteration 10099, source loss =  0.126, discriminator acc = 0.998\n",
      "Iteration 10199, source loss =  0.102, discriminator acc = 0.792\n",
      "Iteration 10299, source loss =  0.122, discriminator acc = 0.999\n",
      "Iteration 10399, source loss =  0.135, discriminator acc = 0.009\n",
      "Iteration 10499, source loss =  0.090, discriminator acc = 0.826\n",
      "Iteration 10599, source loss =  0.110, discriminator acc = 0.013\n",
      "Iteration 10699, source loss =  0.091, discriminator acc = 0.998\n",
      "Iteration 10799, source loss =  0.094, discriminator acc = 0.700\n",
      "Iteration 10899, source loss =  0.120, discriminator acc = 0.031\n",
      "Iteration 10999, source loss =  0.100, discriminator acc = 0.952\n",
      "Iteration 11099, source loss =  0.156, discriminator acc = 0.280\n",
      "Iteration 11199, source loss =  0.116, discriminator acc = 0.636\n",
      "Iteration 11299, source loss =  0.109, discriminator acc = 0.983\n",
      "Iteration 11399, source loss =  0.104, discriminator acc = 0.293\n",
      "Iteration 11499, source loss =  0.165, discriminator acc = 0.345\n",
      "Iteration 11599, source loss =  0.146, discriminator acc = 0.019\n",
      "Iteration 11699, source loss =  0.105, discriminator acc = 0.927\n",
      "Iteration 11799, source loss =  0.127, discriminator acc = 0.999\n",
      "Iteration 11899, source loss =  0.139, discriminator acc = 0.999\n",
      "Iteration 11999, source loss =  0.262, discriminator acc = 0.032\n",
      "Iteration 12099, source loss =  0.094, discriminator acc = 0.676\n",
      "Iteration 12199, source loss =  0.124, discriminator acc = 0.693\n",
      "Iteration 12299, source loss =  0.183, discriminator acc = 0.006\n",
      "Iteration 12399, source loss =  0.125, discriminator acc = 0.648\n",
      "Iteration 12499, source loss =  0.462, discriminator acc = 0.991\n",
      "Iteration 12599, source loss =  0.210, discriminator acc = 0.988\n",
      "Iteration 12699, source loss =  0.142, discriminator acc = 0.343\n",
      "Iteration 12799, source loss =  0.178, discriminator acc = 0.056\n",
      "Iteration 12899, source loss =  0.100, discriminator acc = 0.990\n",
      "Iteration 12999, source loss =  0.145, discriminator acc = 0.539\n",
      "Iteration 13099, source loss =  0.190, discriminator acc = 0.744\n",
      "Iteration 13199, source loss =  0.114, discriminator acc = 0.926\n",
      "Iteration 13299, source loss =  0.105, discriminator acc = 0.272\n",
      "Iteration 13399, source loss =  0.089, discriminator acc = 0.905\n",
      "Iteration 13499, source loss =  0.088, discriminator acc = 0.807\n",
      "Iteration 13599, source loss =  0.098, discriminator acc = 0.178\n",
      "Iteration 13699, source loss =  0.132, discriminator acc = 0.086\n",
      "Iteration 13799, source loss =  0.117, discriminator acc = 0.029\n",
      "Iteration 13899, source loss =  0.125, discriminator acc = 0.006\n",
      "Iteration 13999, source loss =  0.085, discriminator acc = 0.920\n",
      "Iteration 14099, source loss =  0.098, discriminator acc = 0.652\n",
      "Iteration 14199, source loss =  0.100, discriminator acc = 0.395\n",
      "Iteration 14299, source loss =  0.097, discriminator acc = 0.802\n",
      "Iteration 14399, source loss =  0.088, discriminator acc = 0.693\n",
      "Iteration 14499, source loss =  0.094, discriminator acc = 0.823\n",
      "Iteration 14599, source loss =  0.208, discriminator acc = 0.240\n",
      "Iteration 14699, source loss =  0.094, discriminator acc = 0.368\n",
      "Iteration 14799, source loss =  0.092, discriminator acc = 0.042\n",
      "Iteration 14899, source loss =  0.098, discriminator acc = 0.866\n",
      "Iteration 14999, source loss =  0.096, discriminator acc = 0.425\n",
      "PS seed: 234, model seed: 86322\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/86322\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 2s 15us/sample - loss: 0.1077 - mae: 0.0272\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0319 - mae: 0.0148\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0276 - mae: 0.0139\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0260 - mae: 0.0135\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0252 - mae: 0.0132\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0246 - mae: 0.0130\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0241 - mae: 0.0129\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0237 - mae: 0.0127\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0234 - mae: 0.0127\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0232 - mae: 0.0126\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02694155962407589\n",
      "0.02694155962407589\n",
      "Iteration 99, source loss =  1.267, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.442, discriminator acc = 0.501\n",
      "Iteration 299, source loss =  0.399, discriminator acc = 1.000\n",
      "Iteration 399, source loss =  0.310, discriminator acc = 0.587\n",
      "Iteration 499, source loss =  0.503, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.288, discriminator acc = 0.006\n",
      "Iteration 699, source loss =  0.197, discriminator acc = 0.006\n",
      "Iteration 799, source loss =  0.231, discriminator acc = 0.999\n",
      "Iteration 899, source loss =  0.200, discriminator acc = 0.672\n",
      "Iteration 999, source loss =  0.159, discriminator acc = 0.185\n",
      "Iteration 1099, source loss =  0.196, discriminator acc = 0.006\n",
      "Iteration 1199, source loss =  0.158, discriminator acc = 0.998\n",
      "Iteration 1299, source loss =  0.126, discriminator acc = 0.008\n",
      "Iteration 1399, source loss =  0.133, discriminator acc = 0.097\n",
      "Iteration 1499, source loss =  0.164, discriminator acc = 0.064\n",
      "Iteration 1599, source loss =  0.146, discriminator acc = 0.999\n",
      "Iteration 1699, source loss =  0.146, discriminator acc = 0.056\n",
      "Iteration 1799, source loss =  0.122, discriminator acc = 0.998\n",
      "Iteration 1899, source loss =  0.197, discriminator acc = 0.944\n",
      "Iteration 1999, source loss =  0.175, discriminator acc = 0.006\n",
      "Iteration 2099, source loss =  0.202, discriminator acc = 0.565\n",
      "Iteration 2199, source loss =  0.177, discriminator acc = 0.033\n",
      "Iteration 2299, source loss =  0.128, discriminator acc = 0.999\n",
      "Iteration 2399, source loss =  0.101, discriminator acc = 0.998\n",
      "Iteration 2499, source loss =  0.113, discriminator acc = 0.488\n",
      "Iteration 2599, source loss =  0.120, discriminator acc = 0.917\n",
      "Iteration 2699, source loss =  0.154, discriminator acc = 0.953\n",
      "Iteration 2799, source loss =  0.112, discriminator acc = 0.447\n",
      "Iteration 2899, source loss =  0.204, discriminator acc = 0.006\n",
      "Iteration 2999, source loss =  0.148, discriminator acc = 0.997\n",
      "Iteration 3099, source loss =  0.113, discriminator acc = 0.999\n",
      "Iteration 3199, source loss =  0.149, discriminator acc = 0.880\n",
      "Iteration 3299, source loss =  0.139, discriminator acc = 0.741\n",
      "Iteration 3399, source loss =  0.124, discriminator acc = 0.006\n",
      "Iteration 3499, source loss =  0.246, discriminator acc = 0.713\n",
      "Iteration 3599, source loss =  0.126, discriminator acc = 0.006\n",
      "Iteration 3699, source loss =  0.129, discriminator acc = 0.624\n",
      "Iteration 3799, source loss =  0.127, discriminator acc = 0.030\n",
      "Iteration 3899, source loss =  0.115, discriminator acc = 0.823\n",
      "Iteration 3999, source loss =  0.133, discriminator acc = 0.050\n",
      "Iteration 4099, source loss =  0.109, discriminator acc = 0.944\n",
      "Iteration 4199, source loss =  0.121, discriminator acc = 0.006\n",
      "Iteration 4299, source loss =  0.130, discriminator acc = 0.193\n",
      "Iteration 4399, source loss =  0.107, discriminator acc = 0.007\n",
      "Iteration 4499, source loss =  0.135, discriminator acc = 0.006\n",
      "Iteration 4599, source loss =  0.136, discriminator acc = 0.116\n",
      "Iteration 4699, source loss =  0.115, discriminator acc = 0.997\n",
      "Iteration 4799, source loss =  0.153, discriminator acc = 0.565\n",
      "Iteration 4899, source loss =  0.131, discriminator acc = 0.012\n",
      "Iteration 4999, source loss =  0.111, discriminator acc = 0.996\n",
      "Iteration 5099, source loss =  0.143, discriminator acc = 0.684\n",
      "Iteration 5199, source loss =  0.112, discriminator acc = 0.997\n",
      "Iteration 5299, source loss =  0.154, discriminator acc = 0.007\n",
      "Iteration 5399, source loss =  0.114, discriminator acc = 0.956\n",
      "Iteration 5499, source loss =  0.126, discriminator acc = 0.999\n",
      "Iteration 5599, source loss =  0.111, discriminator acc = 0.007\n",
      "Iteration 5699, source loss =  0.154, discriminator acc = 0.011\n",
      "Iteration 5799, source loss =  0.131, discriminator acc = 0.912\n",
      "Iteration 5899, source loss =  0.178, discriminator acc = 0.519\n",
      "Iteration 5999, source loss =  0.108, discriminator acc = 0.994\n",
      "Iteration 6099, source loss =  0.116, discriminator acc = 0.562\n",
      "Iteration 6199, source loss =  0.138, discriminator acc = 0.948\n",
      "Iteration 6299, source loss =  0.105, discriminator acc = 0.997\n",
      "Iteration 6399, source loss =  0.193, discriminator acc = 0.219\n",
      "Iteration 6499, source loss =  0.221, discriminator acc = 0.006\n",
      "Iteration 6599, source loss =  0.144, discriminator acc = 0.038\n",
      "Iteration 6699, source loss =  0.180, discriminator acc = 1.000\n",
      "Iteration 6799, source loss =  0.122, discriminator acc = 0.006\n",
      "Iteration 6899, source loss =  0.114, discriminator acc = 0.996\n",
      "Iteration 6999, source loss =  0.127, discriminator acc = 0.998\n",
      "Iteration 7099, source loss =  0.099, discriminator acc = 0.673\n",
      "Iteration 7199, source loss =  0.107, discriminator acc = 0.963\n",
      "Iteration 7299, source loss =  0.099, discriminator acc = 0.942\n",
      "Iteration 7399, source loss =  0.112, discriminator acc = 0.775\n",
      "Iteration 7499, source loss =  0.113, discriminator acc = 0.972\n",
      "Iteration 7599, source loss =  0.098, discriminator acc = 0.050\n",
      "Iteration 7699, source loss =  0.097, discriminator acc = 0.694\n",
      "Iteration 7799, source loss =  0.105, discriminator acc = 0.031\n",
      "Iteration 7899, source loss =  0.113, discriminator acc = 0.487\n",
      "Iteration 7999, source loss =  0.110, discriminator acc = 0.421\n",
      "Iteration 8099, source loss =  0.101, discriminator acc = 0.065\n",
      "Iteration 8199, source loss =  0.109, discriminator acc = 0.610\n",
      "Iteration 8299, source loss =  0.093, discriminator acc = 0.985\n",
      "Iteration 8399, source loss =  0.105, discriminator acc = 0.997\n",
      "Iteration 8499, source loss =  0.206, discriminator acc = 0.969\n",
      "Iteration 8599, source loss =  0.119, discriminator acc = 0.889\n",
      "Iteration 8699, source loss =  0.108, discriminator acc = 0.979\n",
      "Iteration 8799, source loss =  0.096, discriminator acc = 0.970\n",
      "Iteration 8899, source loss =  0.139, discriminator acc = 0.998\n",
      "Iteration 8999, source loss =  0.111, discriminator acc = 0.894\n",
      "Iteration 9099, source loss =  0.098, discriminator acc = 0.999\n",
      "Iteration 9199, source loss =  0.101, discriminator acc = 0.956\n",
      "Iteration 9299, source loss =  0.174, discriminator acc = 0.009\n",
      "Iteration 9399, source loss =  0.127, discriminator acc = 0.012\n",
      "Iteration 9499, source loss =  0.095, discriminator acc = 0.726\n",
      "Iteration 9599, source loss =  0.131, discriminator acc = 0.232\n",
      "Iteration 9699, source loss =  0.098, discriminator acc = 0.928\n",
      "Iteration 9799, source loss =  0.091, discriminator acc = 0.947\n",
      "Iteration 9899, source loss =  0.090, discriminator acc = 0.140\n",
      "Iteration 9999, source loss =  0.094, discriminator acc = 0.047\n",
      "Iteration 10099, source loss =  0.095, discriminator acc = 0.992\n",
      "Iteration 10199, source loss =  0.092, discriminator acc = 0.197\n",
      "Iteration 10299, source loss =  0.090, discriminator acc = 0.960\n",
      "Iteration 10399, source loss =  0.090, discriminator acc = 0.660\n",
      "Iteration 10499, source loss =  0.095, discriminator acc = 0.908\n",
      "Iteration 10599, source loss =  0.114, discriminator acc = 0.366\n",
      "Iteration 10699, source loss =  0.098, discriminator acc = 0.904\n",
      "Iteration 10799, source loss =  0.097, discriminator acc = 0.813\n",
      "Iteration 10899, source loss =  0.092, discriminator acc = 0.751\n",
      "Iteration 10999, source loss =  0.127, discriminator acc = 0.006\n",
      "Iteration 11099, source loss =  0.114, discriminator acc = 0.165\n",
      "Iteration 11199, source loss =  0.089, discriminator acc = 0.750\n",
      "Iteration 11299, source loss =  0.104, discriminator acc = 0.025\n",
      "Iteration 11399, source loss =  0.125, discriminator acc = 0.025\n",
      "Iteration 11499, source loss =  0.110, discriminator acc = 0.131\n",
      "Iteration 11599, source loss =  0.090, discriminator acc = 0.166\n",
      "Iteration 11699, source loss =  0.096, discriminator acc = 0.775\n",
      "Iteration 11799, source loss =  0.119, discriminator acc = 0.984\n",
      "Iteration 11899, source loss =  0.113, discriminator acc = 0.245\n",
      "Iteration 11999, source loss =  0.127, discriminator acc = 0.996\n",
      "Iteration 12099, source loss =  0.104, discriminator acc = 0.780\n",
      "Iteration 12199, source loss =  0.138, discriminator acc = 0.984\n",
      "Iteration 12299, source loss =  0.213, discriminator acc = 0.006\n",
      "Iteration 12399, source loss =  0.130, discriminator acc = 0.019\n",
      "Iteration 12499, source loss =  0.106, discriminator acc = 0.999\n",
      "Iteration 12599, source loss =  0.180, discriminator acc = 0.998\n",
      "Iteration 12699, source loss =  0.138, discriminator acc = 0.790\n",
      "Iteration 12799, source loss =  0.112, discriminator acc = 0.925\n",
      "Iteration 12899, source loss =  0.131, discriminator acc = 0.887\n",
      "Iteration 12999, source loss =  0.091, discriminator acc = 0.023\n",
      "Iteration 13099, source loss =  0.090, discriminator acc = 0.452\n",
      "Iteration 13199, source loss =  0.088, discriminator acc = 0.975\n",
      "Iteration 13299, source loss =  0.094, discriminator acc = 0.808\n",
      "Iteration 13399, source loss =  0.088, discriminator acc = 0.429\n",
      "Iteration 13499, source loss =  0.089, discriminator acc = 0.235\n",
      "Iteration 13599, source loss =  0.087, discriminator acc = 0.557\n",
      "Iteration 13699, source loss =  0.087, discriminator acc = 0.349\n",
      "Iteration 13799, source loss =  0.085, discriminator acc = 0.301\n",
      "Iteration 13899, source loss =  0.087, discriminator acc = 0.865\n",
      "Iteration 13999, source loss =  0.094, discriminator acc = 0.641\n",
      "Iteration 14099, source loss =  0.088, discriminator acc = 0.120\n",
      "Iteration 14199, source loss =  0.099, discriminator acc = 0.041\n",
      "Iteration 14299, source loss =  0.088, discriminator acc = 0.725\n",
      "Iteration 14399, source loss =  0.087, discriminator acc = 0.714\n",
      "Iteration 14499, source loss =  0.149, discriminator acc = 0.339\n",
      "Iteration 14599, source loss =  0.089, discriminator acc = 0.514\n",
      "Iteration 14699, source loss =  0.128, discriminator acc = 0.725\n",
      "Iteration 14799, source loss =  0.112, discriminator acc = 0.137\n",
      "Iteration 14899, source loss =  0.089, discriminator acc = 0.846\n",
      "Iteration 14999, source loss =  0.117, discriminator acc = 0.913\n",
      "PS seed: 98098, model seed: 98237\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/98237\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 15us/sample - loss: 0.1118 - mae: 0.0276\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0327 - mae: 0.0150\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0277 - mae: 0.0140\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0261 - mae: 0.0135\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 14us/sample - loss: 0.0252 - mae: 0.0133\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 2s 20us/sample - loss: 0.0246 - mae: 0.0131\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0242 - mae: 0.0130\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0238 - mae: 0.0128\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0234 - mae: 0.0127\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0232 - mae: 0.0126\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02675807018876076\n",
      "0.02675807018876076\n",
      "Iteration 99, source loss =  1.344, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.348, discriminator acc = 0.945\n",
      "Iteration 299, source loss =  0.523, discriminator acc = 1.000\n",
      "Iteration 399, source loss =  0.198, discriminator acc = 0.990\n",
      "Iteration 499, source loss =  0.615, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.223, discriminator acc = 1.000\n",
      "Iteration 699, source loss =  0.279, discriminator acc = 0.053\n",
      "Iteration 799, source loss =  0.205, discriminator acc = 0.103\n",
      "Iteration 899, source loss =  0.152, discriminator acc = 0.006\n",
      "Iteration 999, source loss =  0.167, discriminator acc = 0.871\n",
      "Iteration 1099, source loss =  0.153, discriminator acc = 0.156\n",
      "Iteration 1199, source loss =  0.212, discriminator acc = 0.355\n",
      "Iteration 1299, source loss =  0.266, discriminator acc = 0.006\n",
      "Iteration 1399, source loss =  0.188, discriminator acc = 1.000\n",
      "Iteration 1499, source loss =  0.154, discriminator acc = 0.214\n",
      "Iteration 1599, source loss =  0.139, discriminator acc = 1.000\n",
      "Iteration 1699, source loss =  0.147, discriminator acc = 0.164\n",
      "Iteration 1799, source loss =  0.158, discriminator acc = 0.971\n",
      "Iteration 1899, source loss =  0.106, discriminator acc = 0.998\n",
      "Iteration 1999, source loss =  0.132, discriminator acc = 0.003\n",
      "Iteration 2099, source loss =  0.109, discriminator acc = 0.972\n",
      "Iteration 2199, source loss =  0.117, discriminator acc = 0.993\n",
      "Iteration 2299, source loss =  0.142, discriminator acc = 0.726\n",
      "Iteration 2399, source loss =  0.134, discriminator acc = 0.171\n",
      "Iteration 2499, source loss =  0.223, discriminator acc = 0.700\n",
      "Iteration 2599, source loss =  0.139, discriminator acc = 0.012\n",
      "Iteration 2699, source loss =  0.104, discriminator acc = 1.000\n",
      "Iteration 2799, source loss =  0.174, discriminator acc = 0.958\n",
      "Iteration 2899, source loss =  0.107, discriminator acc = 0.392\n",
      "Iteration 2999, source loss =  0.118, discriminator acc = 0.541\n",
      "Iteration 3099, source loss =  0.124, discriminator acc = 0.406\n",
      "Iteration 3199, source loss =  0.148, discriminator acc = 0.137\n",
      "Iteration 3299, source loss =  0.257, discriminator acc = 0.007\n",
      "Iteration 3399, source loss =  0.128, discriminator acc = 0.177\n",
      "Iteration 3499, source loss =  0.181, discriminator acc = 0.773\n",
      "Iteration 3599, source loss =  0.122, discriminator acc = 0.910\n",
      "Iteration 3699, source loss =  0.113, discriminator acc = 0.013\n",
      "Iteration 3799, source loss =  0.126, discriminator acc = 0.996\n",
      "Iteration 3899, source loss =  0.129, discriminator acc = 0.609\n",
      "Iteration 3999, source loss =  0.179, discriminator acc = 0.006\n",
      "Iteration 4099, source loss =  0.121, discriminator acc = 0.918\n",
      "Iteration 4199, source loss =  0.156, discriminator acc = 1.000\n",
      "Iteration 4299, source loss =  0.139, discriminator acc = 0.817\n",
      "Iteration 4399, source loss =  0.126, discriminator acc = 0.460\n",
      "Iteration 4499, source loss =  0.117, discriminator acc = 1.000\n",
      "Iteration 4599, source loss =  0.107, discriminator acc = 0.942\n",
      "Iteration 4699, source loss =  0.110, discriminator acc = 0.998\n",
      "Iteration 4799, source loss =  0.114, discriminator acc = 1.000\n",
      "Iteration 4899, source loss =  0.113, discriminator acc = 0.391\n",
      "Iteration 4999, source loss =  0.162, discriminator acc = 0.955\n",
      "Iteration 5099, source loss =  0.142, discriminator acc = 0.967\n",
      "Iteration 5199, source loss =  0.100, discriminator acc = 0.341\n",
      "Iteration 5299, source loss =  0.101, discriminator acc = 0.999\n",
      "Iteration 5399, source loss =  0.188, discriminator acc = 0.022\n",
      "Iteration 5499, source loss =  0.114, discriminator acc = 1.000\n",
      "Iteration 5599, source loss =  0.109, discriminator acc = 0.911\n",
      "Iteration 5699, source loss =  0.124, discriminator acc = 0.994\n",
      "Iteration 5799, source loss =  0.130, discriminator acc = 0.419\n",
      "Iteration 5899, source loss =  0.113, discriminator acc = 0.231\n",
      "Iteration 5999, source loss =  0.235, discriminator acc = 0.008\n",
      "Iteration 6099, source loss =  0.122, discriminator acc = 0.991\n",
      "Iteration 6199, source loss =  0.176, discriminator acc = 0.978\n",
      "Iteration 6299, source loss =  0.156, discriminator acc = 0.876\n",
      "Iteration 6399, source loss =  0.201, discriminator acc = 0.999\n",
      "Iteration 6499, source loss =  0.136, discriminator acc = 0.006\n",
      "Iteration 6599, source loss =  0.124, discriminator acc = 0.981\n",
      "Iteration 6699, source loss =  0.097, discriminator acc = 0.413\n",
      "Iteration 6799, source loss =  0.125, discriminator acc = 0.725\n",
      "Iteration 6899, source loss =  0.091, discriminator acc = 0.999\n",
      "Iteration 6999, source loss =  0.102, discriminator acc = 0.067\n",
      "Iteration 7099, source loss =  0.096, discriminator acc = 0.449\n",
      "Iteration 7199, source loss =  0.088, discriminator acc = 0.961\n",
      "Iteration 7299, source loss =  0.102, discriminator acc = 0.902\n",
      "Iteration 7399, source loss =  0.142, discriminator acc = 0.071\n",
      "Iteration 7499, source loss =  0.089, discriminator acc = 0.527\n",
      "Iteration 7599, source loss =  0.098, discriminator acc = 0.725\n",
      "Iteration 7699, source loss =  0.090, discriminator acc = 0.494\n",
      "Iteration 7799, source loss =  0.100, discriminator acc = 0.862\n",
      "Iteration 7899, source loss =  0.117, discriminator acc = 0.984\n",
      "Iteration 7999, source loss =  0.106, discriminator acc = 0.245\n",
      "Iteration 8099, source loss =  0.110, discriminator acc = 0.260\n",
      "Iteration 8199, source loss =  0.178, discriminator acc = 0.073\n",
      "Iteration 8299, source loss =  0.142, discriminator acc = 0.999\n",
      "Iteration 8399, source loss =  0.126, discriminator acc = 0.798\n",
      "Iteration 8499, source loss =  0.262, discriminator acc = 0.925\n",
      "Iteration 8599, source loss =  0.101, discriminator acc = 0.699\n",
      "Iteration 8699, source loss =  0.237, discriminator acc = 0.015\n",
      "Iteration 8799, source loss =  0.183, discriminator acc = 0.979\n",
      "Iteration 8899, source loss =  0.153, discriminator acc = 0.019\n",
      "Iteration 8999, source loss =  0.150, discriminator acc = 0.503\n",
      "Iteration 9099, source loss =  0.116, discriminator acc = 0.895\n",
      "Iteration 9199, source loss =  0.101, discriminator acc = 0.854\n",
      "Iteration 9299, source loss =  0.132, discriminator acc = 0.770\n",
      "Iteration 9399, source loss =  0.192, discriminator acc = 0.993\n",
      "Iteration 9499, source loss =  0.103, discriminator acc = 0.864\n",
      "Iteration 9599, source loss =  0.105, discriminator acc = 0.093\n",
      "Iteration 9699, source loss =  0.107, discriminator acc = 0.104\n",
      "Iteration 9799, source loss =  0.093, discriminator acc = 0.903\n",
      "Iteration 9899, source loss =  0.134, discriminator acc = 0.970\n",
      "Iteration 9999, source loss =  0.105, discriminator acc = 0.700\n",
      "Iteration 10099, source loss =  0.166, discriminator acc = 0.994\n",
      "Iteration 10199, source loss =  0.099, discriminator acc = 0.006\n",
      "Iteration 10299, source loss =  0.104, discriminator acc = 0.156\n",
      "Iteration 10399, source loss =  0.231, discriminator acc = 0.033\n",
      "Iteration 10499, source loss =  0.133, discriminator acc = 0.247\n",
      "Iteration 10599, source loss =  0.092, discriminator acc = 0.731\n",
      "Iteration 10699, source loss =  0.158, discriminator acc = 0.690\n",
      "Iteration 10799, source loss =  0.128, discriminator acc = 0.131\n",
      "Iteration 10899, source loss =  0.113, discriminator acc = 0.258\n",
      "Iteration 10999, source loss =  0.113, discriminator acc = 0.337\n",
      "Iteration 11099, source loss =  0.098, discriminator acc = 0.959\n",
      "Iteration 11199, source loss =  0.115, discriminator acc = 0.015\n",
      "Iteration 11299, source loss =  0.186, discriminator acc = 0.041\n",
      "Iteration 11399, source loss =  0.095, discriminator acc = 0.338\n",
      "Iteration 11499, source loss =  0.088, discriminator acc = 0.668\n",
      "Iteration 11599, source loss =  0.098, discriminator acc = 0.055\n",
      "Iteration 11699, source loss =  0.096, discriminator acc = 0.740\n",
      "Iteration 11799, source loss =  0.137, discriminator acc = 0.819\n",
      "Iteration 11899, source loss =  0.178, discriminator acc = 0.615\n",
      "Iteration 11999, source loss =  0.095, discriminator acc = 0.533\n",
      "Iteration 12099, source loss =  0.128, discriminator acc = 0.334\n",
      "Iteration 12199, source loss =  0.101, discriminator acc = 0.204\n",
      "Iteration 12299, source loss =  0.095, discriminator acc = 0.997\n",
      "Iteration 12399, source loss =  0.089, discriminator acc = 0.766\n",
      "Iteration 12499, source loss =  0.093, discriminator acc = 0.361\n",
      "Iteration 12599, source loss =  0.089, discriminator acc = 0.662\n",
      "Iteration 12699, source loss =  0.092, discriminator acc = 0.006\n",
      "Iteration 12799, source loss =  0.088, discriminator acc = 0.899\n",
      "Iteration 12899, source loss =  0.087, discriminator acc = 0.386\n",
      "Iteration 12999, source loss =  0.085, discriminator acc = 0.414\n",
      "Iteration 13099, source loss =  0.086, discriminator acc = 0.605\n",
      "Iteration 13199, source loss =  0.087, discriminator acc = 0.368\n",
      "Iteration 13299, source loss =  0.087, discriminator acc = 0.793\n",
      "Iteration 13399, source loss =  0.089, discriminator acc = 0.867\n",
      "Iteration 13499, source loss =  0.085, discriminator acc = 0.856\n",
      "Iteration 13599, source loss =  0.085, discriminator acc = 0.733\n",
      "Iteration 13699, source loss =  0.087, discriminator acc = 0.618\n",
      "Iteration 13799, source loss =  0.088, discriminator acc = 0.613\n",
      "Iteration 13899, source loss =  0.085, discriminator acc = 0.492\n",
      "Iteration 13999, source loss =  0.082, discriminator acc = 0.531\n",
      "Iteration 14099, source loss =  0.084, discriminator acc = 0.808\n",
      "Iteration 14199, source loss =  0.086, discriminator acc = 0.370\n",
      "Iteration 14299, source loss =  0.086, discriminator acc = 0.943\n",
      "Iteration 14399, source loss =  0.087, discriminator acc = 0.861\n",
      "Iteration 14499, source loss =  0.147, discriminator acc = 0.931\n",
      "Iteration 14599, source loss =  0.114, discriminator acc = 0.003\n",
      "Iteration 14699, source loss =  0.137, discriminator acc = 0.291\n",
      "Iteration 14799, source loss =  0.130, discriminator acc = 0.510\n",
      "Iteration 14899, source loss =  0.490, discriminator acc = 0.008\n",
      "Iteration 14999, source loss =  0.105, discriminator acc = 0.993\n"
     ]
    }
   ],
   "source": [
    "def train(ps_seed, model_seed):\n",
    "    print(f\"PS seed: {ps_seed}, model seed: {model_seed}\")\n",
    "\n",
    "    model_folder = data_loading.get_model_rel_path(\n",
    "        MODEL_NAME,\n",
    "        model_params[\"model_version\"],\n",
    "        lib_seed_path=str(model_seed),\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    model_folder = os.path.join(MODEL_DIR, model_folder)\n",
    "    if not os.path.isdir(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "        print(model_folder)\n",
    "        \n",
    "    selected_dir = data_loading.get_selected_dir(\n",
    "        data_loading.get_dset_dir(\n",
    "            data_params[\"data_dir\"],\n",
    "            dset=data_params.get(\"dset\", \"dlpfc\"),\n",
    "        ),\n",
    "        **data_params,\n",
    "    )\n",
    "    # Load spatial data\n",
    "    mat_sp_d, mat_sp_meta_d, st_sample_id_l = data_loading.load_spatial(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    # Load sc data\n",
    "    sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = data_loading.load_sc(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "        seed_int=ps_seed,\n",
    "    )\n",
    "\n",
    "    target_d = {}\n",
    "    if \"train\" in mat_sp_d:\n",
    "        # keys of dict are splits\n",
    "        for split in mat_sp_d:\n",
    "            target_d[split] = np.concatenate(list(mat_sp_d[split].values()))\n",
    "    else:\n",
    "        # keys of subdicts are splits\n",
    "        for split in next(iter(mat_sp_d.values())):\n",
    "            target_d[split] = np.concatenate((v[split] for v in mat_sp_d.values()))\n",
    "\n",
    "\n",
    "    advtrain_folder = os.path.join(model_folder, \"advtrain\")\n",
    "    pretrain_folder = os.path.join(model_folder, \"pretrain\")\n",
    "    if not os.path.isdir(advtrain_folder):\n",
    "        os.makedirs(advtrain_folder)\n",
    "    if not os.path.isdir(pretrain_folder):\n",
    "        os.makedirs(pretrain_folder)\n",
    "\n",
    "    if data_params.get(\"samp_split\"):\n",
    "        tqdm.write(f\"Adversarial training for slides {mat_sp_d['train'].keys()}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"samp_split\")\n",
    "    else:\n",
    "        tqdm.write(f\"Adversarial training for slides {next(iter(mat_sp_d.keys()))}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"one_model\")\n",
    "\n",
    "    if not os.path.isdir(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    embs, embs_noda, clssmodel, clssmodel_noda = da_cellfraction.train(\n",
    "        sc_mix_d[\"train\"],\n",
    "        lab_mix_d[\"train\"],\n",
    "        target_d[\"train\"],\n",
    "        alpha=train_params.get(\"alpha\", 0.6),\n",
    "        alpha_lr=train_params.get(\"alpha_lr\", 5),\n",
    "        emb_dim=model_params[\"celldart_kwargs\"].get(\"emb_dim\", 64),\n",
    "        batch_size=train_params.get(\"batch_size\", 512),\n",
    "        n_iterations=train_params.get(\"n_iter\", 3000),\n",
    "        initial_train=train_params.get(\"pretraining\", True),\n",
    "        initial_train_epochs=train_params.get(\"initial_train_epochs\", 10),\n",
    "        batch_size_initial_train=max(train_params.get(\"batch_size\", 512), 512),\n",
    "        bn_momentum=1-config[\"model_params\"].get(\"bn_momentum\", 0.01),\n",
    "        seed=model_seed,\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "\n",
    "    if not os.path.isdir(os.path.join(save_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(save_folder, \"final_model\"))\n",
    "    if not os.path.isdir(os.path.join(pretrain_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(pretrain_folder, \"final_model\"))\n",
    "\n",
    "    clssmodel_noda.save(os.path.join(pretrain_folder, \"final_model\", \"model\"))\n",
    "    clssmodel.save(os.path.join(save_folder, \"final_model\", \"model\"))\n",
    "\n",
    "    embs_noda.save(os.path.join(pretrain_folder, \"final_model\", \"embs\"))\n",
    "    embs.save(os.path.join(save_folder, \"final_model\", \"embs\"))\n",
    "\n",
    "    with open(os.path.join(model_folder, \"config.yml\"), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    train(ps_seed, model_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/2353 ...\n",
      "Loading Data\n",
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.012334   \n",
      "                                pdac_b                         0.012334   \n",
      "After DA (final model)          pdac_a                         0.077407   \n",
      "                                pdac_b                         0.077407   \n",
      "\n",
      "                                                                  RF50  \\\n",
      "                                                val      test    train   \n",
      "                       SC Split Sample ID                                \n",
      "Before DA                       pdac_a     0.013174  0.013555  0.99990   \n",
      "                                pdac_b     0.013174  0.013555  1.00000   \n",
      "After DA (final model)          pdac_a     0.078702  0.075747  0.99995   \n",
      "                                pdac_b     0.078702  0.075747  1.00000   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     0.9999  1.0000   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "After DA (final model)          pdac_a     1.0000  0.9999   \n",
      "                                pdac_b     1.0000  0.9999   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train       val   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                  1.000000  1.000000   \n",
      "                                pdac_b                  1.000000  1.000000   \n",
      "After DA (final model)          pdac_a                  1.045957  1.040889   \n",
      "                                pdac_b                  1.121117  1.121694   \n",
      "\n",
      "                                                     \\\n",
      "                                               test   \n",
      "                       SC Split Sample ID             \n",
      "Before DA                       pdac_a     1.000000   \n",
      "                                pdac_b     1.000000   \n",
      "After DA (final model)          pdac_a     1.042989   \n",
      "                                pdac_b     1.147939   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.507742  \n",
      "                                pdac_b                          0.469260  \n",
      "After DA (final model)          pdac_a                          0.554933  \n",
      "                                pdac_b                          0.478618  \n",
      "Script run time: 0:02:58.380487\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/24385 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.010409   \n",
      "                                pdac_b                         0.010409   \n",
      "After DA (final model)          pdac_a                         0.066852   \n",
      "                                pdac_b                         0.066852   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a     0.011425  0.011368  1.000000   \n",
      "                                pdac_b     0.011425  0.011368  1.000000   \n",
      "After DA (final model)          pdac_a     0.066778  0.067337  0.999925   \n",
      "                                pdac_b     0.066778  0.067337  0.999975   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     1.0000  1.0000   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "After DA (final model)          pdac_a     0.9997  0.9999   \n",
      "                                pdac_b     1.0000  0.9999   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train       val   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                  1.000000  1.000000   \n",
      "                                pdac_b                  1.000000  1.000000   \n",
      "After DA (final model)          pdac_a                  1.141848  1.156328   \n",
      "                                pdac_b                  1.088733  1.063140   \n",
      "\n",
      "                                                     \\\n",
      "                                               test   \n",
      "                       SC Split Sample ID             \n",
      "Before DA                       pdac_a     1.000000   \n",
      "                                pdac_b     1.000000   \n",
      "After DA (final model)          pdac_a     1.169520   \n",
      "                                pdac_b     1.075401   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.502724  \n",
      "                                pdac_b                          0.472165  \n",
      "After DA (final model)          pdac_a                          0.554812  \n",
      "                                pdac_b                          0.469157  \n",
      "Script run time: 0:03:09.881854\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/284 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.009832   \n",
      "                                pdac_b                         0.009832   \n",
      "After DA (final model)          pdac_a                         0.044209   \n",
      "                                pdac_b                         0.044209   \n",
      "\n",
      "                                                               RF50       \\\n",
      "                                                val      test train  val   \n",
      "                       SC Split Sample ID                                  \n",
      "Before DA                       pdac_a     0.010825  0.010928   1.0  1.0   \n",
      "                                pdac_b     0.010825  0.010928   1.0  1.0   \n",
      "After DA (final model)          pdac_a     0.044706  0.044132   1.0  1.0   \n",
      "                                pdac_b     0.044706  0.044132   1.0  1.0   \n",
      "\n",
      "                                                  miLISI (perplexity=30)  \\\n",
      "                                             test                  train   \n",
      "                       SC Split Sample ID                                  \n",
      "Before DA                       pdac_a     1.0000               1.000000   \n",
      "                                pdac_b     0.9998               1.000000   \n",
      "After DA (final model)          pdac_a     1.0000               1.180301   \n",
      "                                pdac_b     1.0000               1.135821   \n",
      "\n",
      "                                                               \\\n",
      "                                                val      test   \n",
      "                       SC Split Sample ID                       \n",
      "Before DA                       pdac_a     1.000000  1.000000   \n",
      "                                pdac_b     1.000000  1.000000   \n",
      "After DA (final model)          pdac_a     1.212240  1.212189   \n",
      "                                pdac_b     1.075411  1.109477   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.508537  \n",
      "                                pdac_b                          0.475684  \n",
      "After DA (final model)          pdac_a                          0.549952  \n",
      "                                pdac_b                          0.496586  \n",
      "Script run time: 0:03:39.673415\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/86322 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.010234   \n",
      "                                pdac_b                         0.010234   \n",
      "After DA (final model)          pdac_a                         0.065965   \n",
      "                                pdac_b                         0.065965   \n",
      "\n",
      "                                                                   RF50       \\\n",
      "                                                val      test     train  val   \n",
      "                       SC Split Sample ID                                      \n",
      "Before DA                       pdac_a     0.011132  0.011099  1.000000  1.0   \n",
      "                                pdac_b     0.011132  0.011099  1.000000  1.0   \n",
      "After DA (final model)          pdac_a     0.067465  0.064682  0.999975  1.0   \n",
      "                                pdac_b     0.067465  0.064682  1.000000  1.0   \n",
      "\n",
      "                                                  miLISI (perplexity=30)  \\\n",
      "                                             test                  train   \n",
      "                       SC Split Sample ID                                  \n",
      "Before DA                       pdac_a     1.0000               1.000000   \n",
      "                                pdac_b     1.0000               1.000000   \n",
      "After DA (final model)          pdac_a     0.9997               1.164214   \n",
      "                                pdac_b     1.0000               1.074802   \n",
      "\n",
      "                                                               \\\n",
      "                                                val      test   \n",
      "                       SC Split Sample ID                       \n",
      "Before DA                       pdac_a     1.000000  1.000000   \n",
      "                                pdac_b     1.000000  1.000000   \n",
      "After DA (final model)          pdac_a     1.191303  1.162661   \n",
      "                                pdac_b     1.083895  1.072306   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.507781  \n",
      "                                pdac_b                          0.470600  \n",
      "After DA (final model)          pdac_a                          0.567017  \n",
      "                                pdac_b                          0.485869  \n",
      "Script run time: 0:03:59.930481\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 50\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 3195139925\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.9\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-16798\n",
      "train_params:\n",
      "  alpha: 1.0\n",
      "  alpha_lr: 5\n",
      "  batch_size: 256\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/50mix_100000spots/minmax/gen_pdac-16798/98237 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.009917   \n",
      "                                pdac_b                         0.009917   \n",
      "After DA (final model)          pdac_a                         0.052353   \n",
      "                                pdac_b                         0.052353   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a     0.011289  0.011472  0.999975   \n",
      "                                pdac_b     0.011289  0.011472  0.999975   \n",
      "After DA (final model)          pdac_a     0.052857  0.052771  0.999225   \n",
      "                                pdac_b     0.052857  0.052771  1.000000   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     0.9999  1.0000   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "After DA (final model)          pdac_a     0.9989  0.9995   \n",
      "                                pdac_b     0.9998  1.0000   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                       1.0  1.0  1.0   \n",
      "                                pdac_b                       1.0  1.0  1.0   \n",
      "After DA (final model)          pdac_a                       1.0  1.0  1.0   \n",
      "                                pdac_b                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.515171  \n",
      "                                pdac_b                          0.467441  \n",
      "After DA (final model)          pdac_a                          0.551040  \n",
      "                                pdac_b                          0.489781  \n",
      "Script run time: 0:04:04.114351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "from src.da_models.model_utils.utils import get_metric_ctp\n",
    "from src.da_utils.evaluator import Evaluator\n",
    "\n",
    "\n",
    "metric_ctp = get_metric_ctp(\"cos\")\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    evaluator = Evaluator(vars(args), metric_ctp)\n",
    "    evaluator.eval_spots()\n",
    "    evaluator.evaluate_embeddings()\n",
    "    evaluator.eval_sc()\n",
    "\n",
    "    evaluator.produce_results()\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    if MODEL_SEED != \n",
    "    parser = argparse.ArgumentParser(description=\"Evaluates.\")\n",
    "    parser.add_argument(\"--pretraining\", \"-p\", action=\"store_true\", help=\"force pretraining\")\n",
    "    parser.add_argument(\"--modelname\", \"-n\", type=str, default=\"ADDA\", help=\"model name\")\n",
    "    parser.add_argument(\"--milisi\", \"-m\", action=\"store_false\", help=\"no milisi\")\n",
    "    parser.add_argument(\"--config_fname\", \"-f\", type=str, help=\"Name of the config file to use\")\n",
    "    parser.add_argument(\"--configs_dir\", \"-cdir\", type=str, default=\"configs\", help=\"config dir\")\n",
    "    parser.add_argument(\n",
    "        \"--njobs\", type=int, default=1, help=\"Number of jobs to use for parallel processing.\"\n",
    "    )\n",
    "    parser.add_argument(\"--cuda\", \"-c\", default=None, help=\"GPU index to use\")\n",
    "    parser.add_argument(\"--tmpdir\", \"-d\", default=None, help=\"optional temporary results directory\")\n",
    "    parser.add_argument(\"--test\", \"-t\", action=\"store_true\", help=\"test mode\")\n",
    "    parser.add_argument(\n",
    "        \"--early_stopping\",\n",
    "        \"-e\",\n",
    "        action=\"store_true\",\n",
    "        help=\"evaluate early stopping. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reverse_val\",\n",
    "        \"-r\",\n",
    "        action=\"store_true\",\n",
    "        help=\"use best model through reverse validation. Will use provided\"\n",
    "        \"config file to search across models, then use the one loaded. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\"--model_dir\", default=\"model\", help=\"model directory\")\n",
    "    parser.add_argument(\"--results_dir\", default=\"results\", help=\"results directory\")\n",
    "    parser.add_argument(\n",
    "        \"--seed_override\",\n",
    "        default=None,\n",
    "        help=\"seed to use for torch and numpy; overrides that in config file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ps_seed\",\n",
    "        default=-1,\n",
    "        help=\"specific pseudospot seed to use; default of -1 corresponds to 623\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args([\n",
    "        f\"--modelname={MODEL_NAME}\",\n",
    "        f\"--config_fname={CONFIG_FNAME}\",\n",
    "        \"--njobs=8\",\n",
    "        \"--test\",\n",
    "        f\"--model_dir={MODEL_DIR}\",\n",
    "        \"--results_dir=results_FINAL\",\n",
    "        f\"--seed_override={model_seed}\",\n",
    "        f\"--ps_seed={ps_seed}\"\n",
    "    ])\n",
    "\n",
    "    script_start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        level=logging.WARNING,\n",
    "        format=\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\",\n",
    "    )\n",
    "    main(args)\n",
    "    print(\"Script run time:\", datetime.datetime.now(datetime.timezone.utc) - script_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellDART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
