{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellDART Example Code: mouse brain \n",
    "## (10x Visium of anterior mouse brain + scRNA-seq data of mouse brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5646/3903643673.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf  # TensorFlow registers PluggableDevices here.\n",
    "from tqdm.autonotebook import tqdm\n",
    "import yaml\n",
    "\n",
    "from CellDART import da_cellfraction\n",
    "from src.da_utils import data_loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_SEEDS = (3679, 343, 25, 234, 98098)\n",
    "MODEL_SEEDS = (2353, 24385, 284, 86322, 98237)\n",
    "MODEL_DIR = \"model_FINAL\"\n",
    "SEED_OVERRIDE = None\n",
    "\n",
    "CONFIGS_DIR = \"configs\"\n",
    "CONFIG_FNAME = \"basic_config.yml\"\n",
    "\n",
    "# BOOTSTRAP = False\n",
    "# BOOTSTRAP_ROUNDS = 10\n",
    "# BOOTSTRAP_ALPHAS = [0.6, 1 / 0.6]\n",
    "\n",
    "MODEL_NAME = \"CellDART_original\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lib_params = config[\"lib_params\"]\n",
    "data_params = config[\"data_params\"]\n",
    "model_params = config[\"model_params\"]\n",
    "train_params = config[\"train_params\"]\n",
    "\n",
    "rewrite_config = False\n",
    "if not \"pretraining\" in train_params:\n",
    "    train_params[\"pretraining\"] = True\n",
    "    rewrite_config = True\n",
    "if not \"lr\" in train_params:\n",
    "    train_params[\"lr\"] = 0.001\n",
    "    rewrite_config = True\n",
    "\n",
    "if rewrite_config:\n",
    "    with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "tqdm.write(yaml.safe_dump(config))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load\n",
    "### load scanpy data - 10x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS seed: 3679, model seed: 2353\n",
      "Adversarial training for slides dict_keys(['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151674', '151676']): \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 3s 26us/sample - loss: 0.8027 - mae: 0.0271\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.5745 - mae: 0.0219\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.5421 - mae: 0.0210\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.5219 - mae: 0.0204\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 14us/sample - loss: 0.5062 - mae: 0.0200\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4910 - mae: 0.0196\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.4762 - mae: 0.0192\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.4619 - mae: 0.0188\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4489 - mae: 0.0184\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.4351 - mae: 0.0181\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5752687343978882\n",
      "0.5752687343978882\n",
      "Iteration 99, source loss =  4.386, discriminator acc = 0.288\n",
      "Iteration 199, source loss =  2.327, discriminator acc = 0.135\n",
      "Iteration 299, source loss =  1.637, discriminator acc = 0.574\n",
      "Iteration 399, source loss =  1.921, discriminator acc = 0.682\n",
      "Iteration 499, source loss =  1.555, discriminator acc = 0.774\n",
      "Iteration 599, source loss =  1.310, discriminator acc = 0.836\n",
      "Iteration 699, source loss =  1.287, discriminator acc = 0.974\n",
      "Iteration 799, source loss =  1.142, discriminator acc = 0.966\n",
      "Iteration 899, source loss =  1.268, discriminator acc = 0.475\n",
      "Iteration 999, source loss =  0.970, discriminator acc = 0.790\n",
      "Iteration 1099, source loss =  1.010, discriminator acc = 0.481\n",
      "Iteration 1199, source loss =  0.866, discriminator acc = 0.865\n",
      "Iteration 1299, source loss =  0.760, discriminator acc = 0.942\n",
      "Iteration 1399, source loss =  0.879, discriminator acc = 0.984\n",
      "Iteration 1499, source loss =  0.730, discriminator acc = 0.713\n",
      "Iteration 1599, source loss =  0.706, discriminator acc = 0.474\n",
      "Iteration 1699, source loss =  0.911, discriminator acc = 0.420\n",
      "Iteration 1799, source loss =  0.641, discriminator acc = 0.916\n",
      "Iteration 1899, source loss =  0.679, discriminator acc = 0.956\n",
      "Iteration 1999, source loss =  0.658, discriminator acc = 0.617\n",
      "Iteration 2099, source loss =  0.696, discriminator acc = 0.118\n",
      "Iteration 2199, source loss =  0.830, discriminator acc = 0.300\n",
      "Iteration 2299, source loss =  0.625, discriminator acc = 0.900\n",
      "Iteration 2399, source loss =  0.679, discriminator acc = 0.983\n",
      "Iteration 2499, source loss =  0.683, discriminator acc = 0.854\n",
      "Iteration 2599, source loss =  0.923, discriminator acc = 0.265\n",
      "Iteration 2699, source loss =  1.007, discriminator acc = 0.068\n",
      "Iteration 2799, source loss =  1.475, discriminator acc = 0.142\n",
      "Iteration 2899, source loss =  0.740, discriminator acc = 0.573\n",
      "Iteration 2999, source loss =  0.819, discriminator acc = 0.370\n",
      "Iteration 3099, source loss =  0.946, discriminator acc = 0.214\n",
      "Iteration 3199, source loss =  1.451, discriminator acc = 0.201\n",
      "Iteration 3299, source loss =  0.835, discriminator acc = 0.851\n",
      "Iteration 3399, source loss =  0.880, discriminator acc = 0.966\n",
      "Iteration 3499, source loss =  0.919, discriminator acc = 0.473\n",
      "Iteration 3599, source loss =  0.931, discriminator acc = 0.997\n",
      "Iteration 3699, source loss =  0.811, discriminator acc = 0.992\n",
      "Iteration 3799, source loss =  1.046, discriminator acc = 0.330\n",
      "Iteration 3899, source loss =  1.149, discriminator acc = 0.363\n",
      "Iteration 3999, source loss =  1.070, discriminator acc = 0.169\n",
      "Iteration 4099, source loss =  1.189, discriminator acc = 0.284\n",
      "Iteration 4199, source loss =  0.865, discriminator acc = 0.957\n",
      "Iteration 4299, source loss =  0.919, discriminator acc = 0.727\n",
      "Iteration 4399, source loss =  1.228, discriminator acc = 0.791\n",
      "Iteration 4499, source loss =  1.143, discriminator acc = 0.630\n",
      "Iteration 4599, source loss =  0.969, discriminator acc = 0.331\n",
      "Iteration 4699, source loss =  0.976, discriminator acc = 0.973\n",
      "Iteration 4799, source loss =  1.219, discriminator acc = 0.299\n",
      "Iteration 4899, source loss =  1.144, discriminator acc = 0.984\n",
      "Iteration 4999, source loss =  1.270, discriminator acc = 0.289\n",
      "Iteration 5099, source loss =  0.990, discriminator acc = 0.941\n",
      "Iteration 5199, source loss =  1.197, discriminator acc = 0.369\n",
      "Iteration 5299, source loss =  1.068, discriminator acc = 0.878\n",
      "Iteration 5399, source loss =  1.241, discriminator acc = 0.904\n",
      "Iteration 5499, source loss =  1.098, discriminator acc = 0.381\n",
      "Iteration 5599, source loss =  0.915, discriminator acc = 0.948\n",
      "Iteration 5699, source loss =  1.500, discriminator acc = 0.285\n",
      "Iteration 5799, source loss =  0.961, discriminator acc = 0.880\n",
      "Iteration 5899, source loss =  1.088, discriminator acc = 0.437\n",
      "Iteration 5999, source loss =  0.920, discriminator acc = 0.742\n",
      "Iteration 6099, source loss =  1.013, discriminator acc = 0.580\n",
      "Iteration 6199, source loss =  0.940, discriminator acc = 0.913\n",
      "Iteration 6299, source loss =  0.898, discriminator acc = 0.993\n",
      "Iteration 6399, source loss =  0.900, discriminator acc = 0.526\n",
      "Iteration 6499, source loss =  0.856, discriminator acc = 0.915\n",
      "Iteration 6599, source loss =  0.775, discriminator acc = 0.999\n",
      "Iteration 6699, source loss =  0.849, discriminator acc = 0.909\n",
      "Iteration 6799, source loss =  0.889, discriminator acc = 0.822\n",
      "Iteration 6899, source loss =  0.895, discriminator acc = 0.320\n",
      "Iteration 6999, source loss =  0.906, discriminator acc = 0.674\n",
      "Iteration 7099, source loss =  0.939, discriminator acc = 0.850\n",
      "Iteration 7199, source loss =  0.911, discriminator acc = 0.594\n",
      "Iteration 7299, source loss =  1.116, discriminator acc = 0.510\n",
      "Iteration 7399, source loss =  0.904, discriminator acc = 0.290\n",
      "Iteration 7499, source loss =  0.906, discriminator acc = 0.983\n",
      "Iteration 7599, source loss =  0.809, discriminator acc = 0.972\n",
      "Iteration 7699, source loss =  1.043, discriminator acc = 0.288\n",
      "Iteration 7799, source loss =  0.975, discriminator acc = 0.494\n",
      "Iteration 7899, source loss =  0.850, discriminator acc = 0.246\n",
      "Iteration 7999, source loss =  0.880, discriminator acc = 0.627\n",
      "Iteration 8099, source loss =  0.886, discriminator acc = 0.936\n",
      "Iteration 8199, source loss =  0.905, discriminator acc = 0.249\n",
      "Iteration 8299, source loss =  1.075, discriminator acc = 0.351\n",
      "Iteration 8399, source loss =  1.042, discriminator acc = 0.216\n",
      "Iteration 8499, source loss =  0.917, discriminator acc = 0.953\n",
      "Iteration 8599, source loss =  0.874, discriminator acc = 0.811\n",
      "Iteration 8699, source loss =  0.899, discriminator acc = 0.993\n",
      "Iteration 8799, source loss =  1.010, discriminator acc = 0.337\n",
      "Iteration 8899, source loss =  0.797, discriminator acc = 0.978\n",
      "Iteration 8999, source loss =  1.029, discriminator acc = 0.285\n",
      "Iteration 9099, source loss =  0.804, discriminator acc = 0.951\n",
      "Iteration 9199, source loss =  0.780, discriminator acc = 0.689\n",
      "Iteration 9299, source loss =  0.958, discriminator acc = 0.687\n",
      "Iteration 9399, source loss =  0.962, discriminator acc = 0.945\n",
      "Iteration 9499, source loss =  0.908, discriminator acc = 0.582\n",
      "Iteration 9599, source loss =  0.942, discriminator acc = 0.476\n",
      "Iteration 9699, source loss =  0.889, discriminator acc = 0.422\n",
      "Iteration 9799, source loss =  0.865, discriminator acc = 0.941\n",
      "Iteration 9899, source loss =  1.135, discriminator acc = 0.641\n",
      "Iteration 9999, source loss =  0.908, discriminator acc = 0.917\n",
      "Iteration 10099, source loss =  0.874, discriminator acc = 0.976\n",
      "Iteration 10199, source loss =  0.821, discriminator acc = 0.701\n",
      "Iteration 10299, source loss =  0.874, discriminator acc = 0.482\n",
      "Iteration 10399, source loss =  0.872, discriminator acc = 0.932\n",
      "Iteration 10499, source loss =  0.878, discriminator acc = 0.344\n",
      "Iteration 10599, source loss =  0.805, discriminator acc = 0.950\n",
      "Iteration 10699, source loss =  0.873, discriminator acc = 0.770\n",
      "Iteration 10799, source loss =  0.863, discriminator acc = 0.984\n",
      "Iteration 10899, source loss =  0.918, discriminator acc = 0.251\n",
      "Iteration 10999, source loss =  0.789, discriminator acc = 0.982\n",
      "Iteration 11099, source loss =  0.786, discriminator acc = 0.971\n",
      "Iteration 11199, source loss =  0.831, discriminator acc = 0.740\n",
      "Iteration 11299, source loss =  0.734, discriminator acc = 0.349\n",
      "Iteration 11399, source loss =  0.775, discriminator acc = 0.601\n",
      "Iteration 11499, source loss =  0.792, discriminator acc = 0.789\n",
      "Iteration 11599, source loss =  0.777, discriminator acc = 0.878\n",
      "Iteration 11699, source loss =  0.769, discriminator acc = 0.560\n",
      "Iteration 11799, source loss =  0.847, discriminator acc = 0.339\n",
      "Iteration 11899, source loss =  0.737, discriminator acc = 0.796\n",
      "Iteration 11999, source loss =  0.927, discriminator acc = 0.268\n",
      "Iteration 12099, source loss =  0.738, discriminator acc = 0.936\n",
      "Iteration 12199, source loss =  0.777, discriminator acc = 0.845\n",
      "Iteration 12299, source loss =  0.749, discriminator acc = 0.367\n",
      "Iteration 12399, source loss =  0.853, discriminator acc = 0.312\n",
      "Iteration 12499, source loss =  0.763, discriminator acc = 0.676\n",
      "Iteration 12599, source loss =  0.839, discriminator acc = 0.715\n",
      "Iteration 12699, source loss =  0.794, discriminator acc = 0.771\n",
      "Iteration 12799, source loss =  0.795, discriminator acc = 0.963\n",
      "Iteration 12899, source loss =  1.091, discriminator acc = 0.213\n",
      "Iteration 12999, source loss =  0.746, discriminator acc = 0.687\n",
      "Iteration 13099, source loss =  0.782, discriminator acc = 0.339\n",
      "Iteration 13199, source loss =  0.721, discriminator acc = 0.898\n",
      "Iteration 13299, source loss =  0.754, discriminator acc = 0.468\n",
      "Iteration 13399, source loss =  0.713, discriminator acc = 0.740\n",
      "Iteration 13499, source loss =  0.749, discriminator acc = 0.786\n",
      "Iteration 13599, source loss =  0.806, discriminator acc = 0.449\n",
      "Iteration 13699, source loss =  0.755, discriminator acc = 0.682\n",
      "Iteration 13799, source loss =  0.943, discriminator acc = 0.599\n",
      "Iteration 13899, source loss =  0.803, discriminator acc = 0.348\n",
      "Iteration 13999, source loss =  0.697, discriminator acc = 0.990\n",
      "Iteration 14099, source loss =  0.814, discriminator acc = 0.892\n",
      "Iteration 14199, source loss =  0.742, discriminator acc = 0.730\n",
      "Iteration 14299, source loss =  0.730, discriminator acc = 0.828\n",
      "Iteration 14399, source loss =  0.794, discriminator acc = 0.187\n",
      "Iteration 14499, source loss =  0.830, discriminator acc = 0.256\n",
      "Iteration 14599, source loss =  0.733, discriminator acc = 0.481\n",
      "Iteration 14699, source loss =  0.713, discriminator acc = 0.389\n",
      "Iteration 14799, source loss =  0.724, discriminator acc = 0.604\n",
      "Iteration 14899, source loss =  0.749, discriminator acc = 0.186\n",
      "Iteration 14999, source loss =  0.768, discriminator acc = 0.786\n",
      "PS seed: 343, model seed: 24385\n",
      "Adversarial training for slides dict_keys(['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151674', '151676']): \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.8132 - mae: 0.0272\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5729 - mae: 0.0219\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5397 - mae: 0.0209\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5195 - mae: 0.0204\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5034 - mae: 0.0199\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4893 - mae: 0.0195\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4749 - mae: 0.0191\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4609 - mae: 0.0188\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4476 - mae: 0.0184\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4340 - mae: 0.0180\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236840969657898\n",
      "0.5236840969657898\n",
      "Iteration 99, source loss =  4.612, discriminator acc = 0.223\n",
      "Iteration 199, source loss =  1.603, discriminator acc = 0.752\n",
      "Iteration 299, source loss =  1.737, discriminator acc = 0.288\n",
      "Iteration 399, source loss =  2.200, discriminator acc = 0.937\n",
      "Iteration 499, source loss =  1.384, discriminator acc = 0.846\n",
      "Iteration 599, source loss =  1.281, discriminator acc = 0.839\n",
      "Iteration 699, source loss =  1.180, discriminator acc = 0.930\n",
      "Iteration 799, source loss =  1.192, discriminator acc = 0.929\n",
      "Iteration 899, source loss =  1.206, discriminator acc = 0.728\n",
      "Iteration 999, source loss =  1.164, discriminator acc = 0.697\n",
      "Iteration 1099, source loss =  0.904, discriminator acc = 0.961\n",
      "Iteration 1199, source loss =  1.056, discriminator acc = 0.927\n",
      "Iteration 1299, source loss =  0.985, discriminator acc = 0.684\n",
      "Iteration 1399, source loss =  0.940, discriminator acc = 0.527\n",
      "Iteration 1499, source loss =  0.843, discriminator acc = 0.640\n",
      "Iteration 1599, source loss =  0.759, discriminator acc = 0.341\n",
      "Iteration 1699, source loss =  0.774, discriminator acc = 0.785\n",
      "Iteration 1799, source loss =  0.714, discriminator acc = 0.868\n",
      "Iteration 1899, source loss =  0.719, discriminator acc = 0.796\n",
      "Iteration 1999, source loss =  0.717, discriminator acc = 0.338\n",
      "Iteration 2099, source loss =  0.658, discriminator acc = 0.853\n",
      "Iteration 2199, source loss =  0.649, discriminator acc = 0.673\n",
      "Iteration 2299, source loss =  0.624, discriminator acc = 0.765\n",
      "Iteration 2399, source loss =  0.613, discriminator acc = 0.848\n",
      "Iteration 2499, source loss =  0.636, discriminator acc = 0.621\n",
      "Iteration 2599, source loss =  0.614, discriminator acc = 0.521\n",
      "Iteration 2699, source loss =  0.618, discriminator acc = 0.425\n",
      "Iteration 2799, source loss =  0.587, discriminator acc = 0.488\n",
      "Iteration 2899, source loss =  0.609, discriminator acc = 0.242\n",
      "Iteration 2999, source loss =  0.614, discriminator acc = 0.287\n",
      "Iteration 3099, source loss =  0.570, discriminator acc = 0.339\n",
      "Iteration 3199, source loss =  0.565, discriminator acc = 0.199\n",
      "Iteration 3299, source loss =  0.542, discriminator acc = 0.390\n",
      "Iteration 3399, source loss =  0.523, discriminator acc = 0.743\n",
      "Iteration 3499, source loss =  0.516, discriminator acc = 0.538\n",
      "Iteration 3599, source loss =  0.530, discriminator acc = 0.732\n",
      "Iteration 3699, source loss =  0.521, discriminator acc = 0.367\n",
      "Iteration 3799, source loss =  0.512, discriminator acc = 0.288\n",
      "Iteration 3899, source loss =  0.496, discriminator acc = 0.536\n",
      "Iteration 3999, source loss =  0.490, discriminator acc = 0.714\n",
      "Iteration 4099, source loss =  0.506, discriminator acc = 0.188\n",
      "Iteration 4199, source loss =  0.491, discriminator acc = 0.534\n",
      "Iteration 4299, source loss =  0.472, discriminator acc = 0.338\n",
      "Iteration 4399, source loss =  0.476, discriminator acc = 0.373\n",
      "Iteration 4499, source loss =  0.523, discriminator acc = 0.194\n",
      "Iteration 4599, source loss =  0.496, discriminator acc = 0.177\n",
      "Iteration 4699, source loss =  0.739, discriminator acc = 0.717\n",
      "Iteration 4799, source loss =  2.613, discriminator acc = 0.912\n",
      "Iteration 4899, source loss =  3.328, discriminator acc = 0.995\n",
      "Iteration 4999, source loss =  1.805, discriminator acc = 0.284\n",
      "Iteration 5099, source loss =  1.279, discriminator acc = 1.000\n",
      "Iteration 5199, source loss =  1.690, discriminator acc = 0.707\n",
      "Iteration 5299, source loss =  1.217, discriminator acc = 0.986\n",
      "Iteration 5399, source loss =  1.229, discriminator acc = 0.969\n",
      "Iteration 5499, source loss =  0.857, discriminator acc = 0.995\n",
      "Iteration 5599, source loss =  1.054, discriminator acc = 0.986\n",
      "Iteration 5699, source loss =  0.788, discriminator acc = 0.880\n",
      "Iteration 5799, source loss =  0.828, discriminator acc = 0.833\n",
      "Iteration 5899, source loss =  0.982, discriminator acc = 0.726\n",
      "Iteration 5999, source loss =  0.792, discriminator acc = 0.840\n",
      "Iteration 6099, source loss =  0.990, discriminator acc = 0.188\n",
      "Iteration 6199, source loss =  1.239, discriminator acc = 0.218\n",
      "Iteration 6299, source loss =  0.913, discriminator acc = 0.310\n",
      "Iteration 6399, source loss =  0.831, discriminator acc = 0.832\n",
      "Iteration 6499, source loss =  1.168, discriminator acc = 0.287\n",
      "Iteration 6599, source loss =  0.998, discriminator acc = 0.545\n",
      "Iteration 6699, source loss =  1.162, discriminator acc = 0.546\n",
      "Iteration 6799, source loss =  0.860, discriminator acc = 0.427\n",
      "Iteration 6899, source loss =  0.951, discriminator acc = 0.854\n",
      "Iteration 6999, source loss =  1.030, discriminator acc = 0.722\n",
      "Iteration 7099, source loss =  0.947, discriminator acc = 0.885\n",
      "Iteration 7199, source loss =  0.893, discriminator acc = 0.997\n",
      "Iteration 7299, source loss =  1.022, discriminator acc = 0.811\n",
      "Iteration 7399, source loss =  1.271, discriminator acc = 0.526\n",
      "Iteration 7499, source loss =  0.954, discriminator acc = 0.588\n",
      "Iteration 7599, source loss =  0.909, discriminator acc = 0.988\n",
      "Iteration 7699, source loss =  0.979, discriminator acc = 0.271\n",
      "Iteration 7799, source loss =  0.773, discriminator acc = 0.972\n",
      "Iteration 7899, source loss =  1.151, discriminator acc = 0.358\n",
      "Iteration 7999, source loss =  0.944, discriminator acc = 0.281\n",
      "Iteration 8099, source loss =  0.955, discriminator acc = 0.626\n",
      "Iteration 8199, source loss =  0.866, discriminator acc = 0.731\n",
      "Iteration 8299, source loss =  1.070, discriminator acc = 0.449\n",
      "Iteration 8399, source loss =  0.993, discriminator acc = 0.965\n",
      "Iteration 8499, source loss =  1.082, discriminator acc = 0.335\n",
      "Iteration 8599, source loss =  1.077, discriminator acc = 0.944\n",
      "Iteration 8699, source loss =  1.112, discriminator acc = 0.925\n",
      "Iteration 8799, source loss =  1.059, discriminator acc = 0.639\n",
      "Iteration 8899, source loss =  0.908, discriminator acc = 0.701\n",
      "Iteration 8999, source loss =  1.234, discriminator acc = 0.260\n",
      "Iteration 9099, source loss =  1.196, discriminator acc = 0.842\n",
      "Iteration 9199, source loss =  1.191, discriminator acc = 0.287\n",
      "Iteration 9299, source loss =  1.010, discriminator acc = 0.644\n",
      "Iteration 9399, source loss =  0.881, discriminator acc = 0.886\n",
      "Iteration 9499, source loss =  0.872, discriminator acc = 0.714\n",
      "Iteration 9599, source loss =  0.755, discriminator acc = 0.927\n",
      "Iteration 9699, source loss =  0.881, discriminator acc = 0.455\n",
      "Iteration 9799, source loss =  0.738, discriminator acc = 0.961\n",
      "Iteration 9899, source loss =  0.766, discriminator acc = 0.343\n",
      "Iteration 9999, source loss =  0.750, discriminator acc = 0.295\n",
      "Iteration 10099, source loss =  0.888, discriminator acc = 0.291\n",
      "Iteration 10199, source loss =  0.760, discriminator acc = 0.736\n",
      "Iteration 10299, source loss =  0.729, discriminator acc = 0.999\n",
      "Iteration 10399, source loss =  0.884, discriminator acc = 0.338\n",
      "Iteration 10499, source loss =  0.783, discriminator acc = 0.730\n",
      "Iteration 10599, source loss =  0.838, discriminator acc = 0.668\n",
      "Iteration 10699, source loss =  0.759, discriminator acc = 0.666\n",
      "Iteration 10799, source loss =  0.829, discriminator acc = 0.948\n",
      "Iteration 10899, source loss =  0.870, discriminator acc = 0.985\n",
      "Iteration 10999, source loss =  0.890, discriminator acc = 0.130\n",
      "Iteration 11099, source loss =  0.865, discriminator acc = 0.705\n",
      "Iteration 11199, source loss =  0.808, discriminator acc = 0.886\n",
      "Iteration 11299, source loss =  0.989, discriminator acc = 0.222\n",
      "Iteration 11399, source loss =  1.103, discriminator acc = 0.564\n",
      "Iteration 11499, source loss =  1.107, discriminator acc = 0.289\n",
      "Iteration 11599, source loss =  0.958, discriminator acc = 0.288\n",
      "Iteration 11699, source loss =  0.930, discriminator acc = 0.490\n",
      "Iteration 11799, source loss =  1.095, discriminator acc = 0.911\n",
      "Iteration 11899, source loss =  0.812, discriminator acc = 0.991\n",
      "Iteration 11999, source loss =  0.890, discriminator acc = 0.813\n",
      "Iteration 12099, source loss =  0.841, discriminator acc = 0.673\n",
      "Iteration 12199, source loss =  0.829, discriminator acc = 0.307\n",
      "Iteration 12299, source loss =  0.758, discriminator acc = 0.969\n",
      "Iteration 12399, source loss =  0.878, discriminator acc = 0.449\n",
      "Iteration 12499, source loss =  0.795, discriminator acc = 0.798\n",
      "Iteration 12599, source loss =  0.715, discriminator acc = 0.812\n",
      "Iteration 12699, source loss =  0.770, discriminator acc = 0.383\n",
      "Iteration 12799, source loss =  0.829, discriminator acc = 0.249\n",
      "Iteration 12899, source loss =  0.747, discriminator acc = 0.489\n",
      "Iteration 12999, source loss =  0.835, discriminator acc = 0.308\n",
      "Iteration 13099, source loss =  0.719, discriminator acc = 0.689\n",
      "Iteration 13199, source loss =  0.755, discriminator acc = 0.364\n",
      "Iteration 13299, source loss =  0.697, discriminator acc = 0.813\n",
      "Iteration 13399, source loss =  0.730, discriminator acc = 0.533\n",
      "Iteration 13499, source loss =  0.708, discriminator acc = 0.464\n",
      "Iteration 13599, source loss =  0.755, discriminator acc = 0.908\n",
      "Iteration 13699, source loss =  0.771, discriminator acc = 0.215\n",
      "Iteration 13799, source loss =  0.757, discriminator acc = 0.592\n",
      "Iteration 13899, source loss =  0.690, discriminator acc = 0.845\n",
      "Iteration 13999, source loss =  0.712, discriminator acc = 0.438\n",
      "Iteration 14099, source loss =  0.749, discriminator acc = 0.589\n",
      "Iteration 14199, source loss =  0.726, discriminator acc = 0.589\n",
      "Iteration 14299, source loss =  0.719, discriminator acc = 0.824\n",
      "Iteration 14399, source loss =  0.711, discriminator acc = 0.886\n",
      "Iteration 14499, source loss =  0.806, discriminator acc = 0.319\n",
      "Iteration 14599, source loss =  0.799, discriminator acc = 0.881\n",
      "Iteration 14699, source loss =  0.809, discriminator acc = 0.349\n",
      "Iteration 14799, source loss =  0.898, discriminator acc = 0.549\n",
      "Iteration 14899, source loss =  1.013, discriminator acc = 0.362\n",
      "Iteration 14999, source loss =  0.782, discriminator acc = 0.464\n",
      "PS seed: 25, model seed: 284\n",
      "Adversarial training for slides dict_keys(['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151674', '151676']): \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 14us/sample - loss: 0.8134 - mae: 0.0272\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5729 - mae: 0.0219\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5406 - mae: 0.0210\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5202 - mae: 0.0204\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5037 - mae: 0.0199\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.4890 - mae: 0.0195\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4744 - mae: 0.0191\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4599 - mae: 0.0187\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4458 - mae: 0.0184\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.4325 - mae: 0.0180\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49521382831573485\n",
      "0.49521382831573485\n",
      "Iteration 99, source loss =  4.447, discriminator acc = 0.723\n",
      "Iteration 199, source loss =  1.471, discriminator acc = 0.974\n",
      "Iteration 299, source loss =  2.215, discriminator acc = 0.287\n",
      "Iteration 399, source loss =  1.800, discriminator acc = 0.874\n",
      "Iteration 499, source loss =  1.146, discriminator acc = 0.995\n",
      "Iteration 599, source loss =  1.265, discriminator acc = 0.855\n",
      "Iteration 699, source loss =  1.251, discriminator acc = 0.737\n",
      "Iteration 799, source loss =  1.136, discriminator acc = 0.869\n",
      "Iteration 899, source loss =  1.065, discriminator acc = 0.479\n",
      "Iteration 999, source loss =  0.962, discriminator acc = 0.348\n",
      "Iteration 1099, source loss =  0.804, discriminator acc = 0.907\n",
      "Iteration 1199, source loss =  0.881, discriminator acc = 0.646\n",
      "Iteration 1299, source loss =  0.809, discriminator acc = 0.128\n",
      "Iteration 1399, source loss =  0.686, discriminator acc = 0.867\n",
      "Iteration 1499, source loss =  0.697, discriminator acc = 0.990\n",
      "Iteration 1599, source loss =  0.719, discriminator acc = 0.734\n",
      "Iteration 1699, source loss =  0.769, discriminator acc = 0.174\n",
      "Iteration 1799, source loss =  0.713, discriminator acc = 0.294\n",
      "Iteration 1899, source loss =  0.793, discriminator acc = 0.851\n",
      "Iteration 1999, source loss =  0.863, discriminator acc = 0.823\n",
      "Iteration 2099, source loss =  0.722, discriminator acc = 0.919\n",
      "Iteration 2199, source loss =  0.804, discriminator acc = 0.409\n",
      "Iteration 2299, source loss =  0.730, discriminator acc = 0.918\n",
      "Iteration 2399, source loss =  1.180, discriminator acc = 0.844\n",
      "Iteration 2499, source loss =  1.226, discriminator acc = 0.273\n",
      "Iteration 2599, source loss =  1.011, discriminator acc = 0.738\n",
      "Iteration 2699, source loss =  1.033, discriminator acc = 0.300\n",
      "Iteration 2799, source loss =  0.975, discriminator acc = 0.928\n",
      "Iteration 2899, source loss =  1.294, discriminator acc = 0.596\n",
      "Iteration 2999, source loss =  1.528, discriminator acc = 0.974\n",
      "Iteration 3099, source loss =  0.885, discriminator acc = 0.924\n",
      "Iteration 3199, source loss =  1.099, discriminator acc = 0.288\n",
      "Iteration 3299, source loss =  0.933, discriminator acc = 0.987\n",
      "Iteration 3399, source loss =  1.143, discriminator acc = 0.934\n",
      "Iteration 3499, source loss =  1.063, discriminator acc = 0.175\n",
      "Iteration 3599, source loss =  1.092, discriminator acc = 0.564\n",
      "Iteration 3699, source loss =  1.019, discriminator acc = 0.908\n",
      "Iteration 3799, source loss =  0.902, discriminator acc = 0.995\n",
      "Iteration 3899, source loss =  0.777, discriminator acc = 0.993\n",
      "Iteration 3999, source loss =  0.963, discriminator acc = 0.226\n",
      "Iteration 4099, source loss =  0.705, discriminator acc = 1.000\n",
      "Iteration 4199, source loss =  1.179, discriminator acc = 0.638\n",
      "Iteration 4299, source loss =  1.058, discriminator acc = 0.792\n",
      "Iteration 4399, source loss =  1.259, discriminator acc = 0.803\n",
      "Iteration 4499, source loss =  0.828, discriminator acc = 0.996\n",
      "Iteration 4599, source loss =  0.822, discriminator acc = 0.993\n",
      "Iteration 4699, source loss =  1.160, discriminator acc = 0.446\n",
      "Iteration 4799, source loss =  1.323, discriminator acc = 0.627\n",
      "Iteration 4899, source loss =  0.726, discriminator acc = 0.958\n",
      "Iteration 4999, source loss =  0.877, discriminator acc = 0.287\n",
      "Iteration 5099, source loss =  0.862, discriminator acc = 0.825\n",
      "Iteration 5199, source loss =  0.791, discriminator acc = 0.859\n",
      "Iteration 5299, source loss =  0.794, discriminator acc = 0.747\n",
      "Iteration 5399, source loss =  0.797, discriminator acc = 0.717\n",
      "Iteration 5499, source loss =  1.161, discriminator acc = 0.462\n",
      "Iteration 5599, source loss =  0.810, discriminator acc = 0.915\n",
      "Iteration 5699, source loss =  0.943, discriminator acc = 0.860\n",
      "Iteration 5799, source loss =  0.813, discriminator acc = 0.933\n",
      "Iteration 5899, source loss =  0.897, discriminator acc = 0.769\n",
      "Iteration 5999, source loss =  0.826, discriminator acc = 0.927\n",
      "Iteration 6099, source loss =  0.800, discriminator acc = 0.993\n",
      "Iteration 6199, source loss =  0.885, discriminator acc = 0.359\n",
      "Iteration 6299, source loss =  0.967, discriminator acc = 0.288\n",
      "Iteration 6399, source loss =  0.933, discriminator acc = 0.461\n",
      "Iteration 6499, source loss =  1.009, discriminator acc = 0.526\n",
      "Iteration 6599, source loss =  1.117, discriminator acc = 0.538\n",
      "Iteration 6699, source loss =  1.017, discriminator acc = 0.263\n",
      "Iteration 6799, source loss =  0.838, discriminator acc = 0.909\n",
      "Iteration 6899, source loss =  0.825, discriminator acc = 0.317\n",
      "Iteration 6999, source loss =  0.977, discriminator acc = 0.914\n",
      "Iteration 7099, source loss =  0.889, discriminator acc = 0.977\n",
      "Iteration 7199, source loss =  1.277, discriminator acc = 0.288\n",
      "Iteration 7299, source loss =  1.360, discriminator acc = 0.279\n",
      "Iteration 7399, source loss =  0.893, discriminator acc = 0.811\n",
      "Iteration 7499, source loss =  0.953, discriminator acc = 0.884\n",
      "Iteration 7599, source loss =  0.944, discriminator acc = 0.851\n",
      "Iteration 7699, source loss =  0.863, discriminator acc = 0.946\n",
      "Iteration 7799, source loss =  0.771, discriminator acc = 0.932\n",
      "Iteration 7899, source loss =  1.006, discriminator acc = 0.288\n",
      "Iteration 7999, source loss =  0.715, discriminator acc = 0.972\n",
      "Iteration 8099, source loss =  0.969, discriminator acc = 0.266\n",
      "Iteration 8199, source loss =  0.703, discriminator acc = 0.982\n",
      "Iteration 8299, source loss =  0.782, discriminator acc = 0.512\n",
      "Iteration 8399, source loss =  1.477, discriminator acc = 0.285\n",
      "Iteration 8499, source loss =  0.786, discriminator acc = 0.979\n",
      "Iteration 8599, source loss =  0.832, discriminator acc = 0.319\n",
      "Iteration 8699, source loss =  0.785, discriminator acc = 0.667\n",
      "Iteration 8799, source loss =  0.927, discriminator acc = 0.306\n",
      "Iteration 8899, source loss =  0.905, discriminator acc = 0.306\n",
      "Iteration 8999, source loss =  0.722, discriminator acc = 0.956\n",
      "Iteration 9099, source loss =  0.737, discriminator acc = 0.728\n",
      "Iteration 9199, source loss =  0.707, discriminator acc = 0.873\n",
      "Iteration 9299, source loss =  0.704, discriminator acc = 0.562\n",
      "Iteration 9399, source loss =  0.767, discriminator acc = 0.506\n",
      "Iteration 9499, source loss =  0.752, discriminator acc = 0.253\n",
      "Iteration 9599, source loss =  0.730, discriminator acc = 0.915\n",
      "Iteration 9699, source loss =  0.729, discriminator acc = 0.786\n",
      "Iteration 9799, source loss =  0.870, discriminator acc = 0.284\n",
      "Iteration 9899, source loss =  1.027, discriminator acc = 0.431\n",
      "Iteration 9999, source loss =  0.735, discriminator acc = 0.801\n",
      "Iteration 10099, source loss =  0.695, discriminator acc = 0.753\n",
      "Iteration 10199, source loss =  0.718, discriminator acc = 0.895\n",
      "Iteration 10299, source loss =  0.787, discriminator acc = 0.326\n",
      "Iteration 10399, source loss =  0.704, discriminator acc = 0.489\n",
      "Iteration 10499, source loss =  0.699, discriminator acc = 0.537\n",
      "Iteration 10599, source loss =  0.761, discriminator acc = 0.381\n",
      "Iteration 10699, source loss =  0.691, discriminator acc = 0.504\n",
      "Iteration 10799, source loss =  0.735, discriminator acc = 0.647\n",
      "Iteration 10899, source loss =  0.691, discriminator acc = 0.679\n",
      "Iteration 10999, source loss =  0.693, discriminator acc = 0.705\n",
      "Iteration 11099, source loss =  0.676, discriminator acc = 0.363\n",
      "Iteration 11199, source loss =  0.834, discriminator acc = 0.503\n",
      "Iteration 11299, source loss =  0.666, discriminator acc = 0.944\n",
      "Iteration 11399, source loss =  0.692, discriminator acc = 0.478\n",
      "Iteration 11499, source loss =  0.801, discriminator acc = 0.319\n",
      "Iteration 11599, source loss =  0.639, discriminator acc = 0.808\n",
      "Iteration 11699, source loss =  0.788, discriminator acc = 0.226\n",
      "Iteration 11799, source loss =  0.670, discriminator acc = 0.542\n",
      "Iteration 11899, source loss =  0.671, discriminator acc = 0.543\n",
      "Iteration 11999, source loss =  0.641, discriminator acc = 0.891\n",
      "Iteration 12099, source loss =  0.814, discriminator acc = 0.451\n",
      "Iteration 12199, source loss =  0.784, discriminator acc = 0.292\n",
      "Iteration 12299, source loss =  0.665, discriminator acc = 0.622\n",
      "Iteration 12399, source loss =  0.678, discriminator acc = 0.644\n",
      "Iteration 12499, source loss =  0.663, discriminator acc = 0.463\n",
      "Iteration 12599, source loss =  0.804, discriminator acc = 0.757\n",
      "Iteration 12699, source loss =  0.741, discriminator acc = 0.977\n",
      "Iteration 12799, source loss =  0.982, discriminator acc = 0.285\n",
      "Iteration 12899, source loss =  0.925, discriminator acc = 0.640\n",
      "Iteration 12999, source loss =  0.840, discriminator acc = 0.937\n",
      "Iteration 13099, source loss =  1.008, discriminator acc = 0.884\n",
      "Iteration 13199, source loss =  0.974, discriminator acc = 0.425\n",
      "Iteration 13299, source loss =  1.005, discriminator acc = 0.320\n",
      "Iteration 13399, source loss =  0.735, discriminator acc = 0.983\n",
      "Iteration 13499, source loss =  0.728, discriminator acc = 0.691\n",
      "Iteration 13599, source loss =  0.757, discriminator acc = 0.518\n",
      "Iteration 13699, source loss =  0.687, discriminator acc = 0.964\n",
      "Iteration 13799, source loss =  0.751, discriminator acc = 0.746\n",
      "Iteration 13899, source loss =  0.888, discriminator acc = 0.419\n",
      "Iteration 13999, source loss =  0.778, discriminator acc = 0.347\n",
      "Iteration 14099, source loss =  0.742, discriminator acc = 0.975\n",
      "Iteration 14199, source loss =  0.751, discriminator acc = 0.406\n",
      "Iteration 14299, source loss =  0.690, discriminator acc = 0.906\n",
      "Iteration 14399, source loss =  0.693, discriminator acc = 0.915\n",
      "Iteration 14499, source loss =  0.683, discriminator acc = 0.709\n",
      "Iteration 14599, source loss =  0.762, discriminator acc = 0.546\n",
      "Iteration 14699, source loss =  0.665, discriminator acc = 0.754\n",
      "Iteration 14799, source loss =  0.681, discriminator acc = 0.420\n",
      "Iteration 14899, source loss =  0.652, discriminator acc = 0.880\n",
      "Iteration 14999, source loss =  0.649, discriminator acc = 0.573\n",
      "PS seed: 234, model seed: 86322\n",
      "Adversarial training for slides dict_keys(['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151674', '151676']): \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.8083 - mae: 0.0272\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5740 - mae: 0.0219\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5421 - mae: 0.0210\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.5232 - mae: 0.0205\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5074 - mae: 0.0200\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4929 - mae: 0.0196\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4782 - mae: 0.0192\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4645 - mae: 0.0189\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4503 - mae: 0.0185\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.4370 - mae: 0.0181\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4657786366939545\n",
      "0.4657786366939545\n",
      "Iteration 99, source loss =  3.631, discriminator acc = 0.605\n",
      "Iteration 199, source loss =  1.949, discriminator acc = 0.553\n",
      "Iteration 299, source loss =  2.359, discriminator acc = 0.288\n",
      "Iteration 399, source loss =  2.323, discriminator acc = 0.620\n",
      "Iteration 499, source loss =  1.330, discriminator acc = 0.866\n",
      "Iteration 599, source loss =  1.568, discriminator acc = 0.704\n",
      "Iteration 699, source loss =  1.171, discriminator acc = 0.632\n",
      "Iteration 799, source loss =  1.328, discriminator acc = 0.816\n",
      "Iteration 899, source loss =  1.233, discriminator acc = 0.925\n",
      "Iteration 999, source loss =  1.086, discriminator acc = 0.697\n",
      "Iteration 1099, source loss =  0.970, discriminator acc = 0.820\n",
      "Iteration 1199, source loss =  0.990, discriminator acc = 0.860\n",
      "Iteration 1299, source loss =  0.865, discriminator acc = 0.503\n",
      "Iteration 1399, source loss =  0.712, discriminator acc = 0.951\n",
      "Iteration 1499, source loss =  0.740, discriminator acc = 0.837\n",
      "Iteration 1599, source loss =  0.750, discriminator acc = 0.284\n",
      "Iteration 1699, source loss =  0.713, discriminator acc = 0.839\n",
      "Iteration 1799, source loss =  0.663, discriminator acc = 0.798\n",
      "Iteration 1899, source loss =  0.677, discriminator acc = 0.185\n",
      "Iteration 1999, source loss =  0.628, discriminator acc = 0.456\n",
      "Iteration 2099, source loss =  0.644, discriminator acc = 0.899\n",
      "Iteration 2199, source loss =  0.628, discriminator acc = 0.370\n",
      "Iteration 2299, source loss =  0.685, discriminator acc = 0.124\n",
      "Iteration 2399, source loss =  0.676, discriminator acc = 0.608\n",
      "Iteration 2499, source loss =  0.598, discriminator acc = 0.583\n",
      "Iteration 2599, source loss =  0.622, discriminator acc = 0.790\n",
      "Iteration 2699, source loss =  0.678, discriminator acc = 0.568\n",
      "Iteration 2799, source loss =  0.755, discriminator acc = 0.150\n",
      "Iteration 2899, source loss =  0.743, discriminator acc = 0.233\n",
      "Iteration 2999, source loss =  0.719, discriminator acc = 0.519\n",
      "Iteration 3099, source loss =  1.112, discriminator acc = 0.056\n",
      "Iteration 3199, source loss =  0.782, discriminator acc = 0.941\n",
      "Iteration 3299, source loss =  0.632, discriminator acc = 0.907\n",
      "Iteration 3399, source loss =  0.665, discriminator acc = 0.840\n",
      "Iteration 3499, source loss =  0.746, discriminator acc = 0.507\n",
      "Iteration 3599, source loss =  1.025, discriminator acc = 0.119\n",
      "Iteration 3699, source loss =  0.792, discriminator acc = 0.263\n",
      "Iteration 3799, source loss =  1.614, discriminator acc = 0.282\n",
      "Iteration 3899, source loss =  0.950, discriminator acc = 0.137\n",
      "Iteration 3999, source loss =  1.020, discriminator acc = 0.304\n",
      "Iteration 4099, source loss =  0.901, discriminator acc = 0.145\n",
      "Iteration 4199, source loss =  1.734, discriminator acc = 0.413\n",
      "Iteration 4299, source loss =  1.834, discriminator acc = 0.288\n",
      "Iteration 4399, source loss =  1.197, discriminator acc = 0.307\n",
      "Iteration 4499, source loss =  0.938, discriminator acc = 0.990\n",
      "Iteration 4599, source loss =  1.321, discriminator acc = 0.697\n",
      "Iteration 4699, source loss =  1.286, discriminator acc = 0.397\n",
      "Iteration 4799, source loss =  1.439, discriminator acc = 0.994\n",
      "Iteration 4899, source loss =  1.493, discriminator acc = 0.564\n",
      "Iteration 4999, source loss =  1.159, discriminator acc = 0.893\n",
      "Iteration 5099, source loss =  0.973, discriminator acc = 0.584\n",
      "Iteration 5199, source loss =  1.064, discriminator acc = 0.548\n",
      "Iteration 5299, source loss =  0.852, discriminator acc = 0.996\n",
      "Iteration 5399, source loss =  1.194, discriminator acc = 0.665\n",
      "Iteration 5499, source loss =  1.179, discriminator acc = 0.941\n",
      "Iteration 5599, source loss =  1.216, discriminator acc = 0.505\n",
      "Iteration 5699, source loss =  0.988, discriminator acc = 0.928\n",
      "Iteration 5799, source loss =  1.063, discriminator acc = 0.758\n",
      "Iteration 5899, source loss =  0.952, discriminator acc = 0.201\n",
      "Iteration 5999, source loss =  0.984, discriminator acc = 0.690\n",
      "Iteration 6099, source loss =  0.891, discriminator acc = 0.933\n",
      "Iteration 6199, source loss =  0.967, discriminator acc = 0.923\n",
      "Iteration 6299, source loss =  1.054, discriminator acc = 0.681\n",
      "Iteration 6399, source loss =  1.006, discriminator acc = 0.138\n",
      "Iteration 6499, source loss =  0.883, discriminator acc = 0.950\n",
      "Iteration 6599, source loss =  0.884, discriminator acc = 0.404\n",
      "Iteration 6699, source loss =  0.843, discriminator acc = 0.997\n",
      "Iteration 6799, source loss =  0.855, discriminator acc = 0.962\n",
      "Iteration 6899, source loss =  0.903, discriminator acc = 0.309\n",
      "Iteration 6999, source loss =  0.961, discriminator acc = 0.758\n",
      "Iteration 7099, source loss =  0.795, discriminator acc = 0.941\n",
      "Iteration 7199, source loss =  0.936, discriminator acc = 0.333\n",
      "Iteration 7299, source loss =  0.894, discriminator acc = 0.359\n",
      "Iteration 7399, source loss =  0.804, discriminator acc = 0.713\n",
      "Iteration 7499, source loss =  0.819, discriminator acc = 0.898\n",
      "Iteration 7599, source loss =  0.739, discriminator acc = 0.956\n",
      "Iteration 7699, source loss =  0.837, discriminator acc = 0.390\n",
      "Iteration 7799, source loss =  0.862, discriminator acc = 0.288\n",
      "Iteration 7899, source loss =  0.818, discriminator acc = 0.738\n",
      "Iteration 7999, source loss =  0.778, discriminator acc = 0.571\n",
      "Iteration 8099, source loss =  0.889, discriminator acc = 0.736\n",
      "Iteration 8199, source loss =  0.747, discriminator acc = 0.987\n",
      "Iteration 8299, source loss =  0.796, discriminator acc = 0.258\n",
      "Iteration 8399, source loss =  0.963, discriminator acc = 0.500\n",
      "Iteration 8499, source loss =  0.757, discriminator acc = 0.869\n",
      "Iteration 8599, source loss =  0.729, discriminator acc = 0.875\n",
      "Iteration 8699, source loss =  0.751, discriminator acc = 0.947\n",
      "Iteration 8799, source loss =  0.753, discriminator acc = 0.985\n",
      "Iteration 8899, source loss =  0.842, discriminator acc = 0.957\n",
      "Iteration 8999, source loss =  0.771, discriminator acc = 0.852\n",
      "Iteration 9099, source loss =  1.173, discriminator acc = 0.333\n",
      "Iteration 9199, source loss =  0.720, discriminator acc = 0.946\n",
      "Iteration 9299, source loss =  0.745, discriminator acc = 0.564\n",
      "Iteration 9399, source loss =  0.900, discriminator acc = 0.705\n",
      "Iteration 9499, source loss =  0.815, discriminator acc = 0.368\n",
      "Iteration 9599, source loss =  0.798, discriminator acc = 0.900\n",
      "Iteration 9699, source loss =  0.832, discriminator acc = 0.430\n",
      "Iteration 9799, source loss =  0.989, discriminator acc = 0.666\n",
      "Iteration 9899, source loss =  0.868, discriminator acc = 0.491\n",
      "Iteration 9999, source loss =  0.856, discriminator acc = 0.985\n",
      "Iteration 10099, source loss =  0.779, discriminator acc = 0.885\n",
      "Iteration 10199, source loss =  0.844, discriminator acc = 0.410\n",
      "Iteration 10299, source loss =  0.796, discriminator acc = 0.861\n",
      "Iteration 10399, source loss =  0.859, discriminator acc = 0.883\n",
      "Iteration 10499, source loss =  0.899, discriminator acc = 0.392\n",
      "Iteration 10599, source loss =  0.718, discriminator acc = 0.831\n",
      "Iteration 10699, source loss =  0.780, discriminator acc = 0.999\n",
      "Iteration 10799, source loss =  0.887, discriminator acc = 0.332\n",
      "Iteration 10899, source loss =  0.758, discriminator acc = 0.837\n",
      "Iteration 10999, source loss =  0.991, discriminator acc = 0.455\n",
      "Iteration 11099, source loss =  0.828, discriminator acc = 0.772\n",
      "Iteration 11199, source loss =  0.858, discriminator acc = 0.438\n",
      "Iteration 11299, source loss =  0.876, discriminator acc = 0.786\n",
      "Iteration 11399, source loss =  0.766, discriminator acc = 0.982\n",
      "Iteration 11499, source loss =  0.794, discriminator acc = 0.540\n",
      "Iteration 11599, source loss =  0.842, discriminator acc = 0.981\n",
      "Iteration 11699, source loss =  0.752, discriminator acc = 0.984\n",
      "Iteration 11799, source loss =  0.812, discriminator acc = 0.127\n",
      "Iteration 11899, source loss =  0.761, discriminator acc = 0.716\n",
      "Iteration 11999, source loss =  0.819, discriminator acc = 0.522\n",
      "Iteration 12099, source loss =  0.843, discriminator acc = 0.346\n",
      "Iteration 12199, source loss =  0.861, discriminator acc = 0.910\n",
      "Iteration 12299, source loss =  0.805, discriminator acc = 0.977\n",
      "Iteration 12399, source loss =  0.977, discriminator acc = 0.282\n",
      "Iteration 12499, source loss =  0.874, discriminator acc = 0.979\n",
      "Iteration 12599, source loss =  0.815, discriminator acc = 0.999\n",
      "Iteration 12699, source loss =  0.944, discriminator acc = 0.227\n",
      "Iteration 12799, source loss =  1.079, discriminator acc = 0.355\n",
      "Iteration 12899, source loss =  0.809, discriminator acc = 0.881\n",
      "Iteration 12999, source loss =  1.324, discriminator acc = 0.275\n",
      "Iteration 13099, source loss =  0.828, discriminator acc = 0.851\n",
      "Iteration 13199, source loss =  0.888, discriminator acc = 0.356\n",
      "Iteration 13299, source loss =  0.756, discriminator acc = 0.959\n",
      "Iteration 13399, source loss =  0.944, discriminator acc = 0.327\n",
      "Iteration 13499, source loss =  0.732, discriminator acc = 0.984\n",
      "Iteration 13599, source loss =  0.746, discriminator acc = 0.832\n",
      "Iteration 13699, source loss =  0.749, discriminator acc = 0.532\n",
      "Iteration 13799, source loss =  0.779, discriminator acc = 0.758\n",
      "Iteration 13899, source loss =  0.785, discriminator acc = 0.875\n",
      "Iteration 13999, source loss =  0.718, discriminator acc = 0.772\n",
      "Iteration 14099, source loss =  0.825, discriminator acc = 0.320\n",
      "Iteration 14199, source loss =  0.732, discriminator acc = 0.705\n",
      "Iteration 14299, source loss =  0.716, discriminator acc = 0.262\n",
      "Iteration 14399, source loss =  0.708, discriminator acc = 0.359\n",
      "Iteration 14499, source loss =  0.732, discriminator acc = 0.679\n",
      "Iteration 14599, source loss =  0.717, discriminator acc = 0.756\n",
      "Iteration 14699, source loss =  0.697, discriminator acc = 0.818\n",
      "Iteration 14799, source loss =  0.757, discriminator acc = 0.288\n",
      "Iteration 14899, source loss =  0.813, discriminator acc = 0.378\n",
      "Iteration 14999, source loss =  0.740, discriminator acc = 0.592\n",
      "PS seed: 98098, model seed: 98237\n",
      "Adversarial training for slides dict_keys(['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151674', '151676']): \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.8024 - mae: 0.0271\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5721 - mae: 0.0219\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5403 - mae: 0.0210\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5204 - mae: 0.0204\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.5044 - mae: 0.0200\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4898 - mae: 0.0195\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4753 - mae: 0.0192\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4614 - mae: 0.0188\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4481 - mae: 0.0184\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.4343 - mae: 0.0181\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5068058612442017\n",
      "0.5068058612442017\n",
      "Iteration 99, source loss =  2.788, discriminator acc = 0.292\n",
      "Iteration 199, source loss =  1.985, discriminator acc = 0.446\n",
      "Iteration 299, source loss =  1.651, discriminator acc = 0.738\n",
      "Iteration 399, source loss =  1.280, discriminator acc = 0.713\n",
      "Iteration 499, source loss =  1.533, discriminator acc = 0.988\n",
      "Iteration 599, source loss =  1.738, discriminator acc = 0.597\n",
      "Iteration 699, source loss =  1.414, discriminator acc = 0.983\n",
      "Iteration 799, source loss =  1.082, discriminator acc = 0.993\n",
      "Iteration 899, source loss =  1.010, discriminator acc = 0.582\n",
      "Iteration 999, source loss =  0.892, discriminator acc = 0.977\n",
      "Iteration 1099, source loss =  0.818, discriminator acc = 0.996\n",
      "Iteration 1199, source loss =  0.826, discriminator acc = 0.074\n",
      "Iteration 1299, source loss =  0.701, discriminator acc = 0.939\n",
      "Iteration 1399, source loss =  0.710, discriminator acc = 0.977\n",
      "Iteration 1499, source loss =  0.749, discriminator acc = 0.889\n",
      "Iteration 1599, source loss =  0.814, discriminator acc = 0.802\n",
      "Iteration 1699, source loss =  0.715, discriminator acc = 0.876\n",
      "Iteration 1799, source loss =  0.857, discriminator acc = 0.423\n",
      "Iteration 1899, source loss =  0.688, discriminator acc = 0.776\n",
      "Iteration 1999, source loss =  0.696, discriminator acc = 0.624\n",
      "Iteration 2099, source loss =  0.891, discriminator acc = 0.230\n",
      "Iteration 2199, source loss =  0.820, discriminator acc = 0.984\n",
      "Iteration 2299, source loss =  0.830, discriminator acc = 0.914\n",
      "Iteration 2399, source loss =  0.721, discriminator acc = 0.940\n",
      "Iteration 2499, source loss =  0.989, discriminator acc = 0.966\n",
      "Iteration 2599, source loss =  1.048, discriminator acc = 0.340\n",
      "Iteration 2699, source loss =  0.816, discriminator acc = 0.952\n",
      "Iteration 2799, source loss =  1.836, discriminator acc = 0.295\n",
      "Iteration 2899, source loss =  1.094, discriminator acc = 0.297\n",
      "Iteration 2999, source loss =  1.591, discriminator acc = 0.288\n",
      "Iteration 3099, source loss =  1.107, discriminator acc = 0.942\n",
      "Iteration 3199, source loss =  1.498, discriminator acc = 0.711\n",
      "Iteration 3299, source loss =  0.954, discriminator acc = 0.752\n",
      "Iteration 3399, source loss =  1.166, discriminator acc = 0.744\n",
      "Iteration 3499, source loss =  0.801, discriminator acc = 0.564\n",
      "Iteration 3599, source loss =  0.711, discriminator acc = 0.923\n",
      "Iteration 3699, source loss =  0.792, discriminator acc = 0.871\n",
      "Iteration 3799, source loss =  1.077, discriminator acc = 0.292\n",
      "Iteration 3899, source loss =  0.962, discriminator acc = 0.298\n",
      "Iteration 3999, source loss =  0.806, discriminator acc = 0.996\n",
      "Iteration 4099, source loss =  0.841, discriminator acc = 0.424\n",
      "Iteration 4199, source loss =  1.144, discriminator acc = 0.687\n",
      "Iteration 4299, source loss =  0.946, discriminator acc = 0.887\n",
      "Iteration 4399, source loss =  0.976, discriminator acc = 0.937\n",
      "Iteration 4499, source loss =  1.593, discriminator acc = 0.288\n",
      "Iteration 4599, source loss =  1.036, discriminator acc = 0.862\n",
      "Iteration 4699, source loss =  0.869, discriminator acc = 0.837\n",
      "Iteration 4799, source loss =  0.896, discriminator acc = 0.324\n",
      "Iteration 4899, source loss =  0.872, discriminator acc = 0.868\n",
      "Iteration 4999, source loss =  1.116, discriminator acc = 0.998\n",
      "Iteration 5099, source loss =  1.036, discriminator acc = 0.641\n",
      "Iteration 5199, source loss =  0.939, discriminator acc = 0.991\n",
      "Iteration 5299, source loss =  0.936, discriminator acc = 0.480\n",
      "Iteration 5399, source loss =  0.859, discriminator acc = 0.953\n",
      "Iteration 5499, source loss =  0.746, discriminator acc = 0.979\n",
      "Iteration 5599, source loss =  0.882, discriminator acc = 0.212\n",
      "Iteration 5699, source loss =  0.732, discriminator acc = 0.996\n",
      "Iteration 5799, source loss =  0.948, discriminator acc = 0.988\n",
      "Iteration 5899, source loss =  0.897, discriminator acc = 0.476\n",
      "Iteration 5999, source loss =  0.872, discriminator acc = 0.259\n",
      "Iteration 6099, source loss =  0.934, discriminator acc = 0.712\n",
      "Iteration 6199, source loss =  0.865, discriminator acc = 0.872\n",
      "Iteration 6299, source loss =  0.786, discriminator acc = 0.984\n",
      "Iteration 6399, source loss =  0.870, discriminator acc = 0.997\n",
      "Iteration 6499, source loss =  0.922, discriminator acc = 0.282\n",
      "Iteration 6599, source loss =  0.874, discriminator acc = 0.696\n",
      "Iteration 6699, source loss =  0.955, discriminator acc = 0.511\n",
      "Iteration 6799, source loss =  0.780, discriminator acc = 0.965\n",
      "Iteration 6899, source loss =  0.823, discriminator acc = 0.289\n",
      "Iteration 6999, source loss =  0.852, discriminator acc = 0.847\n",
      "Iteration 7099, source loss =  0.870, discriminator acc = 0.354\n",
      "Iteration 7199, source loss =  0.795, discriminator acc = 0.634\n",
      "Iteration 7299, source loss =  0.721, discriminator acc = 0.833\n",
      "Iteration 7399, source loss =  0.771, discriminator acc = 0.284\n",
      "Iteration 7499, source loss =  0.688, discriminator acc = 0.897\n",
      "Iteration 7599, source loss =  0.739, discriminator acc = 0.381\n",
      "Iteration 7699, source loss =  0.679, discriminator acc = 0.882\n",
      "Iteration 7799, source loss =  0.715, discriminator acc = 0.447\n",
      "Iteration 7899, source loss =  0.787, discriminator acc = 0.664\n",
      "Iteration 7999, source loss =  0.830, discriminator acc = 0.209\n",
      "Iteration 8099, source loss =  0.716, discriminator acc = 0.421\n",
      "Iteration 8199, source loss =  0.839, discriminator acc = 0.342\n",
      "Iteration 8299, source loss =  0.776, discriminator acc = 0.259\n",
      "Iteration 8399, source loss =  0.742, discriminator acc = 0.670\n",
      "Iteration 8499, source loss =  0.927, discriminator acc = 0.217\n",
      "Iteration 8599, source loss =  0.887, discriminator acc = 0.906\n",
      "Iteration 8699, source loss =  0.792, discriminator acc = 0.737\n",
      "Iteration 8799, source loss =  0.833, discriminator acc = 0.830\n",
      "Iteration 8899, source loss =  0.796, discriminator acc = 0.875\n",
      "Iteration 8999, source loss =  0.988, discriminator acc = 0.328\n",
      "Iteration 9099, source loss =  1.217, discriminator acc = 0.298\n",
      "Iteration 9199, source loss =  1.248, discriminator acc = 0.675\n",
      "Iteration 9299, source loss =  0.915, discriminator acc = 0.519\n",
      "Iteration 9399, source loss =  0.905, discriminator acc = 0.963\n",
      "Iteration 9499, source loss =  0.824, discriminator acc = 0.976\n",
      "Iteration 9599, source loss =  0.910, discriminator acc = 0.908\n",
      "Iteration 9699, source loss =  0.767, discriminator acc = 0.966\n",
      "Iteration 9799, source loss =  0.821, discriminator acc = 0.802\n",
      "Iteration 9899, source loss =  0.780, discriminator acc = 0.273\n",
      "Iteration 9999, source loss =  0.926, discriminator acc = 0.144\n",
      "Iteration 10099, source loss =  0.991, discriminator acc = 0.945\n",
      "Iteration 10199, source loss =  0.958, discriminator acc = 0.288\n",
      "Iteration 10299, source loss =  0.800, discriminator acc = 0.838\n",
      "Iteration 10399, source loss =  0.977, discriminator acc = 0.397\n",
      "Iteration 10499, source loss =  0.865, discriminator acc = 0.963\n",
      "Iteration 10599, source loss =  0.789, discriminator acc = 0.585\n",
      "Iteration 10699, source loss =  0.803, discriminator acc = 0.478\n",
      "Iteration 10799, source loss =  0.974, discriminator acc = 0.173\n",
      "Iteration 10899, source loss =  0.806, discriminator acc = 0.889\n",
      "Iteration 10999, source loss =  0.902, discriminator acc = 0.939\n",
      "Iteration 11099, source loss =  0.882, discriminator acc = 0.946\n",
      "Iteration 11199, source loss =  0.935, discriminator acc = 0.522\n",
      "Iteration 11299, source loss =  0.799, discriminator acc = 0.714\n",
      "Iteration 11399, source loss =  0.750, discriminator acc = 0.994\n",
      "Iteration 11499, source loss =  0.863, discriminator acc = 0.291\n",
      "Iteration 11599, source loss =  0.778, discriminator acc = 0.567\n",
      "Iteration 11699, source loss =  0.774, discriminator acc = 0.760\n",
      "Iteration 11799, source loss =  0.869, discriminator acc = 0.288\n",
      "Iteration 11899, source loss =  0.726, discriminator acc = 0.580\n",
      "Iteration 11999, source loss =  0.694, discriminator acc = 0.989\n",
      "Iteration 12099, source loss =  0.779, discriminator acc = 0.305\n",
      "Iteration 12199, source loss =  0.727, discriminator acc = 0.746\n",
      "Iteration 12299, source loss =  0.697, discriminator acc = 0.836\n",
      "Iteration 12399, source loss =  0.744, discriminator acc = 0.837\n",
      "Iteration 12499, source loss =  0.815, discriminator acc = 0.308\n",
      "Iteration 12599, source loss =  0.765, discriminator acc = 0.362\n",
      "Iteration 12699, source loss =  0.754, discriminator acc = 0.656\n",
      "Iteration 12799, source loss =  0.762, discriminator acc = 0.442\n",
      "Iteration 12899, source loss =  0.650, discriminator acc = 0.894\n",
      "Iteration 12999, source loss =  0.680, discriminator acc = 0.805\n",
      "Iteration 13099, source loss =  0.688, discriminator acc = 0.426\n",
      "Iteration 13199, source loss =  0.641, discriminator acc = 0.847\n",
      "Iteration 13299, source loss =  0.659, discriminator acc = 0.501\n",
      "Iteration 13399, source loss =  0.686, discriminator acc = 0.880\n",
      "Iteration 13499, source loss =  0.783, discriminator acc = 0.884\n",
      "Iteration 13599, source loss =  0.660, discriminator acc = 0.995\n",
      "Iteration 13699, source loss =  0.829, discriminator acc = 0.396\n",
      "Iteration 13799, source loss =  0.777, discriminator acc = 0.981\n",
      "Iteration 13899, source loss =  0.878, discriminator acc = 0.262\n",
      "Iteration 13999, source loss =  0.908, discriminator acc = 0.365\n",
      "Iteration 14099, source loss =  0.763, discriminator acc = 0.337\n",
      "Iteration 14199, source loss =  0.715, discriminator acc = 0.887\n",
      "Iteration 14299, source loss =  0.731, discriminator acc = 0.663\n",
      "Iteration 14399, source loss =  0.868, discriminator acc = 0.304\n",
      "Iteration 14499, source loss =  0.739, discriminator acc = 0.615\n",
      "Iteration 14599, source loss =  0.698, discriminator acc = 0.313\n",
      "Iteration 14699, source loss =  0.768, discriminator acc = 0.985\n",
      "Iteration 14799, source loss =  0.691, discriminator acc = 0.532\n",
      "Iteration 14899, source loss =  0.729, discriminator acc = 0.289\n",
      "Iteration 14999, source loss =  0.826, discriminator acc = 0.485\n"
     ]
    }
   ],
   "source": [
    "def train(ps_seed, model_seed):\n",
    "    print(f\"PS seed: {ps_seed}, model seed: {model_seed}\")\n",
    "\n",
    "    model_folder = data_loading.get_model_rel_path(\n",
    "        MODEL_NAME,\n",
    "        model_params[\"model_version\"],\n",
    "        lib_seed_path=str(model_seed),\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    model_folder = os.path.join(MODEL_DIR, model_folder)\n",
    "    if not os.path.isdir(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "        print(model_folder)\n",
    "        \n",
    "    selected_dir = data_loading.get_selected_dir(\n",
    "        data_loading.get_dset_dir(\n",
    "            data_params[\"data_dir\"],\n",
    "            dset=data_params.get(\"dset\", \"dlpfc\"),\n",
    "        ),\n",
    "        **data_params,\n",
    "    )\n",
    "    # Load spatial data\n",
    "    mat_sp_d, mat_sp_meta_d, st_sample_id_l = data_loading.load_spatial(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    # Load sc data\n",
    "    sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = data_loading.load_sc(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "        seed_int=ps_seed,\n",
    "    )\n",
    "\n",
    "    target_d = {}\n",
    "    if \"train\" in mat_sp_d:\n",
    "        # keys of dict are splits\n",
    "        for split in mat_sp_d:\n",
    "            target_d[split] = np.concatenate(list(mat_sp_d[split].values()))\n",
    "    else:\n",
    "        # keys of subdicts are splits\n",
    "        for split in next(iter(mat_sp_d.values())):\n",
    "            target_d[split] = np.concatenate((v[split] for v in mat_sp_d.values()))\n",
    "\n",
    "\n",
    "    advtrain_folder = os.path.join(model_folder, \"advtrain\")\n",
    "    pretrain_folder = os.path.join(model_folder, \"pretrain\")\n",
    "    if not os.path.isdir(advtrain_folder):\n",
    "        os.makedirs(advtrain_folder)\n",
    "    if not os.path.isdir(pretrain_folder):\n",
    "        os.makedirs(pretrain_folder)\n",
    "\n",
    "    if data_params.get(\"samp_split\"):\n",
    "        tqdm.write(f\"Adversarial training for slides {mat_sp_d['train'].keys()}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"samp_split\")\n",
    "    else:\n",
    "        tqdm.write(f\"Adversarial training for slides {next(iter(mat_sp_d.keys()))}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"one_model\")\n",
    "\n",
    "    if not os.path.isdir(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    embs, embs_noda, clssmodel, clssmodel_noda = da_cellfraction.train(\n",
    "        sc_mix_d[\"train\"],\n",
    "        lab_mix_d[\"train\"],\n",
    "        target_d[\"train\"],\n",
    "        alpha=train_params.get(\"alpha\", 0.6),\n",
    "        alpha_lr=train_params.get(\"alpha_lr\", 5),\n",
    "        emb_dim=model_params[\"celldart_kwargs\"].get(\"emb_dim\", 64),\n",
    "        batch_size=train_params.get(\"batch_size\", 512),\n",
    "        n_iterations=train_params.get(\"n_iter\", 3000),\n",
    "        initial_train=train_params.get(\"pretraining\", True),\n",
    "        initial_train_epochs=train_params.get(\"initial_train_epochs\", 10),\n",
    "        batch_size_initial_train=max(train_params.get(\"batch_size\", 512), 512),\n",
    "        seed=model_seed,\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "\n",
    "    if not os.path.isdir(os.path.join(save_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(save_folder, \"final_model\"))\n",
    "    if not os.path.isdir(os.path.join(pretrain_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(pretrain_folder, \"final_model\"))\n",
    "\n",
    "    clssmodel_noda.save(os.path.join(pretrain_folder, \"final_model\", \"model\"))\n",
    "    clssmodel.save(os.path.join(save_folder, \"final_model\", \"model\"))\n",
    "\n",
    "    embs_noda.save(os.path.join(pretrain_folder, \"final_model\", \"embs\"))\n",
    "    embs.save(os.path.join(save_folder, \"final_model\", \"embs\"))\n",
    "\n",
    "    with open(os.path.join(model_folder, \"config.yml\"), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    train(ps_seed, model_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\n",
      "Evaluating CellDART_original on with -1 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config basic_config.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/dlpfc/GSE144136_spatialLIBD/20markers/8mix_100000spots/minmax/std/2353 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/evaluator.py:159: UserWarning: Output folder exists. Will overwrite.\n",
      "  self.results_folder = self.temp_folder_holder.set_output_folder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   16.8s remaining:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   17.2s remaining:   51.5s\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  12 | elapsed:   17.5s remaining:   34.9s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   17.5s remaining:   24.5s\n",
      "[Parallel(n_jobs=12)]: Done   6 out of  12 | elapsed:   17.6s remaining:   17.6s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   18.0s remaining:   12.8s\n",
      "[Parallel(n_jobs=12)]: Done   8 out of  12 | elapsed:   18.0s remaining:    9.0s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   18.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  12 | elapsed:   18.1s remaining:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   18.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   18.3s finished\n",
      "Calculating domain shift for 151507: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151508: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151509: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151510: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151669: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151670: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151671: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151672: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151674: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151676: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151673: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151675: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507                         0.200982   \n",
      "                                151508                         0.200982   \n",
      "                                151509                         0.200982   \n",
      "                                151510                         0.200982   \n",
      "                                151669                         0.200982   \n",
      "                                151670                         0.200982   \n",
      "                                151671                         0.200982   \n",
      "                                151672                         0.200982   \n",
      "                                151674                         0.200982   \n",
      "                                151676                         0.200982   \n",
      "                       val      151673                         0.200982   \n",
      "                       test     151675                         0.200982   \n",
      "After DA (final model) train    151507                         0.237336   \n",
      "                                151508                         0.237336   \n",
      "                                151509                         0.237336   \n",
      "                                151510                         0.237336   \n",
      "                                151669                         0.237336   \n",
      "                                151670                         0.237336   \n",
      "                                151671                         0.237336   \n",
      "                                151672                         0.237336   \n",
      "                                151674                         0.237336   \n",
      "                                151676                         0.237336   \n",
      "                       val      151673                         0.237336   \n",
      "                       test     151675                         0.237336   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507     0.246038  0.239291  1.000000   \n",
      "                                151508     0.246038  0.239291  1.000000   \n",
      "                                151509     0.246038  0.239291  1.000000   \n",
      "                                151510     0.246038  0.239291  0.999975   \n",
      "                                151669     0.246038  0.239291  0.999975   \n",
      "                                151670     0.246038  0.239291  0.999975   \n",
      "                                151671     0.246038  0.239291  0.999975   \n",
      "                                151672     0.246038  0.239291  0.999975   \n",
      "                                151674     0.246038  0.239291  0.999975   \n",
      "                                151676     0.246038  0.239291  1.000000   \n",
      "                       val      151673     0.246038  0.239291  0.999975   \n",
      "                       test     151675     0.246038  0.239291  1.000000   \n",
      "After DA (final model) train    151507     0.242554  0.243884  0.999975   \n",
      "                                151508     0.242554  0.243884  0.999975   \n",
      "                                151509     0.242554  0.243884  1.000000   \n",
      "                                151510     0.242554  0.243884  0.999975   \n",
      "                                151669     0.242554  0.243884  0.999850   \n",
      "                                151670     0.242554  0.243884  0.999750   \n",
      "                                151671     0.242554  0.243884  0.999700   \n",
      "                                151672     0.242554  0.243884  0.999825   \n",
      "                                151674     0.242554  0.243884  1.000000   \n",
      "                                151676     0.242554  0.243884  0.999950   \n",
      "                       val      151673     0.242554  0.243884  0.999213   \n",
      "                       test     151675     0.242554  0.243884  0.999925   \n",
      "\n",
      "                                                             \\\n",
      "                                              val      test   \n",
      "                       SC Split Sample ID                     \n",
      "Before DA              train    151507     0.9999  1.000000   \n",
      "                                151508     0.9999  1.000000   \n",
      "                                151509     1.0000  1.000000   \n",
      "                                151510     1.0000  0.999461   \n",
      "                                151669     1.0000  1.000000   \n",
      "                                151670     1.0000  1.000000   \n",
      "                                151671     0.9999  1.000000   \n",
      "                                151672     1.0000  1.000000   \n",
      "                                151674     1.0000  1.000000   \n",
      "                                151676     0.9999  1.000000   \n",
      "                       val      151673     1.0000  1.000000   \n",
      "                       test     151675     0.9999  1.000000   \n",
      "After DA (final model) train    151507     0.9993  0.999600   \n",
      "                                151508     0.9998  0.999800   \n",
      "                                151509     0.9992  0.999100   \n",
      "                                151510     0.9995  0.998700   \n",
      "                                151669     1.0000  1.000000   \n",
      "                                151670     1.0000  1.000000   \n",
      "                                151671     0.9996  0.999800   \n",
      "                                151672     0.9998  0.999800   \n",
      "                                151674     1.0000  1.000000   \n",
      "                                151676     0.9997  0.999700   \n",
      "                       val      151673     0.9995  0.999900   \n",
      "                       test     151675     0.9993  0.999800   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA              train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "After DA (final model) train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC Ex1-10)  \n",
      "                                                                     0  \n",
      "                       SC Split Sample ID                               \n",
      "Before DA              train    151507                        0.574676  \n",
      "                                151508                        0.576715  \n",
      "                                151509                        0.553758  \n",
      "                                151510                        0.552640  \n",
      "                                151669                        0.574471  \n",
      "                                151670                        0.581738  \n",
      "                                151671                        0.561079  \n",
      "                                151672                        0.550648  \n",
      "                                151674                        0.591755  \n",
      "                                151676                        0.582961  \n",
      "                       val      151673                        0.598667  \n",
      "                       test     151675                        0.602663  \n",
      "After DA (final model) train    151507                        0.624724  \n",
      "                                151508                        0.606163  \n",
      "                                151509                        0.552560  \n",
      "                                151510                        0.606057  \n",
      "                                151669                        0.608104  \n",
      "                                151670                        0.613650  \n",
      "                                151671                        0.598931  \n",
      "                                151672                        0.585957  \n",
      "                                151674                        0.606549  \n",
      "                                151676                        0.605990  \n",
      "                       val      151673                        0.599750  \n",
      "                       test     151675                        0.619989  \n",
      "Script run time: 0:10:23.169946\n",
      "Tensor(\"MatMul_1:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\n",
      "Evaluating CellDART_original on with -1 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config basic_config.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/dlpfc/GSE144136_spatialLIBD/20markers/8mix_100000spots/minmax/std/24385 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n",
      "/home/wma/CellDART/src/da_utils/evaluator.py:159: UserWarning: Output folder exists. Will overwrite.\n",
      "  self.results_folder = self.temp_folder_holder.set_output_folder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   16.7s remaining:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   17.1s remaining:   51.2s\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  12 | elapsed:   17.1s remaining:   34.2s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   17.3s remaining:   24.3s\n",
      "[Parallel(n_jobs=12)]: Done   6 out of  12 | elapsed:   17.4s remaining:   17.4s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   17.5s remaining:   12.5s\n",
      "[Parallel(n_jobs=12)]: Done   8 out of  12 | elapsed:   17.6s remaining:    8.8s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   17.6s remaining:    5.9s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  12 | elapsed:   17.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   17.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   17.9s finished\n",
      "Calculating domain shift for 151507: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151508: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151509: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151510: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151669: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151670: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151671: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151672: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151674: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151676: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151673: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151675: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507                         0.161803   \n",
      "                                151508                         0.161803   \n",
      "                                151509                         0.161803   \n",
      "                                151510                         0.161803   \n",
      "                                151669                         0.161803   \n",
      "                                151670                         0.161803   \n",
      "                                151671                         0.161803   \n",
      "                                151672                         0.161803   \n",
      "                                151674                         0.161803   \n",
      "                                151676                         0.161803   \n",
      "                       val      151673                         0.161803   \n",
      "                       test     151675                         0.161803   \n",
      "After DA (final model) train    151507                         0.229718   \n",
      "                                151508                         0.229718   \n",
      "                                151509                         0.229718   \n",
      "                                151510                         0.229718   \n",
      "                                151669                         0.229718   \n",
      "                                151670                         0.229718   \n",
      "                                151671                         0.229718   \n",
      "                                151672                         0.229718   \n",
      "                                151674                         0.229718   \n",
      "                                151676                         0.229718   \n",
      "                       val      151673                         0.229718   \n",
      "                       test     151675                         0.229718   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507     0.206999  0.204972  0.999975   \n",
      "                                151508     0.206999  0.204972  1.000000   \n",
      "                                151509     0.206999  0.204972  0.999975   \n",
      "                                151510     0.206999  0.204972  1.000000   \n",
      "                                151669     0.206999  0.204972  0.999950   \n",
      "                                151670     0.206999  0.204972  0.999900   \n",
      "                                151671     0.206999  0.204972  0.999975   \n",
      "                                151672     0.206999  0.204972  0.999925   \n",
      "                                151674     0.206999  0.204972  0.999900   \n",
      "                                151676     0.206999  0.204972  0.999152   \n",
      "                       val      151673     0.206999  0.204972  0.999875   \n",
      "                       test     151675     0.206999  0.204972  0.999850   \n",
      "After DA (final model) train    151507     0.234364  0.236539  0.999825   \n",
      "                                151508     0.234364  0.236539  0.999975   \n",
      "                                151509     0.234364  0.236539  0.999825   \n",
      "                                151510     0.234364  0.236539  0.999800   \n",
      "                                151669     0.234364  0.236539  0.999675   \n",
      "                                151670     0.234364  0.236539  0.999750   \n",
      "                                151671     0.234364  0.236539  0.999750   \n",
      "                                151672     0.234364  0.236539  0.999725   \n",
      "                                151674     0.234364  0.236539  0.999925   \n",
      "                                151676     0.234364  0.236539  0.999875   \n",
      "                       val      151673     0.234364  0.236539  0.999825   \n",
      "                       test     151675     0.234364  0.236539  0.999600   \n",
      "\n",
      "                                                             \\\n",
      "                                                val    test   \n",
      "                       SC Split Sample ID                     \n",
      "Before DA              train    151507     1.000000  1.0000   \n",
      "                                151508     1.000000  1.0000   \n",
      "                                151509     1.000000  1.0000   \n",
      "                                151510     1.000000  1.0000   \n",
      "                                151669     1.000000  1.0000   \n",
      "                                151670     1.000000  1.0000   \n",
      "                                151671     1.000000  1.0000   \n",
      "                                151672     1.000000  1.0000   \n",
      "                                151674     0.999900  1.0000   \n",
      "                                151676     1.000000  1.0000   \n",
      "                       val      151673     1.000000  1.0000   \n",
      "                       test     151675     1.000000  1.0000   \n",
      "After DA (final model) train    151507     0.999800  0.9997   \n",
      "                                151508     1.000000  1.0000   \n",
      "                                151509     1.000000  1.0000   \n",
      "                                151510     0.999700  0.9997   \n",
      "                                151669     0.999600  0.9996   \n",
      "                                151670     0.999400  0.9998   \n",
      "                                151671     0.999092  0.9996   \n",
      "                                151672     0.999277  0.9997   \n",
      "                                151674     0.999900  0.9997   \n",
      "                                151676     0.999500  0.9997   \n",
      "                       val      151673     0.999600  0.9999   \n",
      "                       test     151675     0.999200  0.9994   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA              train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "After DA (final model) train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC Ex1-10)  \n",
      "                                                                     0  \n",
      "                       SC Split Sample ID                               \n",
      "Before DA              train    151507                        0.584982  \n",
      "                                151508                        0.578234  \n",
      "                                151509                        0.540206  \n",
      "                                151510                        0.560666  \n",
      "                                151669                        0.607427  \n",
      "                                151670                        0.623372  \n",
      "                                151671                        0.580914  \n",
      "                                151672                        0.567176  \n",
      "                                151674                        0.605348  \n",
      "                                151676                        0.593112  \n",
      "                       val      151673                        0.605287  \n",
      "                       test     151675                        0.610969  \n",
      "After DA (final model) train    151507                        0.642931  \n",
      "                                151508                        0.618566  \n",
      "                                151509                        0.547787  \n",
      "                                151510                        0.627498  \n",
      "                                151669                        0.697735  \n",
      "                                151670                        0.700027  \n",
      "                                151671                        0.652498  \n",
      "                                151672                        0.625901  \n",
      "                                151674                        0.631658  \n",
      "                                151676                        0.624506  \n",
      "                       val      151673                        0.633169  \n",
      "                       test     151675                        0.635499  \n",
      "Script run time: 0:11:00.180161\n",
      "Tensor(\"MatMul_2:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\n",
      "Evaluating CellDART_original on with -1 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config basic_config.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/dlpfc/GSE144136_spatialLIBD/20markers/8mix_100000spots/minmax/std/284 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n",
      "/home/wma/CellDART/src/da_utils/evaluator.py:159: UserWarning: Output folder exists. Will overwrite.\n",
      "  self.results_folder = self.temp_folder_holder.set_output_folder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   25.4s remaining:  2.1min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   25.4s remaining:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  12 | elapsed:   25.4s remaining:   50.7s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   25.4s remaining:   35.5s\n",
      "[Parallel(n_jobs=12)]: Done   6 out of  12 | elapsed:   25.4s remaining:   25.4s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   25.4s remaining:   18.1s\n",
      "[Parallel(n_jobs=12)]: Done   8 out of  12 | elapsed:   25.4s remaining:   12.7s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   25.4s remaining:    8.5s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  12 | elapsed:   25.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   25.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   25.8s finished\n",
      "Calculating domain shift for 151507: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151508: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151509: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151510: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151669: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151670: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151671: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151672: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151674: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151676: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151673: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151675: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507                         0.161534   \n",
      "                                151508                         0.161534   \n",
      "                                151509                         0.161534   \n",
      "                                151510                         0.161534   \n",
      "                                151669                         0.161534   \n",
      "                                151670                         0.161534   \n",
      "                                151671                         0.161534   \n",
      "                                151672                         0.161534   \n",
      "                                151674                         0.161534   \n",
      "                                151676                         0.161534   \n",
      "                       val      151673                         0.161534   \n",
      "                       test     151675                         0.161534   \n",
      "After DA (final model) train    151507                         0.191696   \n",
      "                                151508                         0.191696   \n",
      "                                151509                         0.191696   \n",
      "                                151510                         0.191696   \n",
      "                                151669                         0.191696   \n",
      "                                151670                         0.191696   \n",
      "                                151671                         0.191696   \n",
      "                                151672                         0.191696   \n",
      "                                151674                         0.191696   \n",
      "                                151676                         0.191696   \n",
      "                       val      151673                         0.191696   \n",
      "                       test     151675                         0.191696   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507     0.207418  0.203573  0.999925   \n",
      "                                151508     0.207418  0.203573  0.999925   \n",
      "                                151509     0.207418  0.203573  0.999950   \n",
      "                                151510     0.207418  0.203573  0.999950   \n",
      "                                151669     0.207418  0.203573  0.999900   \n",
      "                                151670     0.207418  0.203573  0.999875   \n",
      "                                151671     0.207418  0.203573  0.999850   \n",
      "                                151672     0.207418  0.203573  0.999875   \n",
      "                                151674     0.207418  0.203573  0.999800   \n",
      "                                151676     0.207418  0.203573  0.999725   \n",
      "                       val      151673     0.207418  0.203573  0.999013   \n",
      "                       test     151675     0.207418  0.203573  0.999775   \n",
      "After DA (final model) train    151507     0.199219  0.200055  0.998833   \n",
      "                                151508     0.199219  0.200055  0.999375   \n",
      "                                151509     0.199219  0.200055  0.999475   \n",
      "                                151510     0.199219  0.200055  0.999400   \n",
      "                                151669     0.199219  0.200055  0.999925   \n",
      "                                151670     0.199219  0.200055  0.999286   \n",
      "                                151671     0.199219  0.200055  0.999900   \n",
      "                                151672     0.199219  0.200055  0.999725   \n",
      "                                151674     0.199219  0.200055  0.999975   \n",
      "                                151676     0.199219  0.200055  0.999750   \n",
      "                       val      151673     0.199219  0.200055  0.999950   \n",
      "                       test     151675     0.199219  0.200055  0.999775   \n",
      "\n",
      "                                                               \\\n",
      "                                                val      test   \n",
      "                       SC Split Sample ID                       \n",
      "Before DA              train    151507     1.000000  0.999700   \n",
      "                                151508     0.999900  0.999800   \n",
      "                                151509     0.999800  0.999700   \n",
      "                                151510     0.999900  0.999900   \n",
      "                                151669     0.999900  0.999900   \n",
      "                                151670     1.000000  0.999900   \n",
      "                                151671     1.000000  0.999800   \n",
      "                                151672     1.000000  0.999900   \n",
      "                                151674     1.000000  0.999600   \n",
      "                                151676     0.999900  0.999700   \n",
      "                       val      151673     0.999900  0.999800   \n",
      "                       test     151675     0.999900  0.999900   \n",
      "After DA (final model) train    151507     0.999108  0.999600   \n",
      "                                151508     0.998930  0.999300   \n",
      "                                151509     0.999000  0.999178   \n",
      "                                151510     0.999061  0.999500   \n",
      "                                151669     0.999500  1.000000   \n",
      "                                151670     0.999800  0.999600   \n",
      "                                151671     0.999600  0.999292   \n",
      "                                151672     0.998977  0.999900   \n",
      "                                151674     0.999900  0.999900   \n",
      "                                151676     0.999077  0.998900   \n",
      "                       val      151673     0.999800  1.000000   \n",
      "                       test     151675     0.999400  0.999800   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA              train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "After DA (final model) train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC Ex1-10)  \n",
      "                                                                     0  \n",
      "                       SC Split Sample ID                               \n",
      "Before DA              train    151507                        0.616732  \n",
      "                                151508                        0.605777  \n",
      "                                151509                        0.584067  \n",
      "                                151510                        0.596372  \n",
      "                                151669                        0.628846  \n",
      "                                151670                        0.639717  \n",
      "                                151671                        0.599053  \n",
      "                                151672                        0.585638  \n",
      "                                151674                        0.621228  \n",
      "                                151676                        0.610276  \n",
      "                       val      151673                        0.623671  \n",
      "                       test     151675                        0.633652  \n",
      "After DA (final model) train    151507                        0.601873  \n",
      "                                151508                        0.582005  \n",
      "                                151509                        0.530761  \n",
      "                                151510                        0.569611  \n",
      "                                151669                        0.627238  \n",
      "                                151670                        0.625934  \n",
      "                                151671                        0.598691  \n",
      "                                151672                        0.589497  \n",
      "                                151674                        0.623785  \n",
      "                                151676                        0.608798  \n",
      "                       val      151673                        0.615107  \n",
      "                       test     151675                        0.628790  \n",
      "Script run time: 0:11:10.080550\n",
      "Tensor(\"MatMul_3:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\n",
      "Evaluating CellDART_original on with -1 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config basic_config.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/dlpfc/GSE144136_spatialLIBD/20markers/8mix_100000spots/minmax/std/86322 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n",
      "/home/wma/CellDART/src/da_utils/evaluator.py:159: UserWarning: Output folder exists. Will overwrite.\n",
      "  self.results_folder = self.temp_folder_holder.set_output_folder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   26.5s remaining:  2.2min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   26.6s remaining:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  12 | elapsed:   26.8s remaining:   53.5s\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   27.3s remaining:   38.2s\n",
      "[Parallel(n_jobs=12)]: Done   6 out of  12 | elapsed:   27.3s remaining:   27.3s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   27.5s remaining:   19.6s\n",
      "[Parallel(n_jobs=12)]: Done   8 out of  12 | elapsed:   27.6s remaining:   13.8s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   27.8s remaining:    9.3s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  12 | elapsed:   27.8s remaining:    5.6s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   27.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   27.9s finished\n",
      "Calculating domain shift for 151507: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151508: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151509: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151510: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151669: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151670: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151671: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151672: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151674: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151676: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151673: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151675: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507                         0.140565   \n",
      "                                151508                         0.140565   \n",
      "                                151509                         0.140565   \n",
      "                                151510                         0.140565   \n",
      "                                151669                         0.140565   \n",
      "                                151670                         0.140565   \n",
      "                                151671                         0.140565   \n",
      "                                151672                         0.140565   \n",
      "                                151674                         0.140565   \n",
      "                                151676                         0.140565   \n",
      "                       val      151673                         0.140565   \n",
      "                       test     151675                         0.140565   \n",
      "After DA (final model) train    151507                         0.215837   \n",
      "                                151508                         0.215837   \n",
      "                                151509                         0.215837   \n",
      "                                151510                         0.215837   \n",
      "                                151669                         0.215837   \n",
      "                                151670                         0.215837   \n",
      "                                151671                         0.215837   \n",
      "                                151672                         0.215837   \n",
      "                                151674                         0.215837   \n",
      "                                151676                         0.215837   \n",
      "                       val      151673                         0.215837   \n",
      "                       test     151675                         0.215837   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507     0.189678  0.187038  0.999975   \n",
      "                                151508     0.189678  0.187038  0.999975   \n",
      "                                151509     0.189678  0.187038  0.999975   \n",
      "                                151510     0.189678  0.187038  0.999950   \n",
      "                                151669     0.189678  0.187038  0.999950   \n",
      "                                151670     0.189678  0.187038  0.999925   \n",
      "                                151671     0.189678  0.187038  0.999975   \n",
      "                                151672     0.189678  0.187038  0.999975   \n",
      "                                151674     0.189678  0.187038  1.000000   \n",
      "                                151676     0.189678  0.187038  0.999900   \n",
      "                       val      151673     0.189678  0.187038  0.999925   \n",
      "                       test     151675     0.189678  0.187038  0.999975   \n",
      "After DA (final model) train    151507     0.221365  0.221792  0.999775   \n",
      "                                151508     0.221365  0.221792  0.999255   \n",
      "                                151509     0.221365  0.221792  0.999800   \n",
      "                                151510     0.221365  0.221792  0.999800   \n",
      "                                151669     0.221365  0.221792  0.999875   \n",
      "                                151670     0.221365  0.221792  0.998446   \n",
      "                                151671     0.221365  0.221792  0.999950   \n",
      "                                151672     0.221365  0.221792  0.999925   \n",
      "                                151674     0.221365  0.221792  0.999775   \n",
      "                                151676     0.221365  0.221792  0.999700   \n",
      "                       val      151673     0.221365  0.221792  0.999400   \n",
      "                       test     151675     0.221365  0.221792  0.999475   \n",
      "\n",
      "                                                               \\\n",
      "                                                val      test   \n",
      "                       SC Split Sample ID                       \n",
      "Before DA              train    151507     1.000000  0.999900   \n",
      "                                151508     1.000000  1.000000   \n",
      "                                151509     1.000000  1.000000   \n",
      "                                151510     1.000000  1.000000   \n",
      "                                151669     1.000000  1.000000   \n",
      "                                151670     1.000000  0.999900   \n",
      "                                151671     1.000000  0.999900   \n",
      "                                151672     1.000000  1.000000   \n",
      "                                151674     1.000000  1.000000   \n",
      "                                151676     0.999900  1.000000   \n",
      "                       val      151673     0.999900  1.000000   \n",
      "                       test     151675     0.999900  0.999900   \n",
      "After DA (final model) train    151507     0.999300  0.999700   \n",
      "                                151508     0.999900  0.999700   \n",
      "                                151509     0.998800  0.998800   \n",
      "                                151510     0.999400  0.999500   \n",
      "                                151669     1.000000  0.999800   \n",
      "                                151670     0.999800  0.999086   \n",
      "                                151671     0.999900  0.999392   \n",
      "                                151672     0.999277  0.999700   \n",
      "                                151674     0.999400  0.999300   \n",
      "                                151676     0.999500  0.999300   \n",
      "                       val      151673     0.999600  0.999500   \n",
      "                       test     151675     0.998107  0.999600   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA              train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "After DA (final model) train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC Ex1-10)  \n",
      "                                                                     0  \n",
      "                       SC Split Sample ID                               \n",
      "Before DA              train    151507                        0.620060  \n",
      "                                151508                        0.605174  \n",
      "                                151509                        0.563012  \n",
      "                                151510                        0.592656  \n",
      "                                151669                        0.642876  \n",
      "                                151670                        0.658909  \n",
      "                                151671                        0.615628  \n",
      "                                151672                        0.597172  \n",
      "                                151674                        0.618366  \n",
      "                                151676                        0.612033  \n",
      "                       val      151673                        0.628068  \n",
      "                       test     151675                        0.634850  \n",
      "After DA (final model) train    151507                        0.636566  \n",
      "                                151508                        0.609849  \n",
      "                                151509                        0.535670  \n",
      "                                151510                        0.593029  \n",
      "                                151669                        0.664217  \n",
      "                                151670                        0.673268  \n",
      "                                151671                        0.629516  \n",
      "                                151672                        0.614116  \n",
      "                                151674                        0.649611  \n",
      "                                151676                        0.641564  \n",
      "                       val      151673                        0.642515  \n",
      "                       test     151675                        0.672108  \n",
      "Script run time: 0:12:22.801686\n",
      "Tensor(\"MatMul_4:0\", shape=(2, 2), dtype=float32, device=/device:CPU:0)\n",
      "Evaluating CellDART_original on with -1 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config basic_config.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: dlpfc\n",
      "  n_markers: 20\n",
      "  n_mix: 8\n",
      "  n_spots: 100000\n",
      "  samp_split: true\n",
      "  sc_id: GSE144136\n",
      "  scaler_name: minmax\n",
      "  st_id: spatialLIBD\n",
      "  st_split: false\n",
      "lib_params: {}\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: std\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 512\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.001\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: true\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/dlpfc/GSE144136_spatialLIBD/20markers/8mix_100000spots/minmax/std/98237 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n",
      "/home/wma/CellDART/src/da_utils/evaluator.py:159: UserWarning: Output folder exists. Will overwrite.\n",
      "  self.results_folder = self.temp_folder_holder.set_output_folder(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   33.7s remaining:  2.8min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:   34.2s remaining:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  12 | elapsed:   34.2s remaining:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:   34.2s remaining:   47.9s\n",
      "[Parallel(n_jobs=12)]: Done   6 out of  12 | elapsed:   34.2s remaining:   34.2s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:   34.3s remaining:   24.5s\n",
      "[Parallel(n_jobs=12)]: Done   8 out of  12 | elapsed:   34.4s remaining:   17.2s\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:   34.4s remaining:   11.5s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  12 | elapsed:   34.4s remaining:    6.9s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   34.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   34.5s finished\n",
      "Calculating domain shift for 151507: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151508: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151509: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151510: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151669: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151670: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151671: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151672: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151674: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151676: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151673: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for 151675: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507                         0.166780   \n",
      "                                151508                         0.166780   \n",
      "                                151509                         0.166780   \n",
      "                                151510                         0.166780   \n",
      "                                151669                         0.166780   \n",
      "                                151670                         0.166780   \n",
      "                                151671                         0.166780   \n",
      "                                151672                         0.166780   \n",
      "                                151674                         0.166780   \n",
      "                                151676                         0.166780   \n",
      "                       val      151673                         0.166780   \n",
      "                       test     151675                         0.166780   \n",
      "After DA (final model) train    151507                         0.237558   \n",
      "                                151508                         0.237558   \n",
      "                                151509                         0.237558   \n",
      "                                151510                         0.237558   \n",
      "                                151669                         0.237558   \n",
      "                                151670                         0.237558   \n",
      "                                151671                         0.237558   \n",
      "                                151672                         0.237558   \n",
      "                                151674                         0.237558   \n",
      "                                151676                         0.237558   \n",
      "                       val      151673                         0.237558   \n",
      "                       test     151675                         0.237558   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA              train    151507     0.211304  0.208903  0.999975   \n",
      "                                151508     0.211304  0.208903  0.999975   \n",
      "                                151509     0.211304  0.208903  1.000000   \n",
      "                                151510     0.211304  0.208903  0.999975   \n",
      "                                151669     0.211304  0.208903  0.999975   \n",
      "                                151670     0.211304  0.208903  1.000000   \n",
      "                                151671     0.211304  0.208903  1.000000   \n",
      "                                151672     0.211304  0.208903  0.999950   \n",
      "                                151674     0.211304  0.208903  0.999925   \n",
      "                                151676     0.211304  0.208903  1.000000   \n",
      "                       val      151673     0.211304  0.208903  0.999975   \n",
      "                       test     151675     0.211304  0.208903  0.999875   \n",
      "After DA (final model) train    151507     0.242729  0.242864  0.999875   \n",
      "                                151508     0.242729  0.242864  0.999825   \n",
      "                                151509     0.242729  0.242864  1.000000   \n",
      "                                151510     0.242729  0.242864  0.999850   \n",
      "                                151669     0.242729  0.242864  0.999925   \n",
      "                                151670     0.242729  0.242864  0.999950   \n",
      "                                151671     0.242729  0.242864  0.999900   \n",
      "                                151672     0.242729  0.242864  0.999725   \n",
      "                                151674     0.242729  0.242864  0.999925   \n",
      "                                151676     0.242729  0.242864  0.999850   \n",
      "                       val      151673     0.242729  0.242864  0.999850   \n",
      "                       test     151675     0.242729  0.242864  0.999750   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA              train    151507     1.0000  1.0000   \n",
      "                                151508     1.0000  1.0000   \n",
      "                                151509     1.0000  0.9999   \n",
      "                                151510     1.0000  1.0000   \n",
      "                                151669     1.0000  1.0000   \n",
      "                                151670     1.0000  1.0000   \n",
      "                                151671     1.0000  1.0000   \n",
      "                                151672     1.0000  1.0000   \n",
      "                                151674     1.0000  1.0000   \n",
      "                                151676     1.0000  1.0000   \n",
      "                       val      151673     1.0000  1.0000   \n",
      "                       test     151675     1.0000  1.0000   \n",
      "After DA (final model) train    151507     0.9999  0.9997   \n",
      "                                151508     1.0000  1.0000   \n",
      "                                151509     0.9997  0.9999   \n",
      "                                151510     0.9999  0.9998   \n",
      "                                151669     1.0000  0.9999   \n",
      "                                151670     0.9999  0.9999   \n",
      "                                151671     1.0000  0.9999   \n",
      "                                151672     1.0000  0.9999   \n",
      "                                151674     1.0000  1.0000   \n",
      "                                151676     1.0000  1.0000   \n",
      "                       val      151673     1.0000  0.9999   \n",
      "                       test     151675     1.0000  1.0000   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA              train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "After DA (final model) train    151507                       1.0  1.0  1.0   \n",
      "                                151508                       1.0  1.0  1.0   \n",
      "                                151509                       1.0  1.0  1.0   \n",
      "                                151510                       1.0  1.0  1.0   \n",
      "                                151669                       1.0  1.0  1.0   \n",
      "                                151670                       1.0  1.0  1.0   \n",
      "                                151671                       1.0  1.0  1.0   \n",
      "                                151672                       1.0  1.0  1.0   \n",
      "                                151674                       1.0  1.0  1.0   \n",
      "                                151676                       1.0  1.0  1.0   \n",
      "                       val      151673                       1.0  1.0  1.0   \n",
      "                       test     151675                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC Ex1-10)  \n",
      "                                                                     0  \n",
      "                       SC Split Sample ID                               \n",
      "Before DA              train    151507                        0.604078  \n",
      "                                151508                        0.589171  \n",
      "                                151509                        0.560227  \n",
      "                                151510                        0.580904  \n",
      "                                151669                        0.619436  \n",
      "                                151670                        0.640582  \n",
      "                                151671                        0.595598  \n",
      "                                151672                        0.580092  \n",
      "                                151674                        0.607989  \n",
      "                                151676                        0.597800  \n",
      "                       val      151673                        0.608738  \n",
      "                       test     151675                        0.615769  \n",
      "After DA (final model) train    151507                        0.581926  \n",
      "                                151508                        0.595975  \n",
      "                                151509                        0.580088  \n",
      "                                151510                        0.581266  \n",
      "                                151669                        0.585709  \n",
      "                                151670                        0.583326  \n",
      "                                151671                        0.578946  \n",
      "                                151672                        0.567376  \n",
      "                                151674                        0.644390  \n",
      "                                151676                        0.627962  \n",
      "                       val      151673                        0.632373  \n",
      "                       test     151675                        0.646697  \n",
      "Script run time: 0:13:27.563866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "from src.da_models.model_utils.utils import get_metric_ctp\n",
    "from src.da_utils.evaluator import Evaluator\n",
    "\n",
    "\n",
    "metric_ctp = get_metric_ctp(\"cos\")\n",
    "\n",
    "def _device_to_str(device):\n",
    "    return device.name.lstrip(\"/physical_device:\")\n",
    "\n",
    "def get_device(cuda_index=None):\n",
    "    if cuda_index is None:\n",
    "        return _device_to_str(tf.config.list_physical_devices(\"GPU\")[0])\n",
    "\n",
    "    cuda_index = int(cuda_index)\n",
    "\n",
    "    if cuda_index < 0:\n",
    "        return _device_to_str(tf.config.list_physical_devices(\"CPU\")[0])\n",
    "\n",
    "    devices=tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "    if len(devices) > cuda_index:\n",
    "        return _device_to_str(devices[cuda_index])\n",
    "    if len(devices) > 0:\n",
    "        warnings.warn(\"GPU ordinal not valid; using default\", category=UserWarning, stacklevel=2)\n",
    "        return _device_to_str(devices[0])\n",
    "\n",
    "    warnings.warn(\"Using CPU\", category=UserWarning, stacklevel=2)\n",
    "    return _device_to_str(tf.config.list_physical_devices(\"CPU\")[0])\n",
    "\n",
    "def main(args):\n",
    "    evaluator = Evaluator(vars(args), metric_ctp)\n",
    "    evaluator.eval_spots()\n",
    "    evaluator.evaluate_embeddings()\n",
    "    evaluator.eval_sc()\n",
    "\n",
    "    evaluator.produce_results()\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    parser = argparse.ArgumentParser(description=\"Evaluates.\")\n",
    "    parser.add_argument(\"--pretraining\", \"-p\", action=\"store_true\", help=\"force pretraining\")\n",
    "    parser.add_argument(\"--modelname\", \"-n\", type=str, default=\"ADDA\", help=\"model name\")\n",
    "    parser.add_argument(\"--milisi\", \"-m\", action=\"store_false\", help=\"no milisi\")\n",
    "    parser.add_argument(\"--config_fname\", \"-f\", type=str, help=\"Name of the config file to use\")\n",
    "    parser.add_argument(\"--configs_dir\", \"-cdir\", type=str, default=\"configs\", help=\"config dir\")\n",
    "    parser.add_argument(\n",
    "        \"--njobs\", type=int, default=1, help=\"Number of jobs to use for parallel processing.\"\n",
    "    )\n",
    "    parser.add_argument(\"--cuda\", \"-c\", default=None, help=\"GPU index to use\")\n",
    "    parser.add_argument(\"--tmpdir\", \"-d\", default=None, help=\"optional temporary results directory\")\n",
    "    parser.add_argument(\"--test\", \"-t\", action=\"store_true\", help=\"test mode\")\n",
    "    parser.add_argument(\n",
    "        \"--early_stopping\",\n",
    "        \"-e\",\n",
    "        action=\"store_true\",\n",
    "        help=\"evaluate early stopping. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reverse_val\",\n",
    "        \"-r\",\n",
    "        action=\"store_true\",\n",
    "        help=\"use best model through reverse validation. Will use provided\"\n",
    "        \"config file to search across models, then use the one loaded. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\"--model_dir\", default=\"model\", help=\"model directory\")\n",
    "    parser.add_argument(\"--results_dir\", default=\"results\", help=\"results directory\")\n",
    "    parser.add_argument(\n",
    "        \"--seed_override\",\n",
    "        default=None,\n",
    "        help=\"seed to use for torch and numpy; overrides that in config file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ps_seed\",\n",
    "        default=-1,\n",
    "        help=\"specific pseudospot seed to use; default of -1 corresponds to 623\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args([\n",
    "        f\"--modelname={MODEL_NAME}\",\n",
    "        f\"--config_fname={CONFIG_FNAME}\",\n",
    "        \"--njobs=-1\",\n",
    "        \"--test\",\n",
    "        f\"--model_dir={MODEL_DIR}\",\n",
    "        \"--results_dir=results_FINAL\",\n",
    "        f\"--seed_override={model_seed}\",\n",
    "        f\"--ps_seed={ps_seed}\",\n",
    "        f\"--cuda=-1\"\n",
    "    ])\n",
    "\n",
    "    script_start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        level=logging.WARNING,\n",
    "        format=\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\",\n",
    "    )\n",
    "    with tf.device(get_device(args.cuda)):\n",
    "        a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "        print(c)\n",
    "\n",
    "        main(args)\n",
    "    print(\"Script run time:\", datetime.datetime.now(datetime.timezone.utc) - script_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellDART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
