{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellDART Example Code: mouse brain \n",
    "## (10x Visium of anterior mouse brain + scRNA-seq data of mouse brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22086/3903643673.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf  # TensorFlow registers PluggableDevices here.\n",
    "from tqdm.autonotebook import tqdm\n",
    "import yaml\n",
    "\n",
    "from CellDART import da_cellfraction\n",
    "from src.da_utils import data_loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_SEEDS = (3679, 343, 25, 234, 98098)\n",
    "MODEL_SEEDS = (2353, 24385, 284, 86322, 98237)\n",
    "MODEL_DIR = \"model_FINAL\"\n",
    "SEED_OVERRIDE = None\n",
    "\n",
    "CONFIGS_DIR = \"configs\"\n",
    "CONFIG_FNAME = \"celldart-final-pdac-ht.yml\"\n",
    "\n",
    "# BOOTSTRAP = False\n",
    "# BOOTSTRAP_ROUNDS = 10\n",
    "# BOOTSTRAP_ALPHAS = [0.6, 1 / 0.6]\n",
    "\n",
    "MODEL_NAME = \"CellDART_original\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "lib_params = config[\"lib_params\"]\n",
    "data_params = config[\"data_params\"]\n",
    "model_params = config[\"model_params\"]\n",
    "train_params = config[\"train_params\"]\n",
    "\n",
    "rewrite_config = False\n",
    "if not \"pretraining\" in train_params:\n",
    "    train_params[\"pretraining\"] = True\n",
    "    rewrite_config = True\n",
    "if not \"lr\" in train_params:\n",
    "    train_params[\"lr\"] = 0.001\n",
    "    rewrite_config = True\n",
    "\n",
    "if rewrite_config:\n",
    "    with open(os.path.join(CONFIGS_DIR, MODEL_NAME, CONFIG_FNAME), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "tqdm.write(yaml.safe_dump(config))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load\n",
    "### load scanpy data - 10x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS seed: 3679, model seed: 2353\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 2s 16us/sample - loss: 0.1091 - mae: 0.0272\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0247 - mae: 0.0131\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0203 - mae: 0.0121\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0191 - mae: 0.0117\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0184 - mae: 0.0115\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0180 - mae: 0.0113\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0177 - mae: 0.0112\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0174 - mae: 0.0111\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0172 - mae: 0.0110\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0170 - mae: 0.0109\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021543493438661097\n",
      "0.021543493438661097\n",
      "Iteration 99, source loss =  0.755, discriminator acc = 1.000\n",
      "Iteration 199, source loss =  0.307, discriminator acc = 0.682\n",
      "Iteration 299, source loss =  1.147, discriminator acc = 0.827\n",
      "Iteration 399, source loss =  0.222, discriminator acc = 0.832\n",
      "Iteration 499, source loss =  0.327, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.244, discriminator acc = 1.000\n",
      "Iteration 699, source loss =  0.121, discriminator acc = 1.000\n",
      "Iteration 799, source loss =  0.320, discriminator acc = 0.981\n",
      "Iteration 899, source loss =  0.444, discriminator acc = 0.981\n",
      "Iteration 999, source loss =  0.223, discriminator acc = 0.984\n",
      "Iteration 1099, source loss =  0.134, discriminator acc = 0.911\n",
      "Iteration 1199, source loss =  0.354, discriminator acc = 0.995\n",
      "Iteration 1299, source loss =  0.193, discriminator acc = 0.139\n",
      "Iteration 1399, source loss =  0.134, discriminator acc = 0.014\n",
      "Iteration 1499, source loss =  0.090, discriminator acc = 0.970\n",
      "Iteration 1599, source loss =  0.105, discriminator acc = 0.997\n",
      "Iteration 1699, source loss =  0.100, discriminator acc = 0.983\n",
      "Iteration 1799, source loss =  0.101, discriminator acc = 0.273\n",
      "Iteration 1899, source loss =  0.076, discriminator acc = 0.629\n",
      "Iteration 1999, source loss =  0.076, discriminator acc = 0.809\n",
      "Iteration 2099, source loss =  0.070, discriminator acc = 0.801\n",
      "Iteration 2199, source loss =  0.073, discriminator acc = 0.575\n",
      "Iteration 2299, source loss =  0.066, discriminator acc = 0.561\n",
      "Iteration 2399, source loss =  0.065, discriminator acc = 0.641\n",
      "Iteration 2499, source loss =  0.058, discriminator acc = 0.702\n",
      "Iteration 2599, source loss =  0.056, discriminator acc = 0.687\n",
      "Iteration 2699, source loss =  0.057, discriminator acc = 0.455\n",
      "Iteration 2799, source loss =  0.064, discriminator acc = 0.639\n",
      "Iteration 2899, source loss =  0.054, discriminator acc = 0.885\n",
      "Iteration 2999, source loss =  0.052, discriminator acc = 0.812\n",
      "Iteration 3099, source loss =  0.057, discriminator acc = 0.476\n",
      "Iteration 3199, source loss =  0.090, discriminator acc = 0.015\n",
      "Iteration 3299, source loss =  0.120, discriminator acc = 0.994\n",
      "Iteration 3399, source loss =  0.138, discriminator acc = 0.006\n",
      "Iteration 3499, source loss =  0.146, discriminator acc = 0.006\n",
      "Iteration 3599, source loss =  0.069, discriminator acc = 0.173\n",
      "Iteration 3699, source loss =  0.162, discriminator acc = 0.721\n",
      "Iteration 3799, source loss =  0.095, discriminator acc = 0.734\n",
      "Iteration 3899, source loss =  0.076, discriminator acc = 0.768\n",
      "Iteration 3999, source loss =  0.145, discriminator acc = 1.000\n",
      "Iteration 4099, source loss =  0.108, discriminator acc = 1.000\n",
      "Iteration 4199, source loss =  0.117, discriminator acc = 0.015\n",
      "Iteration 4299, source loss =  0.127, discriminator acc = 0.999\n",
      "Iteration 4399, source loss =  0.147, discriminator acc = 1.000\n",
      "Iteration 4499, source loss =  0.106, discriminator acc = 1.000\n",
      "Iteration 4599, source loss =  0.247, discriminator acc = 0.075\n",
      "Iteration 4699, source loss =  0.106, discriminator acc = 1.000\n",
      "Iteration 4799, source loss =  0.138, discriminator acc = 0.999\n",
      "Iteration 4899, source loss =  0.096, discriminator acc = 0.999\n",
      "Iteration 4999, source loss =  0.129, discriminator acc = 0.999\n",
      "Iteration 5099, source loss =  0.144, discriminator acc = 0.006\n",
      "Iteration 5199, source loss =  0.118, discriminator acc = 0.912\n",
      "Iteration 5299, source loss =  0.108, discriminator acc = 0.311\n",
      "Iteration 5399, source loss =  0.115, discriminator acc = 0.658\n",
      "Iteration 5499, source loss =  0.129, discriminator acc = 0.736\n",
      "Iteration 5599, source loss =  0.115, discriminator acc = 0.011\n",
      "Iteration 5699, source loss =  0.107, discriminator acc = 1.000\n",
      "Iteration 5799, source loss =  0.154, discriminator acc = 0.006\n",
      "Iteration 5899, source loss =  0.128, discriminator acc = 0.065\n",
      "Iteration 5999, source loss =  0.092, discriminator acc = 0.952\n",
      "Iteration 6099, source loss =  0.111, discriminator acc = 0.006\n",
      "Iteration 6199, source loss =  0.105, discriminator acc = 0.485\n",
      "Iteration 6299, source loss =  0.092, discriminator acc = 0.046\n",
      "Iteration 6399, source loss =  0.102, discriminator acc = 0.996\n",
      "Iteration 6499, source loss =  0.107, discriminator acc = 0.006\n",
      "Iteration 6599, source loss =  0.083, discriminator acc = 1.000\n",
      "Iteration 6699, source loss =  0.090, discriminator acc = 0.972\n",
      "Iteration 6799, source loss =  0.077, discriminator acc = 0.859\n",
      "Iteration 6899, source loss =  0.087, discriminator acc = 0.997\n",
      "Iteration 6999, source loss =  0.096, discriminator acc = 0.610\n",
      "Iteration 7099, source loss =  0.080, discriminator acc = 0.061\n",
      "Iteration 7199, source loss =  0.108, discriminator acc = 0.426\n",
      "Iteration 7299, source loss =  0.137, discriminator acc = 0.510\n",
      "Iteration 7399, source loss =  0.139, discriminator acc = 0.007\n",
      "Iteration 7499, source loss =  0.087, discriminator acc = 0.006\n",
      "Iteration 7599, source loss =  0.131, discriminator acc = 0.047\n",
      "Iteration 7699, source loss =  0.128, discriminator acc = 0.884\n",
      "Iteration 7799, source loss =  0.149, discriminator acc = 0.006\n",
      "Iteration 7899, source loss =  0.166, discriminator acc = 0.977\n",
      "Iteration 7999, source loss =  0.091, discriminator acc = 0.006\n",
      "Iteration 8099, source loss =  0.081, discriminator acc = 0.980\n",
      "Iteration 8199, source loss =  0.085, discriminator acc = 0.026\n",
      "Iteration 8299, source loss =  0.072, discriminator acc = 0.999\n",
      "Iteration 8399, source loss =  0.080, discriminator acc = 0.018\n",
      "Iteration 8499, source loss =  0.076, discriminator acc = 0.302\n",
      "Iteration 8599, source loss =  0.078, discriminator acc = 0.083\n",
      "Iteration 8699, source loss =  0.114, discriminator acc = 0.472\n",
      "Iteration 8799, source loss =  0.082, discriminator acc = 0.049\n",
      "Iteration 8899, source loss =  0.067, discriminator acc = 0.648\n",
      "Iteration 8999, source loss =  0.088, discriminator acc = 0.967\n",
      "Iteration 9099, source loss =  0.087, discriminator acc = 0.014\n",
      "Iteration 9199, source loss =  0.074, discriminator acc = 0.315\n",
      "Iteration 9299, source loss =  0.066, discriminator acc = 0.321\n",
      "Iteration 9399, source loss =  0.062, discriminator acc = 0.890\n",
      "Iteration 9499, source loss =  0.062, discriminator acc = 0.025\n",
      "Iteration 9599, source loss =  0.062, discriminator acc = 0.715\n",
      "Iteration 9699, source loss =  0.063, discriminator acc = 0.532\n",
      "Iteration 9799, source loss =  0.067, discriminator acc = 0.899\n",
      "Iteration 9899, source loss =  0.069, discriminator acc = 0.266\n",
      "Iteration 9999, source loss =  0.060, discriminator acc = 0.301\n",
      "Iteration 10099, source loss =  0.065, discriminator acc = 0.871\n",
      "Iteration 10199, source loss =  0.059, discriminator acc = 0.857\n",
      "Iteration 10299, source loss =  0.065, discriminator acc = 0.781\n",
      "Iteration 10399, source loss =  0.058, discriminator acc = 0.798\n",
      "Iteration 10499, source loss =  0.070, discriminator acc = 0.975\n",
      "Iteration 10599, source loss =  0.064, discriminator acc = 0.955\n",
      "Iteration 10699, source loss =  0.072, discriminator acc = 0.845\n",
      "Iteration 10799, source loss =  0.071, discriminator acc = 0.880\n",
      "Iteration 10899, source loss =  0.059, discriminator acc = 0.072\n",
      "Iteration 10999, source loss =  0.069, discriminator acc = 0.749\n",
      "Iteration 11099, source loss =  0.068, discriminator acc = 0.813\n",
      "Iteration 11199, source loss =  0.173, discriminator acc = 0.334\n",
      "Iteration 11299, source loss =  0.104, discriminator acc = 0.954\n",
      "Iteration 11399, source loss =  0.097, discriminator acc = 0.006\n",
      "Iteration 11499, source loss =  0.197, discriminator acc = 0.076\n",
      "Iteration 11599, source loss =  0.198, discriminator acc = 0.117\n",
      "Iteration 11699, source loss =  0.108, discriminator acc = 0.006\n",
      "Iteration 11799, source loss =  0.185, discriminator acc = 0.999\n",
      "Iteration 11899, source loss =  0.110, discriminator acc = 0.962\n",
      "Iteration 11999, source loss =  0.108, discriminator acc = 0.993\n",
      "Iteration 12099, source loss =  0.102, discriminator acc = 0.904\n",
      "Iteration 12199, source loss =  0.151, discriminator acc = 0.985\n",
      "Iteration 12299, source loss =  0.104, discriminator acc = 0.900\n",
      "Iteration 12399, source loss =  0.081, discriminator acc = 0.034\n",
      "Iteration 12499, source loss =  0.118, discriminator acc = 0.010\n",
      "Iteration 12599, source loss =  0.097, discriminator acc = 0.999\n",
      "Iteration 12699, source loss =  0.173, discriminator acc = 0.386\n",
      "Iteration 12799, source loss =  0.128, discriminator acc = 0.990\n",
      "Iteration 12899, source loss =  0.079, discriminator acc = 0.629\n",
      "Iteration 12999, source loss =  0.078, discriminator acc = 0.930\n",
      "Iteration 13099, source loss =  0.081, discriminator acc = 0.451\n",
      "Iteration 13199, source loss =  0.062, discriminator acc = 0.716\n",
      "Iteration 13299, source loss =  0.075, discriminator acc = 0.751\n",
      "Iteration 13399, source loss =  0.091, discriminator acc = 0.090\n",
      "Iteration 13499, source loss =  0.064, discriminator acc = 0.685\n",
      "Iteration 13599, source loss =  0.063, discriminator acc = 0.674\n",
      "Iteration 13699, source loss =  0.066, discriminator acc = 0.886\n",
      "Iteration 13799, source loss =  0.063, discriminator acc = 0.945\n",
      "Iteration 13899, source loss =  0.055, discriminator acc = 0.741\n",
      "Iteration 13999, source loss =  0.056, discriminator acc = 0.931\n",
      "Iteration 14099, source loss =  0.073, discriminator acc = 0.773\n",
      "Iteration 14199, source loss =  0.086, discriminator acc = 0.595\n",
      "Iteration 14299, source loss =  0.070, discriminator acc = 0.860\n",
      "Iteration 14399, source loss =  0.065, discriminator acc = 0.848\n",
      "Iteration 14499, source loss =  0.065, discriminator acc = 0.981\n",
      "Iteration 14599, source loss =  0.063, discriminator acc = 0.872\n",
      "Iteration 14699, source loss =  0.068, discriminator acc = 0.734\n",
      "Iteration 14799, source loss =  0.074, discriminator acc = 0.373\n",
      "Iteration 14899, source loss =  0.107, discriminator acc = 0.985\n",
      "Iteration 14999, source loss =  0.074, discriminator acc = 0.972\n",
      "PS seed: 343, model seed: 24385\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/24385\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.1040 - mae: 0.0264\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0240 - mae: 0.0130\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0203 - mae: 0.0120\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0191 - mae: 0.0117\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0184 - mae: 0.0114\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0180 - mae: 0.0112\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0177 - mae: 0.0111\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0174 - mae: 0.0110\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0172 - mae: 0.0109\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0170 - mae: 0.0109\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02375203073322773\n",
      "0.02375203073322773\n",
      "Iteration 99, source loss =  0.889, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.364, discriminator acc = 0.006\n",
      "Iteration 299, source loss =  0.678, discriminator acc = 0.007\n",
      "Iteration 399, source loss =  0.564, discriminator acc = 0.006\n",
      "Iteration 499, source loss =  0.309, discriminator acc = 0.006\n",
      "Iteration 599, source loss =  0.200, discriminator acc = 0.014\n",
      "Iteration 699, source loss =  0.240, discriminator acc = 0.793\n",
      "Iteration 799, source loss =  0.322, discriminator acc = 0.386\n",
      "Iteration 899, source loss =  0.122, discriminator acc = 0.006\n",
      "Iteration 999, source loss =  0.151, discriminator acc = 0.006\n",
      "Iteration 1099, source loss =  0.387, discriminator acc = 0.006\n",
      "Iteration 1199, source loss =  0.127, discriminator acc = 0.913\n",
      "Iteration 1299, source loss =  0.161, discriminator acc = 0.006\n",
      "Iteration 1399, source loss =  0.203, discriminator acc = 0.994\n",
      "Iteration 1499, source loss =  0.177, discriminator acc = 0.983\n",
      "Iteration 1599, source loss =  0.151, discriminator acc = 0.008\n",
      "Iteration 1699, source loss =  0.101, discriminator acc = 0.007\n",
      "Iteration 1799, source loss =  0.178, discriminator acc = 0.006\n",
      "Iteration 1899, source loss =  0.147, discriminator acc = 0.006\n",
      "Iteration 1999, source loss =  0.095, discriminator acc = 1.000\n",
      "Iteration 2099, source loss =  0.089, discriminator acc = 1.000\n",
      "Iteration 2199, source loss =  0.117, discriminator acc = 0.915\n",
      "Iteration 2299, source loss =  0.091, discriminator acc = 0.997\n",
      "Iteration 2399, source loss =  0.098, discriminator acc = 1.000\n",
      "Iteration 2499, source loss =  0.100, discriminator acc = 0.005\n",
      "Iteration 2599, source loss =  0.128, discriminator acc = 0.857\n",
      "Iteration 2699, source loss =  0.111, discriminator acc = 0.059\n",
      "Iteration 2799, source loss =  0.096, discriminator acc = 0.053\n",
      "Iteration 2899, source loss =  0.143, discriminator acc = 0.046\n",
      "Iteration 2999, source loss =  0.130, discriminator acc = 0.199\n",
      "Iteration 3099, source loss =  0.111, discriminator acc = 1.000\n",
      "Iteration 3199, source loss =  0.094, discriminator acc = 0.006\n",
      "Iteration 3299, source loss =  0.140, discriminator acc = 0.999\n",
      "Iteration 3399, source loss =  0.088, discriminator acc = 0.006\n",
      "Iteration 3499, source loss =  0.073, discriminator acc = 0.999\n",
      "Iteration 3599, source loss =  0.086, discriminator acc = 0.993\n",
      "Iteration 3699, source loss =  0.103, discriminator acc = 0.954\n",
      "Iteration 3799, source loss =  0.086, discriminator acc = 0.645\n",
      "Iteration 3899, source loss =  0.135, discriminator acc = 0.087\n",
      "Iteration 3999, source loss =  0.092, discriminator acc = 0.996\n",
      "Iteration 4099, source loss =  0.102, discriminator acc = 0.006\n",
      "Iteration 4199, source loss =  0.129, discriminator acc = 0.006\n",
      "Iteration 4299, source loss =  0.142, discriminator acc = 0.008\n",
      "Iteration 4399, source loss =  0.133, discriminator acc = 0.006\n",
      "Iteration 4499, source loss =  0.090, discriminator acc = 0.711\n",
      "Iteration 4599, source loss =  0.091, discriminator acc = 0.988\n",
      "Iteration 4699, source loss =  0.099, discriminator acc = 0.016\n",
      "Iteration 4799, source loss =  0.082, discriminator acc = 1.000\n",
      "Iteration 4899, source loss =  0.159, discriminator acc = 0.569\n",
      "Iteration 4999, source loss =  0.109, discriminator acc = 0.590\n",
      "Iteration 5099, source loss =  0.122, discriminator acc = 0.913\n",
      "Iteration 5199, source loss =  0.123, discriminator acc = 1.000\n",
      "Iteration 5299, source loss =  0.114, discriminator acc = 0.006\n",
      "Iteration 5399, source loss =  0.114, discriminator acc = 0.006\n",
      "Iteration 5499, source loss =  0.083, discriminator acc = 0.975\n",
      "Iteration 5599, source loss =  0.090, discriminator acc = 0.756\n",
      "Iteration 5699, source loss =  0.090, discriminator acc = 0.909\n",
      "Iteration 5799, source loss =  0.092, discriminator acc = 0.006\n",
      "Iteration 5899, source loss =  0.104, discriminator acc = 0.198\n",
      "Iteration 5999, source loss =  0.088, discriminator acc = 0.934\n",
      "Iteration 6099, source loss =  0.089, discriminator acc = 0.006\n",
      "Iteration 6199, source loss =  0.097, discriminator acc = 0.999\n",
      "Iteration 6299, source loss =  0.099, discriminator acc = 0.882\n",
      "Iteration 6399, source loss =  0.070, discriminator acc = 1.000\n",
      "Iteration 6499, source loss =  0.088, discriminator acc = 0.986\n",
      "Iteration 6599, source loss =  0.076, discriminator acc = 0.985\n",
      "Iteration 6699, source loss =  0.072, discriminator acc = 0.977\n",
      "Iteration 6799, source loss =  0.073, discriminator acc = 0.179\n",
      "Iteration 6899, source loss =  0.073, discriminator acc = 0.959\n",
      "Iteration 6999, source loss =  0.079, discriminator acc = 0.936\n",
      "Iteration 7099, source loss =  0.074, discriminator acc = 0.999\n",
      "Iteration 7199, source loss =  0.082, discriminator acc = 0.437\n",
      "Iteration 7299, source loss =  0.069, discriminator acc = 0.807\n",
      "Iteration 7399, source loss =  0.070, discriminator acc = 0.870\n",
      "Iteration 7499, source loss =  0.083, discriminator acc = 0.093\n",
      "Iteration 7599, source loss =  0.067, discriminator acc = 0.782\n",
      "Iteration 7699, source loss =  0.071, discriminator acc = 0.039\n",
      "Iteration 7799, source loss =  0.069, discriminator acc = 0.922\n",
      "Iteration 7899, source loss =  0.073, discriminator acc = 0.976\n",
      "Iteration 7999, source loss =  0.074, discriminator acc = 0.701\n",
      "Iteration 8099, source loss =  0.069, discriminator acc = 0.810\n",
      "Iteration 8199, source loss =  0.085, discriminator acc = 0.613\n",
      "Iteration 8299, source loss =  0.144, discriminator acc = 0.057\n",
      "Iteration 8399, source loss =  0.086, discriminator acc = 0.020\n",
      "Iteration 8499, source loss =  0.069, discriminator acc = 0.954\n",
      "Iteration 8599, source loss =  0.110, discriminator acc = 0.452\n",
      "Iteration 8699, source loss =  0.085, discriminator acc = 0.006\n",
      "Iteration 8799, source loss =  0.100, discriminator acc = 0.928\n",
      "Iteration 8899, source loss =  0.103, discriminator acc = 0.983\n",
      "Iteration 8999, source loss =  0.073, discriminator acc = 0.903\n",
      "Iteration 9099, source loss =  0.070, discriminator acc = 0.929\n",
      "Iteration 9199, source loss =  0.070, discriminator acc = 0.847\n",
      "Iteration 9299, source loss =  0.076, discriminator acc = 0.229\n",
      "Iteration 9399, source loss =  0.072, discriminator acc = 0.791\n",
      "Iteration 9499, source loss =  0.068, discriminator acc = 0.800\n",
      "Iteration 9599, source loss =  0.077, discriminator acc = 0.985\n",
      "Iteration 9699, source loss =  0.079, discriminator acc = 0.553\n",
      "Iteration 9799, source loss =  0.076, discriminator acc = 0.996\n",
      "Iteration 9899, source loss =  0.066, discriminator acc = 0.939\n",
      "Iteration 9999, source loss =  0.120, discriminator acc = 0.532\n",
      "Iteration 10099, source loss =  0.122, discriminator acc = 0.004\n",
      "Iteration 10199, source loss =  0.085, discriminator acc = 0.995\n",
      "Iteration 10299, source loss =  0.074, discriminator acc = 0.981\n",
      "Iteration 10399, source loss =  0.191, discriminator acc = 0.009\n",
      "Iteration 10499, source loss =  0.129, discriminator acc = 0.007\n",
      "Iteration 10599, source loss =  0.159, discriminator acc = 0.006\n",
      "Iteration 10699, source loss =  0.144, discriminator acc = 0.901\n",
      "Iteration 10799, source loss =  0.096, discriminator acc = 1.000\n",
      "Iteration 10899, source loss =  0.091, discriminator acc = 0.989\n",
      "Iteration 10999, source loss =  0.093, discriminator acc = 0.997\n",
      "Iteration 11099, source loss =  0.214, discriminator acc = 0.034\n",
      "Iteration 11199, source loss =  0.081, discriminator acc = 0.996\n",
      "Iteration 11299, source loss =  0.082, discriminator acc = 0.921\n",
      "Iteration 11399, source loss =  0.074, discriminator acc = 1.000\n",
      "Iteration 11499, source loss =  0.131, discriminator acc = 0.006\n",
      "Iteration 11599, source loss =  0.089, discriminator acc = 0.010\n",
      "Iteration 11699, source loss =  0.079, discriminator acc = 0.999\n",
      "Iteration 11799, source loss =  0.073, discriminator acc = 0.006\n",
      "Iteration 11899, source loss =  0.061, discriminator acc = 0.981\n",
      "Iteration 11999, source loss =  0.068, discriminator acc = 0.028\n",
      "Iteration 12099, source loss =  0.063, discriminator acc = 0.564\n",
      "Iteration 12199, source loss =  0.059, discriminator acc = 0.511\n",
      "Iteration 12299, source loss =  0.059, discriminator acc = 0.901\n",
      "Iteration 12399, source loss =  0.058, discriminator acc = 0.750\n",
      "Iteration 12499, source loss =  0.057, discriminator acc = 0.496\n",
      "Iteration 12599, source loss =  0.059, discriminator acc = 0.458\n",
      "Iteration 12699, source loss =  0.060, discriminator acc = 0.488\n",
      "Iteration 12799, source loss =  0.060, discriminator acc = 0.737\n",
      "Iteration 12899, source loss =  0.060, discriminator acc = 0.887\n",
      "Iteration 12999, source loss =  0.059, discriminator acc = 0.998\n",
      "Iteration 13099, source loss =  0.065, discriminator acc = 0.924\n",
      "Iteration 13199, source loss =  0.061, discriminator acc = 0.940\n",
      "Iteration 13299, source loss =  0.061, discriminator acc = 0.938\n",
      "Iteration 13399, source loss =  0.073, discriminator acc = 0.937\n",
      "Iteration 13499, source loss =  0.064, discriminator acc = 0.935\n",
      "Iteration 13599, source loss =  0.072, discriminator acc = 0.762\n",
      "Iteration 13699, source loss =  0.065, discriminator acc = 0.997\n",
      "Iteration 13799, source loss =  0.102, discriminator acc = 0.993\n",
      "Iteration 13899, source loss =  0.087, discriminator acc = 0.690\n",
      "Iteration 13999, source loss =  0.197, discriminator acc = 0.809\n",
      "Iteration 14099, source loss =  0.107, discriminator acc = 0.050\n",
      "Iteration 14199, source loss =  0.084, discriminator acc = 0.623\n",
      "Iteration 14299, source loss =  0.122, discriminator acc = 1.000\n",
      "Iteration 14399, source loss =  0.208, discriminator acc = 0.006\n",
      "Iteration 14499, source loss =  0.301, discriminator acc = 0.991\n",
      "Iteration 14599, source loss =  0.255, discriminator acc = 0.791\n",
      "Iteration 14699, source loss =  0.134, discriminator acc = 0.874\n",
      "Iteration 14799, source loss =  0.128, discriminator acc = 0.007\n",
      "Iteration 14899, source loss =  0.143, discriminator acc = 0.006\n",
      "Iteration 14999, source loss =  0.150, discriminator acc = 0.364\n",
      "PS seed: 25, model seed: 284\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/284\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.1166 - mae: 0.0299\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0245 - mae: 0.0132\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0208 - mae: 0.0122\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0194 - mae: 0.0118\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 10us/sample - loss: 0.0187 - mae: 0.0115\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0182 - mae: 0.0113\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0178 - mae: 0.0112\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0175 - mae: 0.0111\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0173 - mae: 0.0110\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0171 - mae: 0.0109\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021420157658457756\n",
      "0.021420157658457756\n",
      "Iteration 99, source loss =  0.489, discriminator acc = 0.370\n",
      "Iteration 199, source loss =  0.652, discriminator acc = 1.000\n",
      "Iteration 299, source loss =  0.208, discriminator acc = 1.000\n",
      "Iteration 399, source loss =  0.229, discriminator acc = 1.000\n",
      "Iteration 499, source loss =  0.224, discriminator acc = 1.000\n",
      "Iteration 599, source loss =  0.116, discriminator acc = 1.000\n",
      "Iteration 699, source loss =  0.367, discriminator acc = 1.000\n",
      "Iteration 799, source loss =  0.123, discriminator acc = 1.000\n",
      "Iteration 899, source loss =  0.132, discriminator acc = 1.000\n",
      "Iteration 999, source loss =  0.102, discriminator acc = 0.088\n",
      "Iteration 1099, source loss =  0.564, discriminator acc = 0.990\n",
      "Iteration 1199, source loss =  0.137, discriminator acc = 1.000\n",
      "Iteration 1299, source loss =  0.200, discriminator acc = 0.130\n",
      "Iteration 1399, source loss =  0.199, discriminator acc = 0.999\n",
      "Iteration 1499, source loss =  0.187, discriminator acc = 0.999\n",
      "Iteration 1599, source loss =  0.163, discriminator acc = 0.389\n",
      "Iteration 1699, source loss =  0.107, discriminator acc = 0.993\n",
      "Iteration 1799, source loss =  0.136, discriminator acc = 0.695\n",
      "Iteration 1899, source loss =  0.152, discriminator acc = 0.005\n",
      "Iteration 1999, source loss =  0.068, discriminator acc = 0.970\n",
      "Iteration 2099, source loss =  0.087, discriminator acc = 0.998\n",
      "Iteration 2199, source loss =  0.107, discriminator acc = 0.042\n",
      "Iteration 2299, source loss =  0.111, discriminator acc = 0.016\n",
      "Iteration 2399, source loss =  0.067, discriminator acc = 0.979\n",
      "Iteration 2499, source loss =  0.071, discriminator acc = 0.977\n",
      "Iteration 2599, source loss =  0.094, discriminator acc = 0.870\n",
      "Iteration 2699, source loss =  0.072, discriminator acc = 0.954\n",
      "Iteration 2799, source loss =  0.074, discriminator acc = 0.996\n",
      "Iteration 2899, source loss =  0.086, discriminator acc = 0.029\n",
      "Iteration 2999, source loss =  0.104, discriminator acc = 1.000\n",
      "Iteration 3099, source loss =  0.109, discriminator acc = 0.997\n",
      "Iteration 3199, source loss =  0.095, discriminator acc = 0.999\n",
      "Iteration 3299, source loss =  0.072, discriminator acc = 0.997\n",
      "Iteration 3399, source loss =  0.066, discriminator acc = 1.000\n",
      "Iteration 3499, source loss =  0.098, discriminator acc = 0.997\n",
      "Iteration 3599, source loss =  0.121, discriminator acc = 1.000\n",
      "Iteration 3699, source loss =  0.105, discriminator acc = 1.000\n",
      "Iteration 3799, source loss =  0.108, discriminator acc = 1.000\n",
      "Iteration 3899, source loss =  0.101, discriminator acc = 1.000\n",
      "Iteration 3999, source loss =  0.118, discriminator acc = 0.992\n",
      "Iteration 4099, source loss =  0.149, discriminator acc = 0.093\n",
      "Iteration 4199, source loss =  0.106, discriminator acc = 0.959\n",
      "Iteration 4299, source loss =  0.228, discriminator acc = 0.087\n",
      "Iteration 4399, source loss =  0.121, discriminator acc = 0.746\n",
      "Iteration 4499, source loss =  0.088, discriminator acc = 1.000\n",
      "Iteration 4599, source loss =  0.288, discriminator acc = 0.006\n",
      "Iteration 4699, source loss =  0.128, discriminator acc = 1.000\n",
      "Iteration 4799, source loss =  0.100, discriminator acc = 1.000\n",
      "Iteration 4899, source loss =  0.199, discriminator acc = 0.006\n",
      "Iteration 4999, source loss =  0.086, discriminator acc = 0.999\n",
      "Iteration 5099, source loss =  0.109, discriminator acc = 0.451\n",
      "Iteration 5199, source loss =  0.072, discriminator acc = 0.998\n",
      "Iteration 5299, source loss =  0.121, discriminator acc = 0.005\n",
      "Iteration 5399, source loss =  0.088, discriminator acc = 0.351\n",
      "Iteration 5499, source loss =  0.078, discriminator acc = 0.044\n",
      "Iteration 5599, source loss =  0.072, discriminator acc = 0.108\n",
      "Iteration 5699, source loss =  0.090, discriminator acc = 0.867\n",
      "Iteration 5799, source loss =  0.066, discriminator acc = 1.000\n",
      "Iteration 5899, source loss =  0.079, discriminator acc = 0.006\n",
      "Iteration 5999, source loss =  0.069, discriminator acc = 0.204\n",
      "Iteration 6099, source loss =  0.082, discriminator acc = 0.961\n",
      "Iteration 6199, source loss =  0.118, discriminator acc = 1.000\n",
      "Iteration 6299, source loss =  0.129, discriminator acc = 0.245\n",
      "Iteration 6399, source loss =  0.101, discriminator acc = 0.036\n",
      "Iteration 6499, source loss =  0.070, discriminator acc = 0.999\n",
      "Iteration 6599, source loss =  0.100, discriminator acc = 0.025\n",
      "Iteration 6699, source loss =  0.110, discriminator acc = 0.998\n",
      "Iteration 6799, source loss =  0.144, discriminator acc = 1.000\n",
      "Iteration 6899, source loss =  0.118, discriminator acc = 0.009\n",
      "Iteration 6999, source loss =  0.112, discriminator acc = 0.998\n",
      "Iteration 7099, source loss =  0.073, discriminator acc = 0.988\n",
      "Iteration 7199, source loss =  0.124, discriminator acc = 0.009\n",
      "Iteration 7299, source loss =  0.116, discriminator acc = 0.999\n",
      "Iteration 7399, source loss =  0.070, discriminator acc = 0.470\n",
      "Iteration 7499, source loss =  0.111, discriminator acc = 1.000\n",
      "Iteration 7599, source loss =  0.087, discriminator acc = 0.006\n",
      "Iteration 7699, source loss =  0.079, discriminator acc = 0.972\n",
      "Iteration 7799, source loss =  0.162, discriminator acc = 0.984\n",
      "Iteration 7899, source loss =  0.074, discriminator acc = 0.020\n",
      "Iteration 7999, source loss =  0.073, discriminator acc = 0.485\n",
      "Iteration 8099, source loss =  0.154, discriminator acc = 0.063\n",
      "Iteration 8199, source loss =  0.089, discriminator acc = 0.009\n",
      "Iteration 8299, source loss =  0.089, discriminator acc = 0.914\n",
      "Iteration 8399, source loss =  0.092, discriminator acc = 0.941\n",
      "Iteration 8499, source loss =  0.075, discriminator acc = 0.846\n",
      "Iteration 8599, source loss =  0.104, discriminator acc = 0.010\n",
      "Iteration 8699, source loss =  0.081, discriminator acc = 0.175\n",
      "Iteration 8799, source loss =  0.068, discriminator acc = 0.975\n",
      "Iteration 8899, source loss =  0.077, discriminator acc = 0.344\n",
      "Iteration 8999, source loss =  0.100, discriminator acc = 0.987\n",
      "Iteration 9099, source loss =  0.160, discriminator acc = 0.177\n",
      "Iteration 9199, source loss =  0.101, discriminator acc = 0.904\n",
      "Iteration 9299, source loss =  0.107, discriminator acc = 0.994\n",
      "Iteration 9399, source loss =  0.078, discriminator acc = 0.877\n",
      "Iteration 9499, source loss =  0.114, discriminator acc = 0.603\n",
      "Iteration 9599, source loss =  0.148, discriminator acc = 0.813\n",
      "Iteration 9699, source loss =  0.117, discriminator acc = 0.584\n",
      "Iteration 9799, source loss =  0.214, discriminator acc = 0.992\n",
      "Iteration 9899, source loss =  0.126, discriminator acc = 0.006\n",
      "Iteration 9999, source loss =  0.077, discriminator acc = 0.919\n",
      "Iteration 10099, source loss =  0.080, discriminator acc = 0.007\n",
      "Iteration 10199, source loss =  0.066, discriminator acc = 0.973\n",
      "Iteration 10299, source loss =  0.088, discriminator acc = 0.997\n",
      "Iteration 10399, source loss =  0.073, discriminator acc = 0.006\n",
      "Iteration 10499, source loss =  0.109, discriminator acc = 0.787\n",
      "Iteration 10599, source loss =  0.126, discriminator acc = 0.014\n",
      "Iteration 10699, source loss =  0.069, discriminator acc = 0.007\n",
      "Iteration 10799, source loss =  0.082, discriminator acc = 0.939\n",
      "Iteration 10899, source loss =  0.084, discriminator acc = 0.097\n",
      "Iteration 10999, source loss =  0.069, discriminator acc = 0.913\n",
      "Iteration 11099, source loss =  0.149, discriminator acc = 0.121\n",
      "Iteration 11199, source loss =  0.076, discriminator acc = 0.622\n",
      "Iteration 11299, source loss =  0.081, discriminator acc = 0.998\n",
      "Iteration 11399, source loss =  0.073, discriminator acc = 0.450\n",
      "Iteration 11499, source loss =  0.072, discriminator acc = 0.866\n",
      "Iteration 11599, source loss =  0.115, discriminator acc = 0.955\n",
      "Iteration 11699, source loss =  0.068, discriminator acc = 0.299\n",
      "Iteration 11799, source loss =  0.096, discriminator acc = 0.156\n",
      "Iteration 11899, source loss =  0.064, discriminator acc = 0.631\n",
      "Iteration 11999, source loss =  0.069, discriminator acc = 0.964\n",
      "Iteration 12099, source loss =  0.064, discriminator acc = 0.926\n",
      "Iteration 12199, source loss =  0.062, discriminator acc = 0.929\n",
      "Iteration 12299, source loss =  0.065, discriminator acc = 0.032\n",
      "Iteration 12399, source loss =  0.058, discriminator acc = 0.915\n",
      "Iteration 12499, source loss =  0.068, discriminator acc = 0.946\n",
      "Iteration 12599, source loss =  0.070, discriminator acc = 0.791\n",
      "Iteration 12699, source loss =  0.074, discriminator acc = 0.218\n",
      "Iteration 12799, source loss =  0.061, discriminator acc = 0.007\n",
      "Iteration 12899, source loss =  0.076, discriminator acc = 0.616\n",
      "Iteration 12999, source loss =  0.081, discriminator acc = 0.272\n",
      "Iteration 13099, source loss =  0.061, discriminator acc = 0.981\n",
      "Iteration 13199, source loss =  0.062, discriminator acc = 0.854\n",
      "Iteration 13299, source loss =  0.095, discriminator acc = 0.204\n",
      "Iteration 13399, source loss =  0.076, discriminator acc = 0.208\n",
      "Iteration 13499, source loss =  0.213, discriminator acc = 0.908\n",
      "Iteration 13599, source loss =  0.141, discriminator acc = 0.006\n",
      "Iteration 13699, source loss =  0.099, discriminator acc = 0.794\n",
      "Iteration 13799, source loss =  0.143, discriminator acc = 0.006\n",
      "Iteration 13899, source loss =  0.086, discriminator acc = 0.990\n",
      "Iteration 13999, source loss =  0.136, discriminator acc = 0.040\n",
      "Iteration 14099, source loss =  0.069, discriminator acc = 0.970\n",
      "Iteration 14199, source loss =  0.083, discriminator acc = 0.010\n",
      "Iteration 14299, source loss =  0.122, discriminator acc = 0.774\n",
      "Iteration 14399, source loss =  0.174, discriminator acc = 0.293\n",
      "Iteration 14499, source loss =  0.086, discriminator acc = 0.929\n",
      "Iteration 14599, source loss =  0.082, discriminator acc = 0.026\n",
      "Iteration 14699, source loss =  0.086, discriminator acc = 0.999\n",
      "Iteration 14799, source loss =  0.193, discriminator acc = 0.992\n",
      "Iteration 14899, source loss =  0.076, discriminator acc = 0.960\n",
      "Iteration 14999, source loss =  0.076, discriminator acc = 0.999\n",
      "PS seed: 234, model seed: 86322\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/86322\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 14us/sample - loss: 0.0976 - mae: 0.0257\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0236 - mae: 0.0128\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0202 - mae: 0.0120\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0190 - mae: 0.0116\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0184 - mae: 0.0114\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0180 - mae: 0.0112\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 11us/sample - loss: 0.0176 - mae: 0.0111\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0174 - mae: 0.0110\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0171 - mae: 0.0109\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0170 - mae: 0.0109\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01992515220373869\n",
      "0.01992515220373869\n",
      "Iteration 99, source loss =  1.127, discriminator acc = 0.991\n",
      "Iteration 199, source loss =  0.994, discriminator acc = 0.880\n",
      "Iteration 299, source loss =  0.446, discriminator acc = 0.998\n",
      "Iteration 399, source loss =  0.406, discriminator acc = 1.000\n",
      "Iteration 499, source loss =  0.393, discriminator acc = 0.015\n",
      "Iteration 599, source loss =  0.304, discriminator acc = 0.983\n",
      "Iteration 699, source loss =  0.224, discriminator acc = 1.000\n",
      "Iteration 799, source loss =  0.307, discriminator acc = 0.930\n",
      "Iteration 899, source loss =  0.126, discriminator acc = 0.950\n",
      "Iteration 999, source loss =  0.237, discriminator acc = 0.999\n",
      "Iteration 1099, source loss =  0.232, discriminator acc = 0.996\n",
      "Iteration 1199, source loss =  0.101, discriminator acc = 0.979\n",
      "Iteration 1299, source loss =  0.176, discriminator acc = 0.996\n",
      "Iteration 1399, source loss =  0.115, discriminator acc = 0.003\n",
      "Iteration 1499, source loss =  0.076, discriminator acc = 0.311\n",
      "Iteration 1599, source loss =  0.077, discriminator acc = 0.992\n",
      "Iteration 1699, source loss =  0.084, discriminator acc = 0.883\n",
      "Iteration 1799, source loss =  0.080, discriminator acc = 0.162\n",
      "Iteration 1899, source loss =  0.074, discriminator acc = 0.139\n",
      "Iteration 1999, source loss =  0.065, discriminator acc = 0.430\n",
      "Iteration 2099, source loss =  0.065, discriminator acc = 0.394\n",
      "Iteration 2199, source loss =  0.074, discriminator acc = 0.891\n",
      "Iteration 2299, source loss =  0.059, discriminator acc = 0.783\n",
      "Iteration 2399, source loss =  0.060, discriminator acc = 0.793\n",
      "Iteration 2499, source loss =  0.059, discriminator acc = 0.871\n",
      "Iteration 2599, source loss =  0.059, discriminator acc = 0.982\n",
      "Iteration 2699, source loss =  0.067, discriminator acc = 0.980\n",
      "Iteration 2799, source loss =  0.087, discriminator acc = 0.524\n",
      "Iteration 2899, source loss =  0.084, discriminator acc = 0.506\n",
      "Iteration 2999, source loss =  0.133, discriminator acc = 0.003\n",
      "Iteration 3099, source loss =  0.110, discriminator acc = 0.003\n",
      "Iteration 3199, source loss =  0.158, discriminator acc = 0.006\n",
      "Iteration 3299, source loss =  0.067, discriminator acc = 0.949\n",
      "Iteration 3399, source loss =  0.144, discriminator acc = 0.003\n",
      "Iteration 3499, source loss =  0.101, discriminator acc = 0.116\n",
      "Iteration 3599, source loss =  0.099, discriminator acc = 0.062\n",
      "Iteration 3699, source loss =  0.116, discriminator acc = 0.006\n",
      "Iteration 3799, source loss =  0.084, discriminator acc = 0.970\n",
      "Iteration 3899, source loss =  0.091, discriminator acc = 1.000\n",
      "Iteration 3999, source loss =  0.092, discriminator acc = 0.998\n",
      "Iteration 4099, source loss =  0.118, discriminator acc = 0.999\n",
      "Iteration 4199, source loss =  0.242, discriminator acc = 0.007\n",
      "Iteration 4299, source loss =  0.105, discriminator acc = 1.000\n",
      "Iteration 4399, source loss =  0.279, discriminator acc = 0.006\n",
      "Iteration 4499, source loss =  0.146, discriminator acc = 1.000\n",
      "Iteration 4599, source loss =  0.202, discriminator acc = 0.625\n",
      "Iteration 4699, source loss =  0.134, discriminator acc = 0.823\n",
      "Iteration 4799, source loss =  0.105, discriminator acc = 1.000\n",
      "Iteration 4899, source loss =  0.280, discriminator acc = 0.091\n",
      "Iteration 4999, source loss =  0.163, discriminator acc = 0.007\n",
      "Iteration 5099, source loss =  0.207, discriminator acc = 0.852\n",
      "Iteration 5199, source loss =  0.116, discriminator acc = 0.577\n",
      "Iteration 5299, source loss =  0.259, discriminator acc = 0.006\n",
      "Iteration 5399, source loss =  0.104, discriminator acc = 0.991\n",
      "Iteration 5499, source loss =  0.282, discriminator acc = 0.006\n",
      "Iteration 5599, source loss =  0.171, discriminator acc = 0.474\n",
      "Iteration 5699, source loss =  0.146, discriminator acc = 0.979\n",
      "Iteration 5799, source loss =  0.145, discriminator acc = 0.007\n",
      "Iteration 5899, source loss =  0.159, discriminator acc = 0.007\n",
      "Iteration 5999, source loss =  0.135, discriminator acc = 0.999\n",
      "Iteration 6099, source loss =  0.153, discriminator acc = 0.006\n",
      "Iteration 6199, source loss =  0.113, discriminator acc = 0.009\n",
      "Iteration 6299, source loss =  0.159, discriminator acc = 0.040\n",
      "Iteration 6399, source loss =  0.088, discriminator acc = 0.168\n",
      "Iteration 6499, source loss =  0.170, discriminator acc = 0.949\n",
      "Iteration 6599, source loss =  0.161, discriminator acc = 0.972\n",
      "Iteration 6699, source loss =  0.111, discriminator acc = 0.173\n",
      "Iteration 6799, source loss =  0.151, discriminator acc = 0.233\n",
      "Iteration 6899, source loss =  0.109, discriminator acc = 0.068\n",
      "Iteration 6999, source loss =  0.130, discriminator acc = 0.992\n",
      "Iteration 7099, source loss =  0.137, discriminator acc = 0.012\n",
      "Iteration 7199, source loss =  0.088, discriminator acc = 0.778\n",
      "Iteration 7299, source loss =  0.139, discriminator acc = 0.007\n",
      "Iteration 7399, source loss =  0.101, discriminator acc = 0.917\n",
      "Iteration 7499, source loss =  0.126, discriminator acc = 0.041\n",
      "Iteration 7599, source loss =  0.089, discriminator acc = 1.000\n",
      "Iteration 7699, source loss =  0.115, discriminator acc = 0.022\n",
      "Iteration 7799, source loss =  0.101, discriminator acc = 1.000\n",
      "Iteration 7899, source loss =  0.128, discriminator acc = 0.007\n",
      "Iteration 7999, source loss =  0.078, discriminator acc = 0.999\n",
      "Iteration 8099, source loss =  0.068, discriminator acc = 0.005\n",
      "Iteration 8199, source loss =  0.069, discriminator acc = 0.999\n",
      "Iteration 8299, source loss =  0.097, discriminator acc = 0.006\n",
      "Iteration 8399, source loss =  0.078, discriminator acc = 0.951\n",
      "Iteration 8499, source loss =  0.116, discriminator acc = 0.903\n",
      "Iteration 8599, source loss =  0.067, discriminator acc = 0.058\n",
      "Iteration 8699, source loss =  0.061, discriminator acc = 0.972\n",
      "Iteration 8799, source loss =  0.064, discriminator acc = 0.304\n",
      "Iteration 8899, source loss =  0.064, discriminator acc = 0.888\n",
      "Iteration 8999, source loss =  0.061, discriminator acc = 0.939\n",
      "Iteration 9099, source loss =  0.062, discriminator acc = 0.873\n",
      "Iteration 9199, source loss =  0.099, discriminator acc = 0.248\n",
      "Iteration 9299, source loss =  0.060, discriminator acc = 0.154\n",
      "Iteration 9399, source loss =  0.072, discriminator acc = 0.977\n",
      "Iteration 9499, source loss =  0.076, discriminator acc = 0.716\n",
      "Iteration 9599, source loss =  0.068, discriminator acc = 0.319\n",
      "Iteration 9699, source loss =  0.073, discriminator acc = 0.042\n",
      "Iteration 9799, source loss =  0.086, discriminator acc = 0.270\n",
      "Iteration 9899, source loss =  0.093, discriminator acc = 0.007\n",
      "Iteration 9999, source loss =  0.076, discriminator acc = 0.612\n",
      "Iteration 10099, source loss =  0.064, discriminator acc = 0.985\n",
      "Iteration 10199, source loss =  0.067, discriminator acc = 0.776\n",
      "Iteration 10299, source loss =  0.067, discriminator acc = 0.975\n",
      "Iteration 10399, source loss =  0.104, discriminator acc = 0.717\n",
      "Iteration 10499, source loss =  0.077, discriminator acc = 0.863\n",
      "Iteration 10599, source loss =  0.130, discriminator acc = 0.998\n",
      "Iteration 10699, source loss =  0.113, discriminator acc = 0.006\n",
      "Iteration 10799, source loss =  0.065, discriminator acc = 0.957\n",
      "Iteration 10899, source loss =  0.078, discriminator acc = 0.318\n",
      "Iteration 10999, source loss =  0.122, discriminator acc = 0.933\n",
      "Iteration 11099, source loss =  0.076, discriminator acc = 0.963\n",
      "Iteration 11199, source loss =  0.067, discriminator acc = 0.912\n",
      "Iteration 11299, source loss =  0.082, discriminator acc = 0.005\n",
      "Iteration 11399, source loss =  0.104, discriminator acc = 0.660\n",
      "Iteration 11499, source loss =  0.163, discriminator acc = 0.145\n",
      "Iteration 11599, source loss =  0.069, discriminator acc = 0.594\n",
      "Iteration 11699, source loss =  0.068, discriminator acc = 0.998\n",
      "Iteration 11799, source loss =  0.079, discriminator acc = 0.989\n",
      "Iteration 11899, source loss =  0.084, discriminator acc = 0.998\n",
      "Iteration 11999, source loss =  0.063, discriminator acc = 0.212\n",
      "Iteration 12099, source loss =  0.061, discriminator acc = 0.028\n",
      "Iteration 12199, source loss =  0.082, discriminator acc = 0.042\n",
      "Iteration 12299, source loss =  0.140, discriminator acc = 0.714\n",
      "Iteration 12399, source loss =  0.121, discriminator acc = 0.005\n",
      "Iteration 12499, source loss =  0.073, discriminator acc = 0.028\n",
      "Iteration 12599, source loss =  0.107, discriminator acc = 0.011\n",
      "Iteration 12699, source loss =  0.077, discriminator acc = 0.732\n",
      "Iteration 12799, source loss =  0.055, discriminator acc = 0.987\n",
      "Iteration 12899, source loss =  0.075, discriminator acc = 0.029\n",
      "Iteration 12999, source loss =  0.070, discriminator acc = 0.816\n",
      "Iteration 13099, source loss =  0.059, discriminator acc = 0.951\n",
      "Iteration 13199, source loss =  0.071, discriminator acc = 0.910\n",
      "Iteration 13299, source loss =  0.069, discriminator acc = 0.409\n",
      "Iteration 13399, source loss =  0.051, discriminator acc = 0.901\n",
      "Iteration 13499, source loss =  0.095, discriminator acc = 0.614\n",
      "Iteration 13599, source loss =  0.050, discriminator acc = 0.613\n",
      "Iteration 13699, source loss =  0.050, discriminator acc = 0.850\n",
      "Iteration 13799, source loss =  0.069, discriminator acc = 0.478\n",
      "Iteration 13899, source loss =  0.071, discriminator acc = 0.787\n",
      "Iteration 13999, source loss =  0.064, discriminator acc = 0.334\n",
      "Iteration 14099, source loss =  0.170, discriminator acc = 0.312\n",
      "Iteration 14199, source loss =  0.180, discriminator acc = 0.005\n",
      "Iteration 14299, source loss =  0.194, discriminator acc = 0.006\n",
      "Iteration 14399, source loss =  0.274, discriminator acc = 0.964\n",
      "Iteration 14499, source loss =  0.284, discriminator acc = 0.090\n",
      "Iteration 14599, source loss =  0.174, discriminator acc = 0.006\n",
      "Iteration 14699, source loss =  0.078, discriminator acc = 0.993\n",
      "Iteration 14799, source loss =  0.111, discriminator acc = 0.262\n",
      "Iteration 14899, source loss =  0.184, discriminator acc = 0.007\n",
      "Iteration 14999, source loss =  0.095, discriminator acc = 0.736\n",
      "PS seed: 98098, model seed: 98237\n",
      "model_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/98237\n",
      "Adversarial training for slides train: \n",
      "Train on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 2s 15us/sample - loss: 0.1031 - mae: 0.0263\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 13us/sample - loss: 0.0248 - mae: 0.0131\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0206 - mae: 0.0121\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0193 - mae: 0.0117\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0185 - mae: 0.0115\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0181 - mae: 0.0113\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0178 - mae: 0.0112\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0175 - mae: 0.0111\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0173 - mae: 0.0110\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 12us/sample - loss: 0.0171 - mae: 0.0109\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025033984021544456\n",
      "0.025033984021544456\n",
      "Iteration 99, source loss =  1.192, discriminator acc = 0.006\n",
      "Iteration 199, source loss =  0.536, discriminator acc = 0.969\n",
      "Iteration 299, source loss =  0.326, discriminator acc = 0.007\n",
      "Iteration 399, source loss =  0.326, discriminator acc = 0.227\n",
      "Iteration 499, source loss =  0.452, discriminator acc = 0.993\n",
      "Iteration 599, source loss =  0.219, discriminator acc = 0.131\n",
      "Iteration 699, source loss =  0.363, discriminator acc = 0.986\n",
      "Iteration 799, source loss =  0.273, discriminator acc = 0.999\n",
      "Iteration 899, source loss =  0.317, discriminator acc = 0.972\n",
      "Iteration 999, source loss =  0.351, discriminator acc = 0.740\n",
      "Iteration 1099, source loss =  0.110, discriminator acc = 0.999\n",
      "Iteration 1199, source loss =  0.142, discriminator acc = 0.502\n",
      "Iteration 1299, source loss =  0.177, discriminator acc = 0.596\n",
      "Iteration 1399, source loss =  0.088, discriminator acc = 0.998\n",
      "Iteration 1499, source loss =  0.091, discriminator acc = 0.918\n",
      "Iteration 1599, source loss =  0.078, discriminator acc = 0.545\n",
      "Iteration 1699, source loss =  0.081, discriminator acc = 0.356\n",
      "Iteration 1799, source loss =  0.077, discriminator acc = 0.230\n",
      "Iteration 1899, source loss =  0.068, discriminator acc = 0.305\n",
      "Iteration 1999, source loss =  0.062, discriminator acc = 0.390\n",
      "Iteration 2099, source loss =  0.066, discriminator acc = 0.191\n",
      "Iteration 2199, source loss =  0.069, discriminator acc = 0.642\n",
      "Iteration 2299, source loss =  0.061, discriminator acc = 0.820\n",
      "Iteration 2399, source loss =  0.052, discriminator acc = 0.735\n",
      "Iteration 2499, source loss =  0.072, discriminator acc = 0.202\n",
      "Iteration 2599, source loss =  0.068, discriminator acc = 0.020\n",
      "Iteration 2699, source loss =  0.056, discriminator acc = 0.927\n",
      "Iteration 2799, source loss =  0.054, discriminator acc = 0.942\n",
      "Iteration 2899, source loss =  0.046, discriminator acc = 0.994\n",
      "Iteration 2999, source loss =  0.046, discriminator acc = 0.933\n",
      "Iteration 3099, source loss =  0.038, discriminator acc = 0.952\n",
      "Iteration 3199, source loss =  0.048, discriminator acc = 0.847\n",
      "Iteration 3299, source loss =  0.090, discriminator acc = 0.104\n",
      "Iteration 3399, source loss =  0.128, discriminator acc = 0.003\n",
      "Iteration 3499, source loss =  0.080, discriminator acc = 0.215\n",
      "Iteration 3599, source loss =  0.232, discriminator acc = 0.156\n",
      "Iteration 3699, source loss =  0.374, discriminator acc = 0.006\n",
      "Iteration 3799, source loss =  0.521, discriminator acc = 0.006\n",
      "Iteration 3899, source loss =  0.159, discriminator acc = 0.201\n",
      "Iteration 3999, source loss =  0.319, discriminator acc = 0.006\n",
      "Iteration 4099, source loss =  0.214, discriminator acc = 0.006\n",
      "Iteration 4199, source loss =  0.150, discriminator acc = 0.999\n",
      "Iteration 4299, source loss =  0.156, discriminator acc = 0.904\n",
      "Iteration 4399, source loss =  0.073, discriminator acc = 0.986\n",
      "Iteration 4499, source loss =  0.121, discriminator acc = 1.000\n",
      "Iteration 4599, source loss =  0.261, discriminator acc = 1.000\n",
      "Iteration 4699, source loss =  0.244, discriminator acc = 0.009\n",
      "Iteration 4799, source loss =  0.105, discriminator acc = 0.950\n",
      "Iteration 4899, source loss =  0.279, discriminator acc = 0.007\n",
      "Iteration 4999, source loss =  0.086, discriminator acc = 1.000\n",
      "Iteration 5099, source loss =  0.135, discriminator acc = 0.399\n",
      "Iteration 5199, source loss =  0.130, discriminator acc = 0.005\n",
      "Iteration 5299, source loss =  0.090, discriminator acc = 0.063\n",
      "Iteration 5399, source loss =  0.141, discriminator acc = 0.775\n",
      "Iteration 5499, source loss =  0.101, discriminator acc = 0.006\n",
      "Iteration 5599, source loss =  0.291, discriminator acc = 0.501\n",
      "Iteration 5699, source loss =  0.073, discriminator acc = 0.961\n",
      "Iteration 5799, source loss =  0.089, discriminator acc = 1.000\n",
      "Iteration 5899, source loss =  0.278, discriminator acc = 0.030\n",
      "Iteration 5999, source loss =  0.088, discriminator acc = 0.953\n",
      "Iteration 6099, source loss =  0.085, discriminator acc = 0.958\n",
      "Iteration 6199, source loss =  0.219, discriminator acc = 0.006\n",
      "Iteration 6299, source loss =  0.085, discriminator acc = 0.006\n",
      "Iteration 6399, source loss =  0.083, discriminator acc = 0.984\n",
      "Iteration 6499, source loss =  0.171, discriminator acc = 0.597\n",
      "Iteration 6599, source loss =  0.101, discriminator acc = 0.976\n",
      "Iteration 6699, source loss =  0.122, discriminator acc = 0.006\n",
      "Iteration 6799, source loss =  0.131, discriminator acc = 1.000\n",
      "Iteration 6899, source loss =  0.079, discriminator acc = 0.051\n",
      "Iteration 6999, source loss =  0.107, discriminator acc = 0.999\n",
      "Iteration 7099, source loss =  0.099, discriminator acc = 0.006\n",
      "Iteration 7199, source loss =  0.141, discriminator acc = 0.114\n",
      "Iteration 7299, source loss =  0.139, discriminator acc = 0.006\n",
      "Iteration 7399, source loss =  0.093, discriminator acc = 0.349\n",
      "Iteration 7499, source loss =  0.151, discriminator acc = 0.008\n",
      "Iteration 7599, source loss =  0.086, discriminator acc = 0.148\n",
      "Iteration 7699, source loss =  0.112, discriminator acc = 0.977\n",
      "Iteration 7799, source loss =  0.105, discriminator acc = 0.006\n",
      "Iteration 7899, source loss =  0.105, discriminator acc = 0.994\n",
      "Iteration 7999, source loss =  0.174, discriminator acc = 0.029\n",
      "Iteration 8099, source loss =  0.102, discriminator acc = 1.000\n",
      "Iteration 8199, source loss =  0.113, discriminator acc = 0.007\n",
      "Iteration 8299, source loss =  0.095, discriminator acc = 1.000\n",
      "Iteration 8399, source loss =  0.135, discriminator acc = 0.148\n",
      "Iteration 8499, source loss =  0.131, discriminator acc = 0.979\n",
      "Iteration 8599, source loss =  0.130, discriminator acc = 0.500\n",
      "Iteration 8699, source loss =  0.101, discriminator acc = 0.974\n",
      "Iteration 8799, source loss =  0.124, discriminator acc = 0.006\n",
      "Iteration 8899, source loss =  0.095, discriminator acc = 0.082\n",
      "Iteration 8999, source loss =  0.182, discriminator acc = 0.375\n",
      "Iteration 9099, source loss =  0.083, discriminator acc = 0.017\n",
      "Iteration 9199, source loss =  0.103, discriminator acc = 0.979\n",
      "Iteration 9299, source loss =  0.085, discriminator acc = 0.042\n",
      "Iteration 9399, source loss =  0.103, discriminator acc = 0.999\n",
      "Iteration 9499, source loss =  0.114, discriminator acc = 0.831\n",
      "Iteration 9599, source loss =  0.099, discriminator acc = 0.999\n",
      "Iteration 9699, source loss =  0.087, discriminator acc = 0.110\n",
      "Iteration 9799, source loss =  0.166, discriminator acc = 0.006\n",
      "Iteration 9899, source loss =  0.083, discriminator acc = 0.103\n",
      "Iteration 9999, source loss =  0.118, discriminator acc = 0.006\n",
      "Iteration 10099, source loss =  0.079, discriminator acc = 0.934\n",
      "Iteration 10199, source loss =  0.095, discriminator acc = 0.113\n",
      "Iteration 10299, source loss =  0.073, discriminator acc = 0.933\n",
      "Iteration 10399, source loss =  0.119, discriminator acc = 0.007\n",
      "Iteration 10499, source loss =  0.069, discriminator acc = 0.970\n",
      "Iteration 10599, source loss =  0.067, discriminator acc = 0.994\n",
      "Iteration 10699, source loss =  0.088, discriminator acc = 0.747\n",
      "Iteration 10799, source loss =  0.105, discriminator acc = 0.869\n",
      "Iteration 10899, source loss =  0.067, discriminator acc = 0.963\n",
      "Iteration 10999, source loss =  0.076, discriminator acc = 0.315\n",
      "Iteration 11099, source loss =  0.060, discriminator acc = 0.978\n",
      "Iteration 11199, source loss =  0.078, discriminator acc = 0.598\n",
      "Iteration 11299, source loss =  0.066, discriminator acc = 0.006\n",
      "Iteration 11399, source loss =  0.111, discriminator acc = 0.996\n",
      "Iteration 11499, source loss =  0.095, discriminator acc = 0.031\n",
      "Iteration 11599, source loss =  0.064, discriminator acc = 0.078\n",
      "Iteration 11699, source loss =  0.058, discriminator acc = 0.842\n",
      "Iteration 11799, source loss =  0.063, discriminator acc = 0.283\n",
      "Iteration 11899, source loss =  0.057, discriminator acc = 0.560\n",
      "Iteration 11999, source loss =  0.057, discriminator acc = 0.305\n",
      "Iteration 12099, source loss =  0.057, discriminator acc = 0.487\n",
      "Iteration 12199, source loss =  0.058, discriminator acc = 0.459\n",
      "Iteration 12299, source loss =  0.055, discriminator acc = 0.532\n",
      "Iteration 12399, source loss =  0.057, discriminator acc = 0.629\n",
      "Iteration 12499, source loss =  0.056, discriminator acc = 0.896\n",
      "Iteration 12599, source loss =  0.080, discriminator acc = 0.005\n",
      "Iteration 12699, source loss =  0.089, discriminator acc = 0.296\n",
      "Iteration 12799, source loss =  0.057, discriminator acc = 0.803\n",
      "Iteration 12899, source loss =  0.065, discriminator acc = 0.588\n",
      "Iteration 12999, source loss =  0.054, discriminator acc = 0.590\n",
      "Iteration 13099, source loss =  0.064, discriminator acc = 0.689\n",
      "Iteration 13199, source loss =  0.064, discriminator acc = 0.807\n",
      "Iteration 13299, source loss =  0.113, discriminator acc = 0.974\n",
      "Iteration 13399, source loss =  0.092, discriminator acc = 0.442\n",
      "Iteration 13499, source loss =  0.099, discriminator acc = 0.281\n",
      "Iteration 13599, source loss =  0.085, discriminator acc = 0.027\n",
      "Iteration 13699, source loss =  0.333, discriminator acc = 0.997\n",
      "Iteration 13799, source loss =  0.099, discriminator acc = 0.006\n",
      "Iteration 13899, source loss =  0.113, discriminator acc = 0.100\n",
      "Iteration 13999, source loss =  0.148, discriminator acc = 0.006\n",
      "Iteration 14099, source loss =  0.086, discriminator acc = 0.104\n",
      "Iteration 14199, source loss =  0.117, discriminator acc = 0.999\n",
      "Iteration 14299, source loss =  0.116, discriminator acc = 0.008\n",
      "Iteration 14399, source loss =  0.097, discriminator acc = 0.794\n",
      "Iteration 14499, source loss =  0.171, discriminator acc = 0.997\n",
      "Iteration 14599, source loss =  0.061, discriminator acc = 0.750\n",
      "Iteration 14699, source loss =  0.064, discriminator acc = 0.897\n",
      "Iteration 14799, source loss =  0.072, discriminator acc = 0.788\n",
      "Iteration 14899, source loss =  0.067, discriminator acc = 0.801\n",
      "Iteration 14999, source loss =  0.054, discriminator acc = 0.598\n"
     ]
    }
   ],
   "source": [
    "def train(ps_seed, model_seed):\n",
    "    print(f\"PS seed: {ps_seed}, model seed: {model_seed}\")\n",
    "\n",
    "    model_folder = data_loading.get_model_rel_path(\n",
    "        MODEL_NAME,\n",
    "        model_params[\"model_version\"],\n",
    "        lib_seed_path=str(model_seed),\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    model_folder = os.path.join(MODEL_DIR, model_folder)\n",
    "    if not os.path.isdir(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "        print(model_folder)\n",
    "        \n",
    "    selected_dir = data_loading.get_selected_dir(\n",
    "        data_loading.get_dset_dir(\n",
    "            data_params[\"data_dir\"],\n",
    "            dset=data_params.get(\"dset\", \"dlpfc\"),\n",
    "        ),\n",
    "        **data_params,\n",
    "    )\n",
    "    # Load spatial data\n",
    "    mat_sp_d, mat_sp_meta_d, st_sample_id_l = data_loading.load_spatial(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "    )\n",
    "\n",
    "    # Load sc data\n",
    "    sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = data_loading.load_sc(\n",
    "        selected_dir,\n",
    "        **data_params,\n",
    "        seed_int=ps_seed,\n",
    "    )\n",
    "\n",
    "    target_d = {}\n",
    "    if \"train\" in mat_sp_d:\n",
    "        # keys of dict are splits\n",
    "        for split in mat_sp_d:\n",
    "            target_d[split] = np.concatenate(list(mat_sp_d[split].values()))\n",
    "    else:\n",
    "        # keys of subdicts are splits\n",
    "        for split in next(iter(mat_sp_d.values())):\n",
    "            target_d[split] = np.concatenate((v[split] for v in mat_sp_d.values()))\n",
    "\n",
    "\n",
    "    advtrain_folder = os.path.join(model_folder, \"advtrain\")\n",
    "    pretrain_folder = os.path.join(model_folder, \"pretrain\")\n",
    "    if not os.path.isdir(advtrain_folder):\n",
    "        os.makedirs(advtrain_folder)\n",
    "    if not os.path.isdir(pretrain_folder):\n",
    "        os.makedirs(pretrain_folder)\n",
    "\n",
    "    if data_params.get(\"samp_split\"):\n",
    "        tqdm.write(f\"Adversarial training for slides {mat_sp_d['train'].keys()}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"samp_split\")\n",
    "    else:\n",
    "        tqdm.write(f\"Adversarial training for slides {next(iter(mat_sp_d.keys()))}: \")\n",
    "        save_folder = os.path.join(advtrain_folder, \"one_model\")\n",
    "\n",
    "    if not os.path.isdir(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    embs, embs_noda, clssmodel, clssmodel_noda = da_cellfraction.train(\n",
    "        sc_mix_d[\"train\"],\n",
    "        lab_mix_d[\"train\"],\n",
    "        target_d[\"train\"],\n",
    "        alpha=train_params.get(\"alpha\", 0.6),\n",
    "        alpha_lr=train_params.get(\"alpha_lr\", 5),\n",
    "        emb_dim=model_params[\"celldart_kwargs\"].get(\"emb_dim\", 64),\n",
    "        batch_size=train_params.get(\"batch_size\", 512),\n",
    "        n_iterations=train_params.get(\"n_iter\", 3000),\n",
    "        initial_train=train_params.get(\"pretraining\", True),\n",
    "        initial_train_epochs=train_params.get(\"initial_train_epochs\", 10),\n",
    "        batch_size_initial_train=max(train_params.get(\"batch_size\", 512), 512),\n",
    "        seed=model_seed,\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "\n",
    "    if not os.path.isdir(os.path.join(save_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(save_folder, \"final_model\"))\n",
    "    if not os.path.isdir(os.path.join(pretrain_folder, \"final_model\")):\n",
    "        os.makedirs(os.path.join(pretrain_folder, \"final_model\"))\n",
    "\n",
    "    clssmodel_noda.save(os.path.join(pretrain_folder, \"final_model\", \"model\"))\n",
    "    clssmodel.save(os.path.join(save_folder, \"final_model\", \"model\"))\n",
    "\n",
    "    embs_noda.save(os.path.join(pretrain_folder, \"final_model\", \"embs\"))\n",
    "    embs.save(os.path.join(save_folder, \"final_model\", \"embs\"))\n",
    "\n",
    "    with open(os.path.join(model_folder, \"config.yml\"), \"w\") as f:\n",
    "        yaml.safe_dump(config, f)\n",
    "\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    train(ps_seed, model_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/2353 ...\n",
      "Loading Data\n",
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.009479   \n",
      "                                pdac_b                         0.009479   \n",
      "After DA (final model)          pdac_a                         0.036197   \n",
      "                                pdac_b                         0.036197   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a     0.010320  0.009933  0.999975   \n",
      "                                pdac_b     0.010320  0.009933  0.999925   \n",
      "After DA (final model)          pdac_a     0.036407  0.036144  0.999750   \n",
      "                                pdac_b     0.036407  0.036144  1.000000   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     0.9999  0.9999   \n",
      "                                pdac_b     0.9999  1.0000   \n",
      "After DA (final model)          pdac_a     0.9997  0.9988   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train       val   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                  1.000000  1.000000   \n",
      "                                pdac_b                  1.000000  1.000000   \n",
      "After DA (final model)          pdac_a                  1.047718  1.056009   \n",
      "                                pdac_b                  1.001025  1.000000   \n",
      "\n",
      "                                                    \\\n",
      "                                              test   \n",
      "                       SC Split Sample ID            \n",
      "Before DA                       pdac_a     1.00000   \n",
      "                                pdac_b     1.00000   \n",
      "After DA (final model)          pdac_a     1.04794   \n",
      "                                pdac_b     1.00000   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.504217  \n",
      "                                pdac_b                          0.476849  \n",
      "After DA (final model)          pdac_a                          0.539787  \n",
      "                                pdac_b                          0.495171  \n",
      "Script run time: 0:02:50.555371\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/24385 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.011481   \n",
      "                                pdac_b                         0.011481   \n",
      "After DA (final model)          pdac_a                         0.080794   \n",
      "                                pdac_b                         0.080794   \n",
      "\n",
      "                                                                  RF50  \\\n",
      "                                                val      test    train   \n",
      "                       SC Split Sample ID                                \n",
      "Before DA                       pdac_a     0.012181  0.011649  1.00000   \n",
      "                                pdac_b     0.012181  0.011649  1.00000   \n",
      "After DA (final model)          pdac_a     0.078774  0.080421  1.00000   \n",
      "                                pdac_b     0.078774  0.080421  0.99985   \n",
      "\n",
      "                                                       miLISI (perplexity=30)  \\\n",
      "                                              val test                  train   \n",
      "                       SC Split Sample ID                                       \n",
      "Before DA                       pdac_a     1.0000  1.0                    1.0   \n",
      "                                pdac_b     1.0000  1.0                    1.0   \n",
      "After DA (final model)          pdac_a     1.0000  1.0                    1.0   \n",
      "                                pdac_b     0.9998  1.0                    1.0   \n",
      "\n",
      "                                                     \\\n",
      "                                           val test   \n",
      "                       SC Split Sample ID             \n",
      "Before DA                       pdac_a     1.0  1.0   \n",
      "                                pdac_b     1.0  1.0   \n",
      "After DA (final model)          pdac_a     1.0  1.0   \n",
      "                                pdac_b     1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.504198  \n",
      "                                pdac_b                          0.472255  \n",
      "After DA (final model)          pdac_a                          0.514558  \n",
      "                                pdac_b                          0.489994  \n",
      "Script run time: 0:03:04.653243\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/284 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.009191   \n",
      "                                pdac_b                         0.009191   \n",
      "After DA (final model)          pdac_a                         0.037574   \n",
      "                                pdac_b                         0.037574   \n",
      "\n",
      "                                                                  RF50  \\\n",
      "                                                val      test    train   \n",
      "                       SC Split Sample ID                                \n",
      "Before DA                       pdac_a     0.009665  0.009520  0.99975   \n",
      "                                pdac_b     0.009665  0.009520  0.99995   \n",
      "After DA (final model)          pdac_a     0.038313  0.037222  1.00000   \n",
      "                                pdac_b     0.038313  0.037222  1.00000   \n",
      "\n",
      "                                                               \\\n",
      "                                                val      test   \n",
      "                       SC Split Sample ID                       \n",
      "Before DA                       pdac_a     0.982458  0.994086   \n",
      "                                pdac_b     1.000000  0.999900   \n",
      "After DA (final model)          pdac_a     0.999500  0.999700   \n",
      "                                pdac_b     0.999900  1.000000   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train  val test   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                       1.0  1.0  1.0   \n",
      "                                pdac_b                       1.0  1.0  1.0   \n",
      "After DA (final model)          pdac_a                       1.0  1.0  1.0   \n",
      "                                pdac_b                       1.0  1.0  1.0   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.510291  \n",
      "                                pdac_b                          0.475329  \n",
      "After DA (final model)          pdac_a                          0.548202  \n",
      "                                pdac_b                          0.468512  \n",
      "Script run time: 0:03:34.919286\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/86322 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.007810   \n",
      "                                pdac_b                         0.007810   \n",
      "After DA (final model)          pdac_a                         0.045702   \n",
      "                                pdac_b                         0.045702   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a     0.008821  0.008637  1.000000   \n",
      "                                pdac_b     0.008821  0.008637  1.000000   \n",
      "After DA (final model)          pdac_a     0.046648  0.046507  0.999975   \n",
      "                                pdac_b     0.046648  0.046507  0.999975   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     1.0000  1.0000   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "After DA (final model)          pdac_a     0.9999  0.9999   \n",
      "                                pdac_b     0.9999  0.9996   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train       val   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                  1.000000  1.000000   \n",
      "                                pdac_b                  1.000000  1.000000   \n",
      "After DA (final model)          pdac_a                  1.145491  1.135874   \n",
      "                                pdac_b                  1.044705  1.026386   \n",
      "\n",
      "                                                     \\\n",
      "                                               test   \n",
      "                       SC Split Sample ID             \n",
      "Before DA                       pdac_a     1.000000   \n",
      "                                pdac_b     1.000000   \n",
      "After DA (final model)          pdac_a     1.142834   \n",
      "                                pdac_b     1.020768   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.515078  \n",
      "                                pdac_b                          0.469899  \n",
      "After DA (final model)          pdac_a                          0.531680  \n",
      "                                pdac_b                          0.477041  \n",
      "Script run time: 0:03:51.979212\n",
      "Evaluating CellDART_original on with 8 jobs\n",
      "Using library config:\n",
      "None\n",
      "Loading config celldart-final-pdac-ht.yml ... \n",
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: ../AGrEDA/data\n",
      "  dset: pdac\n",
      "  n_markers: 80\n",
      "  n_mix: 70\n",
      "  n_spots: 100000\n",
      "  one_model: true\n",
      "  samp_split: false\n",
      "  sc_id: CA001063\n",
      "  scaler_name: minmax\n",
      "  st_id: GSE111672\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 2123428735\n",
      "model_params:\n",
      "  celldart_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 32\n",
      "  model_version: gen_pdac-18486\n",
      "train_params:\n",
      "  alpha: 0.6\n",
      "  alpha_lr: 5\n",
      "  batch_size: 128\n",
      "  initial_train_epochs: 10\n",
      "  lr: 0.01\n",
      "  n_iter: 15000\n",
      "  pretraining: true\n",
      "  reverse_val: false\n",
      "\n",
      "Saving results to results_FINAL/CellDART_original/pdac/CA001063_GSE111672/80markers/70mix_100000spots/minmax/gen_pdac-18486/98237 ...\n",
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ST adata: \n",
      "Getting predictions: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Samples\n",
      "n_jobs_samples < 4, no parallelization\n",
      "Calculating domain shift for pdac_a: TRAIN |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n",
      "Calculating domain shift for pdac_b: TRAIN | milisi rf50 | VAL | milisi rf50 | TEST | milisi rf50 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Pseudospots (Cosine Distance)  \\\n",
      "                                                                  train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                         0.011106   \n",
      "                                pdac_b                         0.011106   \n",
      "After DA (final model)          pdac_a                         0.023756   \n",
      "                                pdac_b                         0.023756   \n",
      "\n",
      "                                                                   RF50  \\\n",
      "                                                val      test     train   \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a     0.011656  0.011221  0.999975   \n",
      "                                pdac_b     0.011656  0.011221  1.000000   \n",
      "After DA (final model)          pdac_a     0.024552  0.023906  0.999875   \n",
      "                                pdac_b     0.024552  0.023906  0.999975   \n",
      "\n",
      "                                                           \\\n",
      "                                              val    test   \n",
      "                       SC Split Sample ID                   \n",
      "Before DA                       pdac_a     1.0000  1.0000   \n",
      "                                pdac_b     1.0000  1.0000   \n",
      "After DA (final model)          pdac_a     0.9999  0.9999   \n",
      "                                pdac_b     0.9999  1.0000   \n",
      "\n",
      "                                          miLISI (perplexity=30)            \\\n",
      "                                                           train       val   \n",
      "                       SC Split Sample ID                                    \n",
      "Before DA                       pdac_a                  1.000000  1.000000   \n",
      "                                pdac_b                  1.000000  1.000000   \n",
      "After DA (final model)          pdac_a                  1.496945  1.518283   \n",
      "                                pdac_b                  1.427457  1.409327   \n",
      "\n",
      "                                                     \\\n",
      "                                               test   \n",
      "                       SC Split Sample ID             \n",
      "Before DA                       pdac_a     1.000000   \n",
      "                                pdac_b     1.000000   \n",
      "After DA (final model)          pdac_a     1.475480   \n",
      "                                pdac_b     1.525567   \n",
      "\n",
      "                                          Real Spots (Mean AUC celltype)  \n",
      "                                                                       0  \n",
      "                       SC Split Sample ID                                 \n",
      "Before DA                       pdac_a                          0.511013  \n",
      "                                pdac_b                          0.486569  \n",
      "After DA (final model)          pdac_a                          0.543140  \n",
      "                                pdac_b                          0.510643  \n",
      "Script run time: 0:04:31.045073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/CellDART/src/da_utils/output_utils.py:119: UserWarning: Destination exists. Will overwrite.\n",
      "  warnings.warn(\"Destination exists. Will overwrite.\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "from src.da_models.model_utils.utils import get_metric_ctp\n",
    "from src.da_utils.evaluator import Evaluator\n",
    "\n",
    "\n",
    "metric_ctp = get_metric_ctp(\"cos\")\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    evaluator = Evaluator(vars(args), metric_ctp)\n",
    "    evaluator.eval_spots()\n",
    "    evaluator.evaluate_embeddings()\n",
    "    evaluator.eval_sc()\n",
    "\n",
    "    evaluator.produce_results()\n",
    "\n",
    "for ps_seed, model_seed in zip(PS_SEEDS, MODEL_SEEDS):\n",
    "    parser = argparse.ArgumentParser(description=\"Evaluates.\")\n",
    "    parser.add_argument(\"--pretraining\", \"-p\", action=\"store_true\", help=\"force pretraining\")\n",
    "    parser.add_argument(\"--modelname\", \"-n\", type=str, default=\"ADDA\", help=\"model name\")\n",
    "    parser.add_argument(\"--milisi\", \"-m\", action=\"store_false\", help=\"no milisi\")\n",
    "    parser.add_argument(\"--config_fname\", \"-f\", type=str, help=\"Name of the config file to use\")\n",
    "    parser.add_argument(\"--configs_dir\", \"-cdir\", type=str, default=\"configs\", help=\"config dir\")\n",
    "    parser.add_argument(\n",
    "        \"--njobs\", type=int, default=1, help=\"Number of jobs to use for parallel processing.\"\n",
    "    )\n",
    "    parser.add_argument(\"--cuda\", \"-c\", default=None, help=\"GPU index to use\")\n",
    "    parser.add_argument(\"--tmpdir\", \"-d\", default=None, help=\"optional temporary results directory\")\n",
    "    parser.add_argument(\"--test\", \"-t\", action=\"store_true\", help=\"test mode\")\n",
    "    parser.add_argument(\n",
    "        \"--early_stopping\",\n",
    "        \"-e\",\n",
    "        action=\"store_true\",\n",
    "        help=\"evaluate early stopping. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reverse_val\",\n",
    "        \"-r\",\n",
    "        action=\"store_true\",\n",
    "        help=\"use best model through reverse validation. Will use provided\"\n",
    "        \"config file to search across models, then use the one loaded. Default: False\",\n",
    "    )\n",
    "    parser.add_argument(\"--model_dir\", default=\"model\", help=\"model directory\")\n",
    "    parser.add_argument(\"--results_dir\", default=\"results\", help=\"results directory\")\n",
    "    parser.add_argument(\n",
    "        \"--seed_override\",\n",
    "        default=None,\n",
    "        help=\"seed to use for torch and numpy; overrides that in config file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ps_seed\",\n",
    "        default=-1,\n",
    "        help=\"specific pseudospot seed to use; default of -1 corresponds to 623\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args([\n",
    "        f\"--modelname={MODEL_NAME}\",\n",
    "        f\"--config_fname={CONFIG_FNAME}\",\n",
    "        \"--njobs=8\",\n",
    "        \"--test\",\n",
    "        f\"--model_dir={MODEL_DIR}\",\n",
    "        \"--results_dir=results_FINAL\",\n",
    "        f\"--seed_override={model_seed}\",\n",
    "        f\"--ps_seed={ps_seed}\"\n",
    "    ])\n",
    "\n",
    "    script_start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        level=logging.WARNING,\n",
    "        format=\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\",\n",
    "    )\n",
    "    main(args)\n",
    "    print(\"Script run time:\", datetime.datetime.now(datetime.timezone.utc) - script_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellDART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
