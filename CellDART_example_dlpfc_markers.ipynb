{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellDART Example Code: mouse brain \n",
    "## (10x Visium of anterior mouse brain + scRNA-seq data of mouse brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:52.717248Z",
     "iopub.status.busy": "2023-01-11T07:35:52.717088Z",
     "iopub.status.idle": "2023-01-11T07:35:55.300612Z",
     "shell.execute_reply": "2023-01-11T07:35:55.299943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1501/1866271205.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "import anndata as ad\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from CellDART import da_cellfraction\n",
    "from CellDART.utils import random_mix\n",
    "\n",
    "from src.utils.data_loading import load_spatial, load_sc, get_selected_dir\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.326753Z",
     "iopub.status.busy": "2023-01-11T07:35:55.326017Z",
     "iopub.status.idle": "2023-01-11T07:35:55.536738Z",
     "shell.execute_reply": "2023-01-11T07:35:55.536083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf   # TensorFlow registers PluggableDevices here.\n",
    "tf.config.list_physical_devices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.538716Z",
     "iopub.status.busy": "2023-01-11T07:35:55.538551Z",
     "iopub.status.idle": "2023-01-11T07:35:55.542359Z",
     "shell.execute_reply": "2023-01-11T07:35:55.541709Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_USING_ALL_ST_SAMPLES = False\n",
    "N_MARKERS = 20\n",
    "ALL_GENES = False\n",
    "\n",
    "ST_SPLIT = False\n",
    "N_SPOTS = 20000\n",
    "N_MIX = 8\n",
    "SCALER_NAME = \"celldart\"\n",
    "\n",
    "\n",
    "SAMPLE_ID_N = \"151673\"\n",
    "INITIAL_TRAIN_EPOCHS = 10\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "ALPHA = 0.6\n",
    "ALPHA_LR = 5\n",
    "N_ITER = 3000\n",
    "\n",
    "DATA_DIR = \"../AGrEDA/data\"\n",
    "# DATA_DIR = \"./data_combine/\"\n",
    "\n",
    "BOOTSTRAP = False\n",
    "BOOTSTRAP_ROUNDS = 10\n",
    "BOOTSTRAP_ALPHAS = [0.6, 1/0.6]\n",
    "\n",
    "MODEL_NAME = 'CellDART'\n",
    "MODEL_VERSION = \"V1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.544202Z",
     "iopub.status.busy": "2023-01-11T07:35:55.544038Z",
     "iopub.status.idle": "2023-01-11T07:35:55.547048Z",
     "shell.execute_reply": "2023-01-11T07:35:55.546503Z"
    }
   },
   "outputs": [],
   "source": [
    "model_folder = os.path.join(\"model\", MODEL_NAME, MODEL_VERSION)\n",
    "\n",
    "if not os.path.isdir(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "    print(model_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load\n",
    "### load scanpy data - 10x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.548986Z",
     "iopub.status.busy": "2023-01-11T07:35:55.548830Z",
     "iopub.status.idle": "2023-01-11T07:35:55.668190Z",
     "shell.execute_reply": "2023-01-11T07:35:55.667598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load spatial data\n",
    "mat_sp_d, mat_sp_train, st_sample_id_l = load_spatial(\n",
    "    get_selected_dir(DATA_DIR, N_MARKERS, ALL_GENES),\n",
    "    SCALER_NAME,\n",
    "    train_using_all_st_samples=TRAIN_USING_ALL_ST_SAMPLES,\n",
    "    st_split=ST_SPLIT,\n",
    ")\n",
    "\n",
    "# Load sc data\n",
    "sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = load_sc(\n",
    "    get_selected_dir(DATA_DIR, N_MARKERS, ALL_GENES),\n",
    "    SCALER_NAME,\n",
    "    n_mix=N_MIX,\n",
    "    n_spots=N_SPOTS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.670786Z",
     "iopub.status.busy": "2023-01-11T07:35:55.670202Z",
     "iopub.status.idle": "2023-01-11T07:35:55.673835Z",
     "shell.execute_reply": "2023-01-11T07:35:55.673154Z"
    }
   },
   "outputs": [],
   "source": [
    "advtrain_folder = os.path.join(model_folder, \"advtrain\")\n",
    "pretrain_folder = os.path.join(model_folder, \"pretrain\")\n",
    "if not os.path.isdir(advtrain_folder):\n",
    "    os.makedirs(advtrain_folder)\n",
    "if not os.path.isdir(pretrain_folder):\n",
    "    os.makedirs(pretrain_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T07:35:55.675850Z",
     "iopub.status.busy": "2023-01-11T07:35:55.675662Z",
     "iopub.status.idle": "2023-01-11T08:39:15.191693Z",
     "shell.execute_reply": "2023-01-11T08:39:15.191003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial training for ST slide 151507: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 83us/sample - loss: 1.2381 - mae: 0.0348\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.8781 - mae: 0.0288\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.7086 - mae: 0.0257\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.6190 - mae: 0.0234\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5785 - mae: 0.0221\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5578 - mae: 0.0216\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5388 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5240 - mae: 0.0206\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5097 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.4994 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  3.950, discriminator acc = 0.180\n",
      "Iteration 199, source loss =  1.888, discriminator acc = 0.454\n",
      "Iteration 299, source loss =  1.431, discriminator acc = 0.927\n",
      "Iteration 399, source loss =  1.555, discriminator acc = 0.878\n",
      "Iteration 499, source loss =  1.389, discriminator acc = 0.992\n",
      "Iteration 599, source loss =  1.242, discriminator acc = 0.153\n",
      "Iteration 699, source loss =  1.110, discriminator acc = 1.000\n",
      "Iteration 799, source loss =  1.088, discriminator acc = 0.632\n",
      "Iteration 899, source loss =  1.090, discriminator acc = 0.996\n",
      "Iteration 999, source loss =  1.192, discriminator acc = 0.124\n",
      "Iteration 1099, source loss =  1.054, discriminator acc = 0.292\n",
      "Iteration 1199, source loss =  0.921, discriminator acc = 0.905\n",
      "Iteration 1299, source loss =  0.993, discriminator acc = 0.182\n",
      "Iteration 1399, source loss =  0.926, discriminator acc = 0.999\n",
      "Iteration 1499, source loss =  1.067, discriminator acc = 0.151\n",
      "Iteration 1599, source loss =  0.919, discriminator acc = 0.753\n",
      "Iteration 1699, source loss =  0.872, discriminator acc = 0.874\n",
      "Iteration 1799, source loss =  0.997, discriminator acc = 0.929\n",
      "Iteration 1899, source loss =  1.000, discriminator acc = 0.174\n",
      "Iteration 1999, source loss =  0.902, discriminator acc = 0.895\n",
      "Iteration 2099, source loss =  1.206, discriminator acc = 0.311\n",
      "Iteration 2199, source loss =  1.198, discriminator acc = 0.319\n",
      "Iteration 2299, source loss =  0.916, discriminator acc = 0.521\n",
      "Iteration 2399, source loss =  1.065, discriminator acc = 0.938\n",
      "Iteration 2499, source loss =  0.935, discriminator acc = 0.836\n",
      "Iteration 2599, source loss =  0.883, discriminator acc = 0.992\n",
      "Iteration 2699, source loss =  1.089, discriminator acc = 0.318\n",
      "Iteration 2799, source loss =  0.836, discriminator acc = 0.529\n",
      "Iteration 2899, source loss =  1.051, discriminator acc = 0.840\n",
      "Iteration 2999, source loss =  0.856, discriminator acc = 0.996\n",
      "Adversarial training for ST slide 151508: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 0s 24us/sample - loss: 1.2383 - mae: 0.0349\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.8648 - mae: 0.0287\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.7006 - mae: 0.0255\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.6179 - mae: 0.0233\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 9us/sample - loss: 0.5824 - mae: 0.0222\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5594 - mae: 0.0216\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 9us/sample - loss: 0.5415 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 9us/sample - loss: 0.5277 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 9us/sample - loss: 0.5145 - mae: 0.0204\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5004 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  4.053, discriminator acc = 0.066\n",
      "Iteration 199, source loss =  2.089, discriminator acc = 0.855\n",
      "Iteration 299, source loss =  2.219, discriminator acc = 0.821\n",
      "Iteration 399, source loss =  1.457, discriminator acc = 0.856\n",
      "Iteration 499, source loss =  1.599, discriminator acc = 0.843\n",
      "Iteration 599, source loss =  1.429, discriminator acc = 0.835\n",
      "Iteration 699, source loss =  1.336, discriminator acc = 0.836\n",
      "Iteration 799, source loss =  1.223, discriminator acc = 0.880\n",
      "Iteration 899, source loss =  1.189, discriminator acc = 0.957\n",
      "Iteration 999, source loss =  1.432, discriminator acc = 0.966\n",
      "Iteration 1099, source loss =  1.277, discriminator acc = 0.949\n",
      "Iteration 1199, source loss =  1.145, discriminator acc = 0.921\n",
      "Iteration 1299, source loss =  1.066, discriminator acc = 0.402\n",
      "Iteration 1399, source loss =  1.041, discriminator acc = 0.710\n",
      "Iteration 1499, source loss =  0.906, discriminator acc = 0.856\n",
      "Iteration 1599, source loss =  0.861, discriminator acc = 0.886\n",
      "Iteration 1699, source loss =  0.848, discriminator acc = 0.219\n",
      "Iteration 1799, source loss =  0.791, discriminator acc = 0.420\n",
      "Iteration 1899, source loss =  0.777, discriminator acc = 0.314\n",
      "Iteration 1999, source loss =  0.749, discriminator acc = 0.793\n",
      "Iteration 2099, source loss =  0.773, discriminator acc = 0.845\n",
      "Iteration 2199, source loss =  0.796, discriminator acc = 0.197\n",
      "Iteration 2299, source loss =  0.779, discriminator acc = 0.148\n",
      "Iteration 2399, source loss =  0.773, discriminator acc = 0.312\n",
      "Iteration 2499, source loss =  0.777, discriminator acc = 0.785\n",
      "Iteration 2599, source loss =  0.962, discriminator acc = 0.697\n",
      "Iteration 2699, source loss =  0.735, discriminator acc = 0.426\n",
      "Iteration 2799, source loss =  0.846, discriminator acc = 0.102\n",
      "Iteration 2899, source loss =  0.807, discriminator acc = 0.763\n",
      "Iteration 2999, source loss =  0.830, discriminator acc = 0.680\n",
      "Adversarial training for ST slide 151509: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 28us/sample - loss: 1.2007 - mae: 0.0343\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.8423 - mae: 0.0284\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.6880 - mae: 0.0252\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.6120 - mae: 0.0232\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5785 - mae: 0.0222\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5556 - mae: 0.0215\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5385 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5257 - mae: 0.0208\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5119 - mae: 0.0204\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.4986 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  3.593, discriminator acc = 0.056\n",
      "Iteration 199, source loss =  1.802, discriminator acc = 0.818\n",
      "Iteration 299, source loss =  1.440, discriminator acc = 0.812\n",
      "Iteration 399, source loss =  1.289, discriminator acc = 0.484\n",
      "Iteration 499, source loss =  1.650, discriminator acc = 0.187\n",
      "Iteration 599, source loss =  1.273, discriminator acc = 0.194\n",
      "Iteration 699, source loss =  1.317, discriminator acc = 0.779\n",
      "Iteration 799, source loss =  1.301, discriminator acc = 0.194\n",
      "Iteration 899, source loss =  1.265, discriminator acc = 0.954\n",
      "Iteration 999, source loss =  1.175, discriminator acc = 0.448\n",
      "Iteration 1099, source loss =  1.186, discriminator acc = 0.864\n",
      "Iteration 1199, source loss =  1.151, discriminator acc = 0.632\n",
      "Iteration 1299, source loss =  1.108, discriminator acc = 1.000\n",
      "Iteration 1399, source loss =  1.094, discriminator acc = 0.814\n",
      "Iteration 1499, source loss =  0.988, discriminator acc = 0.996\n",
      "Iteration 1599, source loss =  1.090, discriminator acc = 0.960\n",
      "Iteration 1699, source loss =  1.028, discriminator acc = 0.534\n",
      "Iteration 1799, source loss =  0.927, discriminator acc = 0.920\n",
      "Iteration 1899, source loss =  0.948, discriminator acc = 0.256\n",
      "Iteration 1999, source loss =  0.962, discriminator acc = 0.807\n",
      "Iteration 2099, source loss =  1.031, discriminator acc = 0.799\n",
      "Iteration 2199, source loss =  0.943, discriminator acc = 0.920\n",
      "Iteration 2299, source loss =  0.927, discriminator acc = 0.838\n",
      "Iteration 2399, source loss =  0.924, discriminator acc = 0.355\n",
      "Iteration 2499, source loss =  0.837, discriminator acc = 0.973\n",
      "Iteration 2599, source loss =  0.822, discriminator acc = 0.834\n",
      "Iteration 2699, source loss =  0.808, discriminator acc = 0.477\n",
      "Iteration 2799, source loss =  0.781, discriminator acc = 0.800\n",
      "Iteration 2899, source loss =  0.798, discriminator acc = 0.152\n",
      "Iteration 2999, source loss =  0.760, discriminator acc = 0.678\n",
      "Adversarial training for ST slide 151510: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 29us/sample - loss: 1.2386 - mae: 0.0348\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.8713 - mae: 0.0288\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.7110 - mae: 0.0257\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.6205 - mae: 0.0235\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5814 - mae: 0.0223\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5575 - mae: 0.0216\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5407 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5262 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5121 - mae: 0.0203\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5001 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  3.144, discriminator acc = 0.698\n",
      "Iteration 199, source loss =  1.824, discriminator acc = 0.876\n",
      "Iteration 299, source loss =  1.579, discriminator acc = 0.824\n",
      "Iteration 399, source loss =  1.782, discriminator acc = 0.281\n",
      "Iteration 499, source loss =  1.427, discriminator acc = 0.992\n",
      "Iteration 599, source loss =  1.300, discriminator acc = 0.871\n",
      "Iteration 699, source loss =  1.148, discriminator acc = 0.792\n",
      "Iteration 799, source loss =  1.151, discriminator acc = 0.959\n",
      "Iteration 899, source loss =  0.954, discriminator acc = 0.896\n",
      "Iteration 999, source loss =  0.886, discriminator acc = 0.275\n",
      "Iteration 1099, source loss =  0.804, discriminator acc = 0.347\n",
      "Iteration 1199, source loss =  0.774, discriminator acc = 0.731\n",
      "Iteration 1299, source loss =  0.718, discriminator acc = 0.821\n",
      "Iteration 1399, source loss =  0.783, discriminator acc = 0.907\n",
      "Iteration 1499, source loss =  0.763, discriminator acc = 0.481\n",
      "Iteration 1599, source loss =  0.695, discriminator acc = 0.562\n",
      "Iteration 1699, source loss =  0.763, discriminator acc = 0.232\n",
      "Iteration 1799, source loss =  0.685, discriminator acc = 0.877\n",
      "Iteration 1899, source loss =  0.667, discriminator acc = 0.790\n",
      "Iteration 1999, source loss =  0.667, discriminator acc = 0.969\n",
      "Iteration 2099, source loss =  0.637, discriminator acc = 0.851\n",
      "Iteration 2199, source loss =  0.704, discriminator acc = 0.997\n",
      "Iteration 2299, source loss =  0.673, discriminator acc = 0.997\n",
      "Iteration 2399, source loss =  0.772, discriminator acc = 0.147\n",
      "Iteration 2499, source loss =  0.955, discriminator acc = 0.043\n",
      "Iteration 2599, source loss =  0.633, discriminator acc = 0.715\n",
      "Iteration 2699, source loss =  0.675, discriminator acc = 0.721\n",
      "Iteration 2799, source loss =  0.712, discriminator acc = 0.930\n",
      "Iteration 2899, source loss =  0.896, discriminator acc = 0.238\n",
      "Iteration 2999, source loss =  0.962, discriminator acc = 0.099\n",
      "Adversarial training for ST slide 151669: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 27us/sample - loss: 1.2262 - mae: 0.0349\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.8549 - mae: 0.0285\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.6930 - mae: 0.0252\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.6120 - mae: 0.0231\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5764 - mae: 0.0221\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5536 - mae: 0.0215\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5374 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5224 - mae: 0.0206\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5095 - mae: 0.0203\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.4983 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  3.426, discriminator acc = 0.155\n",
      "Iteration 199, source loss =  2.906, discriminator acc = 0.714\n",
      "Iteration 299, source loss =  2.119, discriminator acc = 0.993\n",
      "Iteration 399, source loss =  1.659, discriminator acc = 0.208\n",
      "Iteration 499, source loss =  1.161, discriminator acc = 0.879\n",
      "Iteration 599, source loss =  1.208, discriminator acc = 0.979\n",
      "Iteration 699, source loss =  1.434, discriminator acc = 0.180\n",
      "Iteration 799, source loss =  1.227, discriminator acc = 0.939\n",
      "Iteration 899, source loss =  1.208, discriminator acc = 0.931\n",
      "Iteration 999, source loss =  1.054, discriminator acc = 0.622\n",
      "Iteration 1099, source loss =  0.916, discriminator acc = 0.977\n",
      "Iteration 1199, source loss =  0.988, discriminator acc = 0.179\n",
      "Iteration 1299, source loss =  0.841, discriminator acc = 0.880\n",
      "Iteration 1399, source loss =  0.766, discriminator acc = 0.964\n",
      "Iteration 1499, source loss =  0.783, discriminator acc = 0.188\n",
      "Iteration 1599, source loss =  0.734, discriminator acc = 0.880\n",
      "Iteration 1699, source loss =  0.724, discriminator acc = 0.532\n",
      "Iteration 1799, source loss =  0.727, discriminator acc = 0.219\n",
      "Iteration 1899, source loss =  0.676, discriminator acc = 0.891\n",
      "Iteration 1999, source loss =  0.678, discriminator acc = 0.851\n",
      "Iteration 2099, source loss =  0.680, discriminator acc = 0.140\n",
      "Iteration 2199, source loss =  0.657, discriminator acc = 0.055\n",
      "Iteration 2299, source loss =  0.617, discriminator acc = 0.718\n",
      "Iteration 2399, source loss =  0.650, discriminator acc = 0.660\n",
      "Iteration 2499, source loss =  0.651, discriminator acc = 0.408\n",
      "Iteration 2599, source loss =  0.652, discriminator acc = 0.155\n",
      "Iteration 2699, source loss =  0.619, discriminator acc = 0.486\n",
      "Iteration 2799, source loss =  0.734, discriminator acc = 0.080\n",
      "Iteration 2899, source loss =  0.596, discriminator acc = 0.764\n",
      "Iteration 2999, source loss =  0.696, discriminator acc = 0.193\n",
      "Adversarial training for ST slide 151670: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 27us/sample - loss: 1.2172 - mae: 0.0343\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.8664 - mae: 0.0286\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.7089 - mae: 0.0256\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.6212 - mae: 0.0234\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5809 - mae: 0.0222\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5583 - mae: 0.0216\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5405 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.5260 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5102 - mae: 0.0203\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.4992 - mae: 0.0200\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  3.523, discriminator acc = 0.226\n",
      "Iteration 199, source loss =  2.603, discriminator acc = 0.594\n",
      "Iteration 299, source loss =  1.481, discriminator acc = 0.145\n",
      "Iteration 399, source loss =  1.385, discriminator acc = 0.159\n",
      "Iteration 499, source loss =  1.486, discriminator acc = 0.150\n",
      "Iteration 599, source loss =  1.119, discriminator acc = 0.544\n",
      "Iteration 699, source loss =  1.314, discriminator acc = 0.143\n",
      "Iteration 799, source loss =  1.257, discriminator acc = 0.149\n",
      "Iteration 899, source loss =  1.158, discriminator acc = 0.313\n",
      "Iteration 999, source loss =  1.193, discriminator acc = 0.829\n",
      "Iteration 1099, source loss =  1.071, discriminator acc = 0.335\n",
      "Iteration 1199, source loss =  1.135, discriminator acc = 0.416\n",
      "Iteration 1299, source loss =  1.050, discriminator acc = 1.000\n",
      "Iteration 1399, source loss =  1.056, discriminator acc = 0.279\n",
      "Iteration 1499, source loss =  0.914, discriminator acc = 0.999\n",
      "Iteration 1599, source loss =  0.902, discriminator acc = 0.581\n",
      "Iteration 1699, source loss =  0.978, discriminator acc = 0.642\n",
      "Iteration 1799, source loss =  0.858, discriminator acc = 0.964\n",
      "Iteration 1899, source loss =  1.188, discriminator acc = 0.118\n",
      "Iteration 1999, source loss =  0.993, discriminator acc = 0.923\n",
      "Iteration 2099, source loss =  1.044, discriminator acc = 0.225\n",
      "Iteration 2199, source loss =  0.934, discriminator acc = 0.969\n",
      "Iteration 2299, source loss =  1.000, discriminator acc = 0.631\n",
      "Iteration 2399, source loss =  1.145, discriminator acc = 0.465\n",
      "Iteration 2499, source loss =  0.930, discriminator acc = 0.985\n",
      "Iteration 2599, source loss =  0.921, discriminator acc = 0.691\n",
      "Iteration 2699, source loss =  0.851, discriminator acc = 0.981\n",
      "Iteration 2799, source loss =  0.933, discriminator acc = 0.448\n",
      "Iteration 2899, source loss =  0.841, discriminator acc = 0.851\n",
      "Iteration 2999, source loss =  0.879, discriminator acc = 0.964\n",
      "Adversarial training for ST slide 151671: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 33us/sample - loss: 1.2149 - mae: 0.0345\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.8600 - mae: 0.0285\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.6984 - mae: 0.0254\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.6131 - mae: 0.0232\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5764 - mae: 0.0221\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5528 - mae: 0.0214\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5380 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5219 - mae: 0.0206\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5093 - mae: 0.0203\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.4973 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  2.810, discriminator acc = 0.170\n",
      "Iteration 199, source loss =  2.593, discriminator acc = 0.170\n",
      "Iteration 299, source loss =  1.463, discriminator acc = 0.869\n",
      "Iteration 399, source loss =  1.476, discriminator acc = 0.999\n",
      "Iteration 499, source loss =  1.320, discriminator acc = 0.170\n",
      "Iteration 599, source loss =  1.474, discriminator acc = 0.429\n",
      "Iteration 699, source loss =  1.366, discriminator acc = 0.166\n",
      "Iteration 799, source loss =  1.143, discriminator acc = 0.945\n",
      "Iteration 899, source loss =  1.196, discriminator acc = 0.193\n",
      "Iteration 999, source loss =  1.160, discriminator acc = 1.000\n",
      "Iteration 1099, source loss =  1.105, discriminator acc = 0.624\n",
      "Iteration 1199, source loss =  1.047, discriminator acc = 1.000\n",
      "Iteration 1299, source loss =  1.029, discriminator acc = 0.201\n",
      "Iteration 1399, source loss =  0.952, discriminator acc = 0.939\n",
      "Iteration 1499, source loss =  0.931, discriminator acc = 0.265\n",
      "Iteration 1599, source loss =  0.877, discriminator acc = 0.564\n",
      "Iteration 1699, source loss =  0.974, discriminator acc = 0.878\n",
      "Iteration 1799, source loss =  0.971, discriminator acc = 0.820\n",
      "Iteration 1899, source loss =  0.948, discriminator acc = 0.809\n",
      "Iteration 1999, source loss =  1.131, discriminator acc = 0.943\n",
      "Iteration 2099, source loss =  1.023, discriminator acc = 0.586\n",
      "Iteration 2199, source loss =  0.955, discriminator acc = 0.769\n",
      "Iteration 2299, source loss =  0.997, discriminator acc = 0.937\n",
      "Iteration 2399, source loss =  0.980, discriminator acc = 0.187\n",
      "Iteration 2499, source loss =  0.827, discriminator acc = 0.991\n",
      "Iteration 2599, source loss =  0.910, discriminator acc = 0.968\n",
      "Iteration 2699, source loss =  0.929, discriminator acc = 0.254\n",
      "Iteration 2799, source loss =  0.846, discriminator acc = 0.988\n",
      "Iteration 2899, source loss =  0.951, discriminator acc = 1.000\n",
      "Iteration 2999, source loss =  0.943, discriminator acc = 0.155\n",
      "Adversarial training for ST slide 151672: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 30us/sample - loss: 1.1892 - mae: 0.0343\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.8198 - mae: 0.0280\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.6678 - mae: 0.0248\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 10us/sample - loss: 0.6031 - mae: 0.0229\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5732 - mae: 0.0220\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5524 - mae: 0.0214\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5352 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5230 - mae: 0.0206\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5098 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.4968 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  2.421, discriminator acc = 0.074\n",
      "Iteration 199, source loss =  1.426, discriminator acc = 0.151\n",
      "Iteration 299, source loss =  1.454, discriminator acc = 0.932\n",
      "Iteration 399, source loss =  1.516, discriminator acc = 0.399\n",
      "Iteration 499, source loss =  1.360, discriminator acc = 0.313\n",
      "Iteration 599, source loss =  1.259, discriminator acc = 0.180\n",
      "Iteration 699, source loss =  1.182, discriminator acc = 0.474\n",
      "Iteration 799, source loss =  1.122, discriminator acc = 1.000\n",
      "Iteration 899, source loss =  1.258, discriminator acc = 0.469\n",
      "Iteration 999, source loss =  1.224, discriminator acc = 0.213\n",
      "Iteration 1099, source loss =  1.150, discriminator acc = 0.170\n",
      "Iteration 1199, source loss =  1.135, discriminator acc = 0.915\n",
      "Iteration 1299, source loss =  1.111, discriminator acc = 0.850\n",
      "Iteration 1399, source loss =  1.108, discriminator acc = 0.228\n",
      "Iteration 1499, source loss =  1.098, discriminator acc = 0.922\n",
      "Iteration 1599, source loss =  1.105, discriminator acc = 0.504\n",
      "Iteration 1699, source loss =  1.062, discriminator acc = 0.996\n",
      "Iteration 1799, source loss =  1.002, discriminator acc = 0.738\n",
      "Iteration 1899, source loss =  1.024, discriminator acc = 0.915\n",
      "Iteration 1999, source loss =  0.987, discriminator acc = 0.913\n",
      "Iteration 2099, source loss =  0.952, discriminator acc = 0.937\n",
      "Iteration 2199, source loss =  0.904, discriminator acc = 0.949\n",
      "Iteration 2299, source loss =  0.930, discriminator acc = 0.184\n",
      "Iteration 2399, source loss =  0.827, discriminator acc = 0.919\n",
      "Iteration 2499, source loss =  0.843, discriminator acc = 0.215\n",
      "Iteration 2599, source loss =  0.801, discriminator acc = 0.527\n",
      "Iteration 2699, source loss =  0.793, discriminator acc = 0.687\n",
      "Iteration 2799, source loss =  0.788, discriminator acc = 0.215\n",
      "Iteration 2899, source loss =  0.779, discriminator acc = 0.279\n",
      "Iteration 2999, source loss =  0.759, discriminator acc = 0.957\n",
      "Adversarial training for ST slide 151673: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 34us/sample - loss: 1.2216 - mae: 0.0345\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.8605 - mae: 0.0286\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.6969 - mae: 0.0254\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.6109 - mae: 0.0232\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5734 - mae: 0.0220\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5506 - mae: 0.0214\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 13us/sample - loss: 0.5358 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5197 - mae: 0.0205\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5074 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.4952 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  2.733, discriminator acc = 0.859\n",
      "Iteration 199, source loss =  2.061, discriminator acc = 0.154\n",
      "Iteration 299, source loss =  1.557, discriminator acc = 0.623\n",
      "Iteration 399, source loss =  1.483, discriminator acc = 0.218\n",
      "Iteration 499, source loss =  1.317, discriminator acc = 0.900\n",
      "Iteration 599, source loss =  1.290, discriminator acc = 0.893\n",
      "Iteration 699, source loss =  1.129, discriminator acc = 0.151\n",
      "Iteration 799, source loss =  1.154, discriminator acc = 0.970\n",
      "Iteration 899, source loss =  1.110, discriminator acc = 0.715\n",
      "Iteration 999, source loss =  1.185, discriminator acc = 0.969\n",
      "Iteration 1099, source loss =  1.284, discriminator acc = 0.156\n",
      "Iteration 1199, source loss =  1.040, discriminator acc = 0.952\n",
      "Iteration 1299, source loss =  1.010, discriminator acc = 0.322\n",
      "Iteration 1399, source loss =  1.037, discriminator acc = 0.722\n",
      "Iteration 1499, source loss =  0.953, discriminator acc = 0.789\n",
      "Iteration 1599, source loss =  1.153, discriminator acc = 0.999\n",
      "Iteration 1699, source loss =  0.961, discriminator acc = 0.286\n",
      "Iteration 1799, source loss =  0.888, discriminator acc = 0.971\n",
      "Iteration 1899, source loss =  0.848, discriminator acc = 0.740\n",
      "Iteration 1999, source loss =  0.843, discriminator acc = 0.494\n",
      "Iteration 2099, source loss =  0.856, discriminator acc = 0.891\n",
      "Iteration 2199, source loss =  0.837, discriminator acc = 0.963\n",
      "Iteration 2299, source loss =  0.813, discriminator acc = 0.750\n",
      "Iteration 2399, source loss =  0.793, discriminator acc = 0.287\n",
      "Iteration 2499, source loss =  0.802, discriminator acc = 0.563\n",
      "Iteration 2599, source loss =  0.851, discriminator acc = 0.134\n",
      "Iteration 2699, source loss =  0.751, discriminator acc = 0.678\n",
      "Iteration 2799, source loss =  0.851, discriminator acc = 0.445\n",
      "Iteration 2899, source loss =  0.775, discriminator acc = 0.723\n",
      "Iteration 2999, source loss =  0.780, discriminator acc = 0.082\n",
      "Adversarial training for ST slide 151674: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 35us/sample - loss: 1.2210 - mae: 0.0350\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.8519 - mae: 0.0286\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.6929 - mae: 0.0253\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.6141 - mae: 0.0232\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5786 - mae: 0.0221\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5557 - mae: 0.0215\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5379 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5237 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5080 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.4974 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  4.454, discriminator acc = 0.155\n",
      "Iteration 199, source loss =  2.480, discriminator acc = 0.155\n",
      "Iteration 299, source loss =  1.532, discriminator acc = 0.856\n",
      "Iteration 399, source loss =  1.431, discriminator acc = 0.949\n",
      "Iteration 499, source loss =  1.423, discriminator acc = 0.876\n",
      "Iteration 599, source loss =  1.587, discriminator acc = 0.156\n",
      "Iteration 699, source loss =  1.418, discriminator acc = 0.855\n",
      "Iteration 799, source loss =  1.138, discriminator acc = 0.817\n",
      "Iteration 899, source loss =  1.320, discriminator acc = 0.964\n",
      "Iteration 999, source loss =  1.040, discriminator acc = 0.650\n",
      "Iteration 1099, source loss =  1.033, discriminator acc = 0.808\n",
      "Iteration 1199, source loss =  0.994, discriminator acc = 0.306\n",
      "Iteration 1299, source loss =  0.987, discriminator acc = 0.426\n",
      "Iteration 1399, source loss =  0.818, discriminator acc = 0.965\n",
      "Iteration 1499, source loss =  0.787, discriminator acc = 0.978\n",
      "Iteration 1599, source loss =  0.890, discriminator acc = 0.164\n",
      "Iteration 1699, source loss =  0.822, discriminator acc = 0.302\n",
      "Iteration 1799, source loss =  1.058, discriminator acc = 0.375\n",
      "Iteration 1899, source loss =  0.771, discriminator acc = 0.935\n",
      "Iteration 1999, source loss =  0.740, discriminator acc = 0.963\n",
      "Iteration 2099, source loss =  0.773, discriminator acc = 0.854\n",
      "Iteration 2199, source loss =  0.753, discriminator acc = 0.707\n",
      "Iteration 2299, source loss =  0.869, discriminator acc = 0.066\n",
      "Iteration 2399, source loss =  0.761, discriminator acc = 0.944\n",
      "Iteration 2499, source loss =  0.693, discriminator acc = 0.949\n",
      "Iteration 2599, source loss =  0.728, discriminator acc = 0.031\n",
      "Iteration 2699, source loss =  0.678, discriminator acc = 0.741\n",
      "Iteration 2799, source loss =  0.680, discriminator acc = 0.972\n",
      "Iteration 2899, source loss =  0.681, discriminator acc = 0.723\n",
      "Iteration 2999, source loss =  0.805, discriminator acc = 0.068\n",
      "Adversarial training for ST slide 151675: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 32us/sample - loss: 1.2348 - mae: 0.0349\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.8671 - mae: 0.0288\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.7062 - mae: 0.0257\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.6197 - mae: 0.0235\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5790 - mae: 0.0222\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5573 - mae: 0.0216\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 12us/sample - loss: 0.5388 - mae: 0.0211\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 11us/sample - loss: 0.5246 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5096 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.4976 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  2.281, discriminator acc = 0.137\n",
      "Iteration 199, source loss =  2.357, discriminator acc = 0.762\n",
      "Iteration 299, source loss =  1.646, discriminator acc = 0.880\n",
      "Iteration 399, source loss =  1.667, discriminator acc = 0.877\n",
      "Iteration 499, source loss =  1.350, discriminator acc = 0.874\n",
      "Iteration 599, source loss =  1.551, discriminator acc = 0.888\n",
      "Iteration 699, source loss =  1.322, discriminator acc = 0.901\n",
      "Iteration 799, source loss =  1.287, discriminator acc = 0.882\n",
      "Iteration 899, source loss =  1.250, discriminator acc = 0.873\n",
      "Iteration 999, source loss =  1.287, discriminator acc = 0.882\n",
      "Iteration 1099, source loss =  1.243, discriminator acc = 0.995\n",
      "Iteration 1199, source loss =  1.294, discriminator acc = 0.950\n",
      "Iteration 1299, source loss =  1.455, discriminator acc = 0.499\n",
      "Iteration 1399, source loss =  1.343, discriminator acc = 0.883\n",
      "Iteration 1499, source loss =  1.047, discriminator acc = 0.857\n",
      "Iteration 1599, source loss =  1.096, discriminator acc = 0.361\n",
      "Iteration 1699, source loss =  1.009, discriminator acc = 0.547\n",
      "Iteration 1799, source loss =  0.910, discriminator acc = 0.623\n",
      "Iteration 1899, source loss =  0.903, discriminator acc = 0.656\n",
      "Iteration 1999, source loss =  0.896, discriminator acc = 0.532\n",
      "Iteration 2099, source loss =  0.851, discriminator acc = 0.503\n",
      "Iteration 2199, source loss =  0.812, discriminator acc = 0.890\n",
      "Iteration 2299, source loss =  0.812, discriminator acc = 0.927\n",
      "Iteration 2399, source loss =  0.799, discriminator acc = 0.922\n",
      "Iteration 2499, source loss =  0.781, discriminator acc = 0.974\n",
      "Iteration 2599, source loss =  0.824, discriminator acc = 0.740\n",
      "Iteration 2699, source loss =  0.756, discriminator acc = 0.621\n",
      "Iteration 2799, source loss =  0.725, discriminator acc = 0.830\n",
      "Iteration 2899, source loss =  0.690, discriminator acc = 0.784\n",
      "Iteration 2999, source loss =  0.665, discriminator acc = 0.769\n",
      "Adversarial training for ST slide 151676: \n",
      "Train on 20000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 38us/sample - loss: 1.2224 - mae: 0.0346\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.8533 - mae: 0.0285\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.6936 - mae: 0.0253\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.6117 - mae: 0.0231\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5764 - mae: 0.0221\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5557 - mae: 0.0215\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.5390 - mae: 0.0210\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s 14us/sample - loss: 0.5254 - mae: 0.0207\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.5099 - mae: 0.0202\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.4981 - mae: 0.0199\n",
      "initial_train_done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wma/miniconda3/envs/CellDART/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, source loss =  2.441, discriminator acc = 0.847\n",
      "Iteration 199, source loss =  1.537, discriminator acc = 0.865\n",
      "Iteration 299, source loss =  1.552, discriminator acc = 0.855\n",
      "Iteration 399, source loss =  1.503, discriminator acc = 0.871\n",
      "Iteration 499, source loss =  1.373, discriminator acc = 0.883\n",
      "Iteration 599, source loss =  1.590, discriminator acc = 0.873\n",
      "Iteration 699, source loss =  1.297, discriminator acc = 0.885\n",
      "Iteration 799, source loss =  1.325, discriminator acc = 0.875\n",
      "Iteration 899, source loss =  1.265, discriminator acc = 0.878\n",
      "Iteration 999, source loss =  1.179, discriminator acc = 0.887\n",
      "Iteration 1099, source loss =  1.233, discriminator acc = 0.974\n",
      "Iteration 1199, source loss =  1.317, discriminator acc = 0.527\n",
      "Iteration 1299, source loss =  1.381, discriminator acc = 0.987\n",
      "Iteration 1399, source loss =  1.063, discriminator acc = 0.959\n",
      "Iteration 1499, source loss =  1.107, discriminator acc = 0.373\n",
      "Iteration 1599, source loss =  0.983, discriminator acc = 0.486\n",
      "Iteration 1699, source loss =  0.894, discriminator acc = 0.513\n",
      "Iteration 1799, source loss =  0.859, discriminator acc = 0.436\n",
      "Iteration 1899, source loss =  0.817, discriminator acc = 0.690\n",
      "Iteration 1999, source loss =  0.823, discriminator acc = 0.688\n",
      "Iteration 2099, source loss =  0.815, discriminator acc = 0.912\n",
      "Iteration 2199, source loss =  0.785, discriminator acc = 0.639\n",
      "Iteration 2299, source loss =  0.781, discriminator acc = 0.534\n",
      "Iteration 2399, source loss =  0.706, discriminator acc = 0.695\n",
      "Iteration 2499, source loss =  0.703, discriminator acc = 0.598\n",
      "Iteration 2599, source loss =  0.675, discriminator acc = 0.476\n",
      "Iteration 2699, source loss =  0.681, discriminator acc = 0.530\n",
      "Iteration 2799, source loss =  0.662, discriminator acc = 0.681\n",
      "Iteration 2899, source loss =  0.629, discriminator acc = 0.147\n",
      "Iteration 2999, source loss =  0.595, discriminator acc = 0.537\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_USING_ALL_ST_SAMPLES:\n",
    "    print(f\"Adversarial training for all ST slides\")\n",
    "    embs, clssmodel, clssmodel_noda = da_cellfraction.train(\n",
    "        sc_mix_d[\"train\"],\n",
    "        lab_mix_d[\"train\"],\n",
    "        mat_sp_train_s,\n",
    "        alpha=ALPHA,\n",
    "        alpha_lr=5,\n",
    "        emb_dim=64,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_iterations=N_ITER,\n",
    "        initial_train=True,\n",
    "        initial_train_epochs=INITIAL_TRAIN_EPOCHS,\n",
    "    )\n",
    "elif BOOTSTRAP:\n",
    "    pred_sp_boostrap_d = {}\n",
    "    \n",
    "    outer = tqdm(total=len(BOOTSTRAP_ALPHAS), desc=\"Alphas\", position=0)\n",
    "    inner1 = tqdm(total=len(st_sample_id_l), desc=f\"Sample\", position=1)\n",
    "    inner2 = tqdm(total=BOOTSTRAP_ROUNDS, desc=f\"Bootstrap #\", position=2)\n",
    "    for alpha in BOOTSTRAP_ALPHAS:\n",
    "        \n",
    "        inner1.refresh()  # force print final state\n",
    "        inner1.reset()  # reuse bar\n",
    "\n",
    "        \n",
    "        pred_sp_boostrap_d[alpha] = {}\n",
    "        \n",
    "\n",
    "        for sample_id in st_sample_id_l:\n",
    "            inner2.refresh()  # force print final state\n",
    "            inner2.reset()  # reuse bar\n",
    "            \n",
    "            pred_sp_boostrap_d[alpha][sample_id] = []\n",
    "            for i in range(BOOTSTRAP_ROUNDS):\n",
    "                print(f\"Adversarial training for ST slide {sample_id}: \")\n",
    "                embs, clssmodel, _ = da_cellfraction.train(\n",
    "                    sc_mix_d[\"train\"],\n",
    "                    lab_mix_d[\"train\"],\n",
    "                    mat_sp_d[\"train\"][sample_id],\n",
    "                    alpha=alpha,\n",
    "                    alpha_lr=5,\n",
    "                    emb_dim=64,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    n_iterations=N_ITER,\n",
    "                    initial_train=True,\n",
    "                    initial_train_epochs=10,\n",
    "                    seed = i,\n",
    "                )\n",
    "\n",
    "                pred_sp_boostrap_d[alpha][sample_id].append(clssmodel.predict(\n",
    "                     mat_sp_d[\"train\"][sample_id]\n",
    "                ))\n",
    "                inner2.update(1)\n",
    "            inner1.update(1)\n",
    "        outer.update(1)\n",
    "\n",
    "else:\n",
    "    # embs_d, clssmodel_d, clssmodel_noda_d = {}, {}, {}\n",
    "    for sample_id in st_sample_id_l:\n",
    "        print(f\"Adversarial training for ST slide {sample_id}: \")\n",
    "        if not os.path.isdir(os.path.join(advtrain_folder, sample_id)):\n",
    "            os.makedirs(os.path.join(advtrain_folder, sample_id))\n",
    "        if not os.path.isdir(os.path.join(pretrain_folder, sample_id)):\n",
    "            os.makedirs(os.path.join(pretrain_folder, sample_id))\n",
    "        embs, embs_noda, clssmodel, clssmodel_noda = da_cellfraction.train(\n",
    "            sc_mix_d[\"train\"],\n",
    "            lab_mix_d[\"train\"],\n",
    "            mat_sp_d[sample_id][\"train\"],\n",
    "            alpha=ALPHA,\n",
    "            alpha_lr=5,\n",
    "            emb_dim=64,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            n_iterations=N_ITER,\n",
    "            initial_train=True,\n",
    "            initial_train_epochs=10,\n",
    "            seed=int(sample_id)\n",
    "        )\n",
    "        # embs_d[sample_id] = embs\n",
    "        # clssmodel_d[sample_id] = clssmodel\n",
    "        # clssmodel_noda_d[sample_id] = clssmodel_noda\n",
    "\n",
    "        # Save model\n",
    "        clssmodel_noda.save(os.path.join(pretrain_folder, sample_id, \"final_model\"))\n",
    "        clssmodel.save(os.path.join(advtrain_folder, sample_id, \"final_model\"))\n",
    "\n",
    "        embs_noda.save(os.path.join(pretrain_folder, sample_id, \"embs\"))\n",
    "        embs.save(os.path.join(advtrain_folder, sample_id, \"embs\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.195841Z",
     "iopub.status.busy": "2023-01-11T08:39:15.195655Z",
     "iopub.status.idle": "2023-01-11T08:39:15.198765Z",
     "shell.execute_reply": "2023-01-11T08:39:15.198136Z"
    }
   },
   "outputs": [],
   "source": [
    "# confidence = 0.95\n",
    "# if BOOTSTRAP:\n",
    "#     for alpha in BOOTSTRAP_ALPHAS:\n",
    "#         bootstrap_d = {}\n",
    "#         for sample_id in st_sample_id_l:\n",
    "            \n",
    "            \n",
    "#             bootstrap_d[sample_id] = {}\n",
    "#             for i, num in enumerate(numlist):\n",
    "                \n",
    "#                 acc = [metrics.roc_auc_score(*gen_pred_true(num, adata_spatialLIBD_d[SAMPLE_ID_N], pred)[::-1]) for pred in pred_sp_boostrap_d[alpha][SAMPLE_ID_N]]\n",
    "#                 test_mean = np.mean(acc)\n",
    "#                 t_value = ss.t.ppf((1 + confidence) / 2.0, df=BOOTSTRAP_ROUNDS - 1)\n",
    "\n",
    "#                 sd = np.std(acc, ddof=1)\n",
    "#                 se = sd / np.sqrt(BOOTSTRAP_ROUNDS)\n",
    "\n",
    "#                 ci_length = t_value * se\n",
    "\n",
    "#                 ci_lower = test_mean - ci_length\n",
    "#                 ci_upper = test_mean + ci_length\n",
    "\n",
    "#                 bootstrap_d[sample_id][num_to_ex_d[num]] = (ci_lower, test_mean, ci_upper)\n",
    "\n",
    "\n",
    "#         bootstrap_df = pd.DataFrame.from_dict(bootstrap_d)\n",
    "#         display(bootstrap_df)\n",
    "#         bootstrap_df.to_csv(os.path.join(results_folder, f'bootstrap_alpha{alpha}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict cell fraction of spots and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.200685Z",
     "iopub.status.busy": "2023-01-11T08:39:15.200530Z",
     "iopub.status.idle": "2023-01-11T08:39:15.203452Z",
     "shell.execute_reply": "2023-01-11T08:39:15.202816Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_sp_d, pred_sp_noda_d = {}, {}\n",
    "# if TRAIN_USING_ALL_ST_SAMPLES:\n",
    "#     for sample_id in st_sample_id_l:\n",
    "#         pred_sp_d[sample_id] = clssmodel.predict(mat_sp_test_s_d[sample_id])\n",
    "#         pred_sp_noda_d[sample_id] = clssmodel_noda.predict(mat_sp_test_s_d[sample_id])\n",
    "# else:\n",
    "#     for sample_id in st_sample_id_l:\n",
    "#         pred_sp_d[sample_id] = clssmodel_d[sample_id].predict(\n",
    "#             mat_sp_test_s_d[sample_id]\n",
    "#         )\n",
    "#         pred_sp_noda_d[sample_id] = clssmodel_noda_d[sample_id].predict(\n",
    "#             mat_sp_test_s_d[sample_id]\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.205274Z",
     "iopub.status.busy": "2023-01-11T08:39:15.205122Z",
     "iopub.status.idle": "2023-01-11T08:39:15.208051Z",
     "shell.execute_reply": "2023-01-11T08:39:15.207436Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_cellfraction(visnum, adata, pred_sp, ax=None):\n",
    "#     \"\"\"Plot predicted cell fraction for a given visnum\"\"\"\n",
    "#     adata.obs[\"Pred_label\"] = pred_sp[:, visnum]\n",
    "#     # vmin = 0\n",
    "#     # vmax = np.amax(pred_sp)\n",
    "\n",
    "#     sc.pl.spatial(\n",
    "#         adata,\n",
    "#         img_key=\"hires\",\n",
    "#         color=\"Pred_label\",\n",
    "#         palette=\"Set1\",\n",
    "#         size=1.5,\n",
    "#         legend_loc=None,\n",
    "#         title=f\"{sc_sub_dict[visnum]}\",\n",
    "#         spot_size=100,\n",
    "#         show=False,\n",
    "#         # vmin=vmin,\n",
    "#         # vmax=vmax,\n",
    "#         ax=ax,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.209901Z",
     "iopub.status.busy": "2023-01-11T08:39:15.209747Z",
     "iopub.status.idle": "2023-01-11T08:39:15.212705Z",
     "shell.execute_reply": "2023-01-11T08:39:15.212081Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_cell_layers(df):\n",
    "\n",
    "#     layer_idx = df[\"spatialLIBD\"].unique().astype(str)\n",
    "#     samples = df[\"sample_id\"].unique()\n",
    "#     layer_idx.sort()\n",
    "#     fig, ax = plt.subplots(\n",
    "#         nrows=1,\n",
    "#         ncols=len(samples),\n",
    "#         figsize=(5 * len(samples), 5),\n",
    "#         squeeze=False,\n",
    "#         constrained_layout=True,\n",
    "#     )\n",
    "\n",
    "#     for idx, sample in enumerate(samples):\n",
    "#         cells_of_samples = df[df[\"sample_id\"] == sample]\n",
    "#         for index in layer_idx:\n",
    "#             cells_of_layer = cells_of_samples[cells_of_samples[\"spatialLIBD\"] == index]\n",
    "#             ax.flat[idx].scatter(\n",
    "#                 cells_of_layer[\"X\"], -cells_of_layer[\"Y\"], label=index, s=17, marker=\"o\"\n",
    "#             )\n",
    "\n",
    "#         ax.flat[idx].axis(\"equal\")\n",
    "#         ax.flat[idx].set_xticks([])\n",
    "#         ax.flat[idx].set_yticks([])\n",
    "#         ax.flat[idx].set_title(sample)\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.214452Z",
     "iopub.status.busy": "2023-01-11T08:39:15.214299Z",
     "iopub.status.idle": "2023-01-11T08:39:15.217152Z",
     "shell.execute_reply": "2023-01-11T08:39:15.216515Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_roc(visnum, adata, pred_sp, name, ax=None):\n",
    "#     \"\"\"Plot ROC for a given visnum\"\"\"\n",
    "\n",
    "#     def layer_to_layer_number(x):\n",
    "#         for char in x:\n",
    "#             if char.isdigit():\n",
    "#                 if int(char) in Ex_to_L_d[num_to_ex_d[visnum]]:\n",
    "#                     return 1\n",
    "#         return 0\n",
    "\n",
    "#     y_pred = pred_sp[:, visnum]\n",
    "#     y_true = adata.obs[\"spatialLIBD\"].map(layer_to_layer_number).fillna(0)\n",
    "#     # print(y_true)\n",
    "#     # print(y_true.isna().sum())\n",
    "#     RocCurveDisplay.from_predictions(y_true=y_true, y_pred=y_pred, name=name, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.218894Z",
     "iopub.status.busy": "2023-01-11T08:39:15.218732Z",
     "iopub.status.idle": "2023-01-11T08:39:15.221544Z",
     "shell.execute_reply": "2023-01-11T08:39:15.220923Z"
    }
   },
   "outputs": [],
   "source": [
    "# # plot_cell_layers(adata_spatialLIBD_151673.obs)\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout=True)\n",
    "\n",
    "# sc.pl.spatial(\n",
    "#     adata_spatialLIBD_d[SAMPLE_ID_N],\n",
    "#     img_key=None,\n",
    "#     color=\"spatialLIBD\",\n",
    "#     palette=\"Accent_r\",\n",
    "#     size=1.5,\n",
    "#     title=SAMPLE_ID_N,\n",
    "#     # legend_loc = 4,\n",
    "#     spot_size=100,\n",
    "#     show=False,\n",
    "#     ax=ax,\n",
    "# )\n",
    "\n",
    "# ax.axis(\"equal\")\n",
    "# ax.set_xlabel(\"\")\n",
    "# ax.set_ylabel(\"\")\n",
    "\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.223486Z",
     "iopub.status.busy": "2023-01-11T08:39:15.223331Z",
     "iopub.status.idle": "2023-01-11T08:39:15.226443Z",
     "shell.execute_reply": "2023-01-11T08:39:15.225853Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 5, figsize=(20, 8), constrained_layout=True)\n",
    "\n",
    "# for i, num in enumerate(numlist):\n",
    "#     plot_cellfraction(\n",
    "#         num, adata_spatialLIBD_d[SAMPLE_ID_N], pred_sp_d[SAMPLE_ID_N], ax.flat[i]\n",
    "#     )\n",
    "#     ax.flat[i].axis(\"equal\")\n",
    "#     ax.flat[i].set_xlabel(\"\")\n",
    "#     ax.flat[i].set_ylabel(\"\")\n",
    "\n",
    "# fig.show()\n",
    "# # plt.close()\n",
    "\n",
    "# fig, ax = plt.subplots(\n",
    "#     2, 5, figsize=(20, 8), constrained_layout=True, sharex=True, sharey=True\n",
    "# )\n",
    "\n",
    "# for i, num in enumerate(numlist):\n",
    "#     plot_roc(\n",
    "#         num,\n",
    "#         adata_spatialLIBD_d[SAMPLE_ID_N],\n",
    "#         pred_sp_d[SAMPLE_ID_N],\n",
    "#         \"CellDART\",\n",
    "#         ax.flat[i],\n",
    "#     )\n",
    "#     plot_roc(\n",
    "#         num,\n",
    "#         adata_spatialLIBD_d[SAMPLE_ID_N],\n",
    "#         pred_sp_noda_d[SAMPLE_ID_N],\n",
    "#         \"NN_wo_da\",\n",
    "#         ax.flat[i],\n",
    "#     )\n",
    "#     ax.flat[i].plot([0, 1], [0, 1], transform=ax.flat[i].transAxes, ls=\"--\", color=\"k\")\n",
    "#     ax.flat[i].set_aspect(\"equal\")\n",
    "#     ax.flat[i].set_xlim([0, 1])\n",
    "#     ax.flat[i].set_ylim([0, 1])\n",
    "\n",
    "#     ax.flat[i].set_title(f\"{sc_sub_dict[num]}\")\n",
    "\n",
    "#     if i >= len(numlist) - 5:\n",
    "#         ax.flat[i].set_xlabel(\"FPR\")\n",
    "#     else:\n",
    "#         ax.flat[i].set_xlabel(\"\")\n",
    "#     if i % 5 == 0:\n",
    "#         ax.flat[i].set_ylabel(\"TPR\")\n",
    "#     else:\n",
    "#         ax.flat[i].set_ylabel(\"\")\n",
    "\n",
    "# fig.show()\n",
    "# # plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cf. Prediction of Mixture (pseudospots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.228249Z",
     "iopub.status.busy": "2023-01-11T08:39:15.228095Z",
     "iopub.status.idle": "2023-01-11T08:39:15.231284Z",
     "shell.execute_reply": "2023-01-11T08:39:15.230677Z"
    }
   },
   "outputs": [],
   "source": [
    "# if TRAIN_USING_ALL_ST_SAMPLES:\n",
    "#     pred_mix = clssmodel.predict(sc_mix_test_s)\n",
    "# else:\n",
    "#     pred_mix = clssmodel_d[SAMPLE_ID_N].predict(sc_mix_test_s)\n",
    "\n",
    "\n",
    "# cell_type_nums = sc_sub_dict.keys()\n",
    "# nrows = ceil(len(cell_type_nums) / 5)\n",
    "\n",
    "# line_kws = {\"color\": \"tab:orange\"}\n",
    "# scatter_kws = {\"s\": 5}\n",
    "\n",
    "# props = dict(facecolor=\"w\", alpha=0.5)\n",
    "\n",
    "# fig, ax = plt.subplots(\n",
    "#     nrows,\n",
    "#     5,\n",
    "#     figsize=(20, 4 * nrows),\n",
    "#     constrained_layout=True,\n",
    "#     sharex=False,\n",
    "#     sharey=True,\n",
    "# )\n",
    "# for i, num in enumerate(cell_type_nums):\n",
    "#     sns.regplot(\n",
    "#         x=pred_mix[:, num],\n",
    "#         y=lab_mix_test[:, num],\n",
    "#         line_kws=line_kws,\n",
    "#         scatter_kws=scatter_kws,\n",
    "#         ax=ax.flat[i],\n",
    "#     ).set_title(sc_sub_dict[num])\n",
    "#     ax.flat[i].set_aspect(\"equal\")\n",
    "\n",
    "#     ax.flat[i].set_xlabel(\"Predicted Proportion\")\n",
    "#     if i % 5 == 0:\n",
    "#         ax.flat[i].set_ylabel(\"True Proportion\")\n",
    "#     else:\n",
    "#         ax.flat[i].set_ylabel(\"\")\n",
    "#     ax.flat[i].set_xlim([0, 1])\n",
    "#     ax.flat[i].set_ylim([0, 1])\n",
    "\n",
    "#     textstr = f\"MSE: {mean_squared_error(pred_mix[:,num], lab_mix_test[:,num]):.5f}\"\n",
    "\n",
    "#     # place a text box in upper left in axes coords\n",
    "#     ax.flat[i].text(\n",
    "#         0.95,\n",
    "#         0.05,\n",
    "#         textstr,\n",
    "#         transform=ax.flat[i].transAxes,\n",
    "#         verticalalignment=\"bottom\",\n",
    "#         horizontalalignment=\"right\",\n",
    "#         bbox=props,\n",
    "#     )\n",
    "\n",
    "# for i in range(len(cell_type_nums), nrows * 5):\n",
    "#     ax.flat[i].axis(\"off\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T08:39:15.233181Z",
     "iopub.status.busy": "2023-01-11T08:39:15.233025Z",
     "iopub.status.idle": "2023-01-11T08:39:15.235603Z",
     "shell.execute_reply": "2023-01-11T08:39:15.235019Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"\\n\".join(\n",
    "#         f\"{m.__name__} {m.__version__}\"\n",
    "#         for m in globals().values()\n",
    "#         if getattr(m, \"__version__\", None)\n",
    "#     )\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1902524a50f5bfc67b7e8209843052ec6fc35bc71711f723b9c200549b26132"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
